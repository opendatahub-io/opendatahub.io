:_module-type: CONCEPT

[id="making-inference-requests-to-models-deployed-on-single-model-serving-platform_{context}"]
= Making inference requests to models deployed on the single-model serving platform

[role='_abstract']
When you deploy a model by using the single-model serving platform, the model is available as a service that you can access using API requests. This enables you to return predictions based on data inputs. To use API requests to interact with your deployed model, you must know the inference endpoint for the model.

In addition, if you secured your inference endpoint by enabling token authentication, you must know how to access your authentication token so that you can specify this in your inference requests.

// [role='_additional-resources']
// .Additional resources

