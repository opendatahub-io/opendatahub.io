:_module-type: CONCEPT

[id='overview-of-model-monitoring_{context}']
= Overview of model monitoring

[role='_abstract']

To ensure that machine learning models are transparent, fair, and reliable, data scientists can use TrustyAI in {productname-short} to monitor and assess their data science models.

Data scientists can monitor their data science and machine learning models in {productname-short} for the following metrics:

* *Bias:* Check for unfair patterns or biases in data and model predictions to ensure your model's decisions are unbiased.

* *Data drift:* Detect changes in input data distributions over time by comparing the latest real-world data to the original training data. Comparing the data identifies shifts or deviations that could impact model performance, ensuring that the model remains accurate and reliable.

ifdef::upstream[]
* *Explainability:* Understand how your model makes predictions and decisions.
endif::[]



Data scientists can assess their data science and machine learning models in {productname-short} using the following services: 

* *LLM evaluation:* Monitor your Large Language Models (LLMs) against a range of metrics, in order to ensure the accuracy and quality of its output.

* *Guardrails Orchestrator:* Invoke detections on text generation inputs and outputs of Large Language Models (LLMs) and perform standalone detections.

