:_module-type: PROCEDURE

[id="creating-a-workbench-for-distributed-training_{context}"]
= Creating a workbench for distributed training

[role='_abstract']
Create a workbench with the appropriate resources to run a distributed training or tuning job.

.Prerequisites

* You can access an OpenShift cluster that has sufficient worker nodes with supported accelerators to run your training or tuning job.


* Your cluster administrator has configured the cluster as follows:

ifdef::upstream[]
** Installed {productname-long} with the required distributed training components, as described in link:{odhdocshome}/installing-open-data-hub/#installing-the-distributed-workloads-components_install[Installing the distributed workloads components].
endif::[]
ifdef::self-managed[]
** Installed {productname-long} with the required distributed training components, as described in link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}/installing-the-distributed-workloads-components_install[Installing the distributed workloads components] (for disconnected environments, see link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}_in_a_disconnected_environment/installing-the-distributed-workloads-components_install[Installing the distributed workloads components]).
endif::[]
ifdef::cloud-service[]
** Installed {productname-long} with the required distributed training components, as described in link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}/installing-the-distributed-workloads-components_install[Installing the distributed workloads components].
endif::[]

ifdef::upstream[]
** Configured the distributed training resources, as described in link:{odhdocshome}/managing-odh/#managing-distributed-workloads_managing-odh[Managing distributed workloads].
endif::[]
ifndef::upstream[]
** Configured the distributed training resources, as described in link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/managing-distributed-workloads_managing-rhoai[Managing distributed workloads].
endif::[]

ifdef::upstream[]
** Configured supported accelerators, as described in link:{odhdocshome}/working-with-accelerators[Working with accelerators].
endif::[]
ifndef::upstream[]
** Configured supported accelerators, as described in link:{rhoaidocshome}{default-format-url}/working_with_accelerators/[Working with accelerators].
endif::[]

.Procedure
. Log in to the {productname-long} web console.

. If you want to add the workbench to an existing project, open the project and proceed to the next step. 
+
If you want to add the workbench to a new project, create the project as follows:

.. In the left navigation pane, click *Data science projects*, and click *Create project*.
.. Enter a project name, and optionally a description, and click *Create*.
The project details page opens, with the *Overview* tab selected by default.

. Create a workbench as follows:
.. On the project details page, click the *Workbench* tab, and click *Create workbench*.
.. Enter a workbench name, and optionally a description.
.. In the *Notebook image* section, from the *Image selection* list, select the appropriate image for your training or tuning job.
+
ifndef::upstream[]
For example, to run the example fine-tuning job described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/running-kfto-based-distributed-training-workloads_distributed-workloads#fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads[Fine-tuning a model by using Kubeflow Training], select *PyTorch*.
endif::[]
ifdef::upstream[]
For example, to run the example fine-tuning job described in link:{odhdocshome}/working-with-distributed-workloads/#fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads[Fine-tuning a model by using Kubeflow Training], select *PyTorch*.
endif::[]

.. In the *Deployment size* section, from the *Container size* list, select the appropriate size for the size of the model that you want to train or tune.
+
ifndef::upstream[]
For example, to run the example fine-tuning job described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/running-kfto-based-distributed-training-workloads_distributed-workloads#fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads[Fine-tuning a model by using Kubeflow Training], select *Medium*.
endif::[]
ifdef::upstream[]
For example, to run the example fine-tuning job described in link:{odhdocshome}/working-with-distributed-workloads/#fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads[Fine-tuning a model by using Kubeflow Training], select *Medium*.
endif::[]
.. In the *Cluster storage* section, click either *Attach existing storage* or *Create storage* to specify the storage details so that you can share data between the workbench and the training or tuning runs.
+
ifndef::upstream[]
For example, to run the example fine-tuning job described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/running-kfto-based-distributed-training-workloads_distributed-workloads#fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads[Fine-tuning a model by using Kubeflow Training], specify a storage class with ReadWriteMany (RWX) capability.
endif::[]
ifdef::upstream[]
For example, to run the example fine-tuning job described in link:{odhdocshome}/working-with-distributed-workloads/#fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads[Fine-tuning a model by using Kubeflow Training], specify a storage class with ReadWriteMany (RWX) capability.
endif::[]
.. Review the storage configuration and click *Create workbench*. 


.Verification
On the *Workbenches* tab, the status changes from *Starting* to *Running*.

[role='_additional-resources']
.Additional resources

ifndef::upstream[]
* link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/using-data-science-projects_projects#creating-a-data-science-project_projects[Creating a data science project]
* link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/using-project-workbenches_projects#creating-a-workbench-select-ide_projects[Creating a workbench and selecting an IDE]
* link:{rhoaidocshome}{default-format-url}/working_in_your_data_science_ide[Working in your data science IDE]
* link:https://access.redhat.com/articles/rhoai-supported-configs[{productname-long}: Supported Configurations] Knowledgebase article
endif::[]
ifdef::upstream[]
* link:{odhdocshome}/working-on-data-science-projects/#creating-a-data-science-project_projects[Creating a data science project]
* link:{odhdocshome}/working-on-data-science-projects/#creating-a-workbench-select-ide_projects[Creating a workbench and selecting an IDE]
* link:{odhdocshome}/working-in-your-data-science-ide[Working in your data science IDE]
endif::[]
