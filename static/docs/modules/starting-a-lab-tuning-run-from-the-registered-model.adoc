:_module-type: PROCEDURE

[id='starting-a-lab-tuning-run-from-the-registered-model_{context}']
= Starting a LAB-tuning run from the registered model

[role='_abstract']
After registering a base model, you can start a LAB-tuning run to create your customized large language model (LLM). When you configure the run, you will provide the following details:

* The Git repository URL for your taxonomy.
* The URLs where the teacher and judge models are deployed and the credentials needed to access them.
* The hardware profile to use for data generation, training, and evaluation.
* Any hyperparameters to apply to the tuning process.
* The location to store the LAB-tuned model and the credentials needed to access the storage location.

.Prerequisites
* You have logged in to {productname-short}.
ifndef::upstream[]
* Your cluster administrator has configured LAB-tuning in your cluster, as described in link:{rhoaidocshome}{default-format-url}/enabling_lab-tuning/index[Enabling LAB-tuning].
* You have access to an available model registry in your deployment.
* You have created your taxonomy, prepared an OCI storage location for the LAB-tuned model, created a data science project, and deployed teacher and judge models, as described in link:{rhoaidocshome}{default-format-url}/customizing_models_with_lab-tuning/preparing-lab-tuning-resources_lab-tuning[Preparing LAB-tuning resources].
* You have registered a base model with the `LAB starter` label from the model catalog, as described in link:{rhoaidocshome}{default-format-url}/customizing_models_with_lab-tuning/using-lab-tuning_lab-tuning#registering-a-base-model_lab-tuning[Registering a base model].

endif::[]
ifdef::upstream[]
* Your cluster administrator has configured LAB-tuning in your cluster, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#enabling-lab-tuning_lab-tuning[Enabling LAB-tuning].
* You have access to an available model registry in your deployment.
* You have created your taxonomy, prepared an OCI storage location for the LAB-tuned model, created a data science project, and deployed teacher and judge models, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#preparing-lab-tuning-resources_lab-tuning[Preparing LAB-tuning resources].
* You have registered a base model with the `LAB starter` label from the model catalog, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#registering-a-base-model[Registering a base model].
endif::[]

.Procedure
. From the {productname-short} dashboard, click *Models* -> *Model registry*.
+
The *Model registry* page opens.
. Click the name of the model you registered.
+
The details page for the registered model opens.
. On the *Versions* tab of the model details page, click the name of the version you want to LAB-tune.
+
The details page for the version opens.
. Review the version details.
. Click *LAB-tune*.
+
The *Start a LAB-tuning run* dialog opens.
. Select your project from the *Data science project* drop-down list.
. Click *Continue to run details*.
+
. The *Start a LAB-tuning run* page opens.
. Review the *Project details*, *Pipeline details*, and *Base model* sections for accuracy.
. In the *Taxonomy details* section, enter your *Taxonomy GIT URL*. 
. If your Git repository requires authentication, select either the *SSH key* or *Username and token* method and enter the appropriate credentials.
. In the *LAB teacher model* and *LAB judge model* sections, configure the following settings:
.. Select *Authenticated endpoint* if your model requires token authentication, otherwise select *Unauthenticated endpoint*. 
.. Enter the *Endpoint* ending with `/v1`. For example: `https://mixtral-my-project.apps.my-cluster.com/v1`
+
[TIP]
====
To find authentication details for your judge and teacher models, go to the *Models* tab of your data science project. For *Endpoint* and *Model name*, click *Internal and external endpoint details* for your model. For *Token*, expand the section for your model and find the *Token authentication* section.
====
.. Enter the *Model name*. 
.. If authenticated, enter the *Token*.
. In the *Training hardware* section, configure the following settings:
.. For *Hardware profile*, select a hardware profile to match the hardware requirements of your workload to available node resources. 
If project-scoped hardware profiles exist, the *Hardware profile* list includes subheadings to distinguish between global hardware profiles and project-scoped hardware profiles.
.. For *Training nodes*, enter the total number of nodes to use for the run. One node is used for the evaluation run phase.
.. For *Storage class*, select a storage class that is compatible with LAB-tuning and distributed training.
. Optional: In the *Hyperparameters* section, configure advanced settings for the run.
. In the *Fine-tuned model details* section, configure settings for the fine-tuned version of the base model:
.. For *Model output storage location*, select an *Existing connection* location to store the fine-tuned model output, or select *Create connection* to create a new connection.
.. For *OCI storage location* field, enter the full *Model URI* where the LAB-tuned model will be stored. For example: `oci://quay.io/my-org/fine-tuned-model-name:version`
+
The value of the URI is different from the connection. The connection provides access, while the URI defines the specific location.
. Select the *Add model to registry* checkbox so that you can store, share, version, and deploy the LAB-tuned model in the model registry.
.. For *Model version name*, enter a name for the new LAB-tuned model version.
. Click *Start run*.

.Verification
* The *Runs* page opens for the pipeline version.