"use strict";(self.webpackChunkopendatahub_io=self.webpackChunkopendatahub_io||[]).push([[894],{8884:function(t,e,i){i.d(e,{yZ:function(){return s},Bq:function(){return a}});var o=i(955),n="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2ODAuNzY0IiBoZWlnaHQ9IjUyOC4zNTQiIHZpZXdCb3g9IjAgMCAxODAuMTE5IDEzOS43OTQiPjxnIHRyYW5zZm9ybT0idHJhbnNsYXRlKC0xMy41OSAtNjYuNjM5KSIgcGFpbnQtb3JkZXI9ImZpbGwgbWFya2VycyBzdHJva2UiPjxwYXRoIGZpbGw9IiNkMGQwZDAiIGQ9Ik0xMy41OTEgNjYuNjM5SDE5My43MXYxMzkuNzk0SDEzLjU5MXoiLz48cGF0aCBkPSJtMTE4LjUwNyAxMzMuNTE0LTM0LjI0OSAzNC4yNDktMTUuOTY4LTE1Ljk2OC00MS45MzggNDEuOTM3SDE3OC43MjZ6IiBvcGFjaXR5PSIuNjc1IiBmaWxsPSIjZmZmIi8+PGNpcmNsZSBjeD0iNTguMjE3IiBjeT0iMTA4LjU1NSIgcj0iMTEuNzczIiBvcGFjaXR5PSIuNjc1IiBmaWxsPSIjZmZmIi8+PHBhdGggZmlsbD0ibm9uZSIgZD0iTTI2LjExMSA3Ny42MzRoMTUyLjYxNHYxMTYuMDk5SDI2LjExMXoiLz48L2c+PC9zdmc+";const s=[{title:"Installing Open Data Hub",slug:"/docs/installing-open-data-hub/"},{title:"Upgrading Open Data Hub",slug:"/docs/upgrading-open-data-hub/"},{title:"Getting started with Open Data Hub",slug:"/docs/getting-started-with-open-data-hub/"},{title:"Working on data science projects",slug:"/docs/working-on-data-science-projects/"},{title:"Working in your data science IDE",slug:"/docs/working-in-your-data-science-ide/"},{title:"Working with data science pipelines",slug:"/docs/working-with-data-science-pipelines/"},{title:"Serving models",slug:"/docs/serving-models/"},{title:"Customizing models with LAB-tuning",slug:"/docs/customizing-models-with-lab-tuning/"},{title:"Monitoring data science models",slug:"/docs/monitoring-data-science-models/"},{title:"Working with distributed workloads",slug:"/docs/working-with-distributed-workloads/"},{title:"Working with accelerators",slug:"/docs/working-with-accelerators/"},{title:"Working with connected applications",slug:"/docs/working-with-connected-applications/"},{title:"Working with data in an S3-compatible object store",slug:"/docs/working-with-data-in-s3-compatible-object-store/"},{title:"Working with model registries",slug:"/docs/working-with-model-registries/"},{title:"Working with RAG",slug:"/docs/working-with-rag/"},{title:"Managing Open Data Hub",slug:"/docs/managing-odh/"},{title:"Managing resources",slug:"/docs/managing-resources/"},{title:"Configuring Feature Store",slug:"/docs/configuring-feature-store/"},{title:"Architecture",slug:"/docs/architecture"},{title:"Tiered Components",slug:"/docs/tiered-components"},{title:"Roadmap",slug:"/docs/release-notes",children:[{title:"Release Notes",slug:"/docs/release-notes"},{title:"Future Releases",slug:"/docs/future"}]}],a=(o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,o.Z,{future:[{title:"Open Data Hub 1.8 (July 2023)",version:1.8,children:[{title:"ODH Operator"},{title:"ODH Dashboard"},{title:"Model Mesh"},{title:"TrustyAI Explainability"},{title:"Data Science Pipelines operator"},{title:"Distributed Workloads"}]}],past:[{title:"Open Data Hub 1.7 (June 2023)",version:1.7,children:[{title:"ODH Operator",description:"ODH Operator image now includes a local copy of the release version of the ODH Core deployment manifests that can be referenced from any supported kfdef"},{title:"ODH Dashboard",description:"Update to version v2.11"},{title:"Model Mesh"},{title:"TrustyAI Explainability"},{title:"Data Science Pipelines operator",description:"Update to version v1.0.0"},{title:"Distributed Workloads",description:"Upgrade to Project CodeFlare v0.0.4"}]},{title:"Open Data Hub 1.6 (May 2023)",version:1.6,children:[{title:"ODH Operator",description:"Default to the `rolling` OLM release channel and deprecate `stable`"},{title:"ODH Dashboard",description:"Upgrade to v2.9"},{title:"Model Mesh"},{title:"TrustyAI Explainability"},{title:"Data Science Pipelines operator",description:"Upgrade to v0.2.0"},{title:"Distributed Workloads",description:"Incubation of the Distributed Workloads stack supporting the CodeFlare SDK"}]},{title:"Open Data Hub 1.5 (April 2023)",version:1.5,children:[{title:"ODH Operator",description:"Migration to the operator-sdk 1.24"},{title:"Model Mesh",description:"Update to v0.11.0"},{title:"TrustyAI Explainability"},{title:"Jupyter Notebooks",description:"Add Python 3.8 / 3.9 versions of all notebook images"},{title:"ODH Dashboard Model Serving UI",description:"Add intial UI support for the new Model Serving stack"},{title:"Data Science Pipelines operator",description:"Adds support for namespace isolation of Data Science Pipelines"}]},{title:"Open Data Hub 1.4 - (October 2022)",version:1.4,children:[{title:"Model Serving",description:"Updates to the etcd and minio setups"},{title:"Support for ODH Notebook Controller"},{title:"ODH Dashboard Admin UI and Notebook Controller backend",description:"Add UI support for admin configurations"},{title:"Deployment of Data Science Pipelines based on Kubeflow Pipelines (Tekton)"},{title:"ODH Re-architecture - Phase 1",description:'Categorize existing components (as of ODH v1.3.0) into support Tiers for updates/deprecation and designate maintainers Tiered approach <br> - Tier 0 - ODH Core <br> - Tier 1 - Long Term community support with assigned MAINTAINERS and full test suite <br> - Tier 2 - Any components in the <a href="https://github.com/opendatahub-io-contrib" >opendatahub-io-contrib</a> org that are not included in the ODH Core deployment but maintain ODH integrations of interest to the community<br>'}]},{title:"Open Data Hub 1.3 - (May/June 2022)",version:1.3,children:[{title:"Tutorials and website cleanup",url:"https://github.com/opendatahub-io/opendatahub.io/projects/1"},{title:"Dashboard updates",url:"https://github.com/opendatahub-io/odh-dashboard/projects/2",description:"Admin -  Bring your own notebooks+ Cluster Settings"},{title:"Bring your own notebooks",description:"Allow admins the flexibility to provide to users their own notebook images"},{title:"Model Serving",description:"Implementation of Model Mesh using Oauth"},{title:"Community governance model",url:"https://github.com/opendatahub-io/opendatahub-community/issues/11"},{title:"Kubeflow 1.5 support",url:"https://github.com/opendatahub-io/manifests/projects/2",description:"Includes ability to install Kubeflow v1.5.0 components on OpenShift <br> Support for the integration of Service Mesh with Kubeflow v1.5 on OpenShift"}]},{title:"Open Data Hub 1.2 - Q4 2021",version:1.2,children:[{title:"JupyterHub Custom Notebooks User Interface improvement",description:"Add User Interface elements for users to enter new custom notebook images"},{title:"Kubeflow 1.3 on OCP 4.6/4.7/4.8",description:"Enable Kubeflow 1.3 on OCP 4.6/4.7/4.8 by resolving all issues.",url:"https://github.com/kubeflow/manifests/issues/1895"},{title:"Kubeflow integration with Red Hat Service Mesh.",description:"Replace Istio stack with Red Hat Serivce Mesh in Kubeflow"},{title:"ODH and KF authentication architecture.",description:"Architect an integrated authentication solution for ODH and KF."},{title:"KF 1.3.1 OCP Stack update.",description:"This includes updating the Kubeflow 1.3.1 openshift stack to work on OCP 4.4+"}]},{title:"Open Data Hub 1.1 - July 2021",version:1.1,children:[{title:"Kubeflow 1.3",description:"Update the Openshift Kubeflow distribution to Kubeflow version 1.3",url:"https://github.com/kubeflow/manifests/tree/v1.3.0/distributions/stacks/openshift"},{title:"Openshift Pipelines",description:"Installation of Red Hat OpenShift Pipelines along with all of the required custom resources to enable a workflow supported by Tekton pipelines"},{title:"Trino",description:"Trino is a fast distributed SQL query engine that can integrate with multiple data sources such as S3, SQL databases, and NoSQL databases"},{title:"JupyterHub",description:"Updates include new Spawner user interface,ability to customize and specify JupyterHub PostgreSQL parameters and new notebook images with JupyterLab."},{title:"Open Data Hub operator",description:"Updates include support for Operator Level 4 (Deep Insights), new Prometheus metrics collection, new Grafana Dashboard and new status field to reflect operator installation status."},{title:"Open Data Hub Dashboard",description:"Integrated with Openshift Authentication to access the dashboard."}]},{title:"Open Data Hub 1.0 - January 2021",version:1,url:"https://github.com/orgs/opendatahub-io/projects/12",children:[{title:"ODH Data Catalog",description:"Migrate Open Data Hub Data Catalog component from Ansible to Kustomize.",url:"https://github.com/opendatahub-io/odh-manifests/issues/222"},{title:"Kubeflow KFServing",description:"Enable KFServing in Open Data Hub.",url:"https://github.com/opendatahub-io/manifests/issues/63"},{title:"Kubeflow Pipelines on Tekton",description:"Enable Kubeflow Pipelines using Tekton in Open Data Hub."},{title:"Disconnected Deployment",description:"Investigate and introduce ability to deploy ODH on disconnected OpenShift clusters.",url:"https://github.com/opendatahub-io/odh-manifests/issues/15"},{title:"JupyterHub Spawner UI Rearchitecture",description:"Replace existing static HTML spawner UI with dynamic React base one which will allow for more customization and easier extensabiliy.",url:"https://github.com/opendatahub-io/odh-manifests/issues/146"}]},{title:"Open Data Hub 0.9 - End of October 2020",version:.9,url:"https://github.com/orgs/opendatahub-io/projects/11",children:[{title:"Kubeflow 1.2",description:"Add OpenShift stack in Kubeflow 1.2 to achieve release sync between ODH and KF",url:"https://github.com/opendatahub-io/manifests/issues/54"},{title:"Disconnected Deployment",moved:1,description:"Investigate and introduce ability to deploy ODH on disconnected OpenShift clusters.",url:"https://github.com/opendatahub-io/odh-manifests/issues/15"},{title:"UBI based KF",moved:"1.1+",description:'Continuation of the "UBI based ODH" expanding to Kubeflow project and looking at what does it take to move Kubeflow components to UBI.'},{title:"CI/CD",description:"Continuation of the of the effort to design and create a complete CI/CD process."},{title:"Object Storage",description:"Add an Object Storage tool based on Rook-Ceph",url:"https://github.com/opendatahub-io/odh-manifests/issues/149"},{title:"Enable Monitoring",description:"Continuation of the effort to enable Prometheus enpoints in all Open Data Hub and Kubeflow components."},{title:"Open Data Hub Dashboard",description:"Team is currently creating an Open Data Hub dashboard that will be the entry point to all installed components.",url:"https://github.com/opendatahub-io/odh-manifests/issues/186"},{title:"Notebooks to Pipelines with Elyra",description:"Added a JupyterLab notebook image that includes Elyra. Elyra converts notebooks to Argo or Kubeflow pipelines.",url:"https://github.com/opendatahub-io/odh-manifests/pull/171"}]},{title:"Open Data Hub 0.8 - End of August 2020",version:.8,url:"https://github.com/orgs/opendatahub-io/projects/8",children:[{title:"ODH JupyterHub",description:"Forked JupyterHub repos under Open Data Hub github repo for maintaining new changes. Added notebook images to Thoth Station for building. Added ability to launch JupyterLab images."},{title:"Notebooks to Pipelines with Elyra",description:"Added a JupyterLab notebook image that includes Elyra. Elyra converts notebooks to Argo or Kubeflow pipelines.",url:"https://github.com/opendatahub-io/odh-manifests/pull/171",moved:.9},{title:"Mixing ODH & KF components- Distributed Training",description:"Added Pytorch operator to work with Open Data Hub components.",url:"https://github.com/opendatahub-io/odh-manifests/issues/147"},{title:"Mixing ODH & KF components- Kubeflow Monitoring",description:"Added monitoring to Kubeflow components by enabling monitoring to Argo and adding Prometheus and Grafana to Kubeflow installation."},{title:"CI/CD",description:"Added more tests to Open Data Hub components including Kafka and Superset and enhanced JupyterHub testing by adding Selenium for web portal testing"}]},{title:"Open Data Hub 0.7 - End of June 2020",version:.7,children:[{title:"KF 1.0 on OpenShift",description:"The main goal of this initiative is to verify Kubeflow 1.0 works on OpenShift and fix the issues we find. Another goal is to document and ideally automate some of the verification process to start enabling the CI for KF on OpenSHift."},{title:"CI improvements",description:"Extending tests for all components, enabling CI for the operator repository."},{title:"Mixing ODH & KF components (start)",description:"Proving users can mix ODH and KF components, compiling a prioritized list of components to be verified and fixed, proving on the first component (probably TF Job or Pytorch Job)"},{title:"Add Object Storage Component",moved:.9,url:"https://github.com/opendatahub-io/odh-manifests/issues/104",description:"Since ODH relies on S3 compatible object storage, add dependency on some minimal install of OpenShift Container Storage."},{title:"Convert Data Catalog to Kustomize",moved:1,url:"https://github.com/opendatahub-io/odh-manifests/issues/105",description:"Data Catalog is the last component missing the conversion to Kustomize."}]},{title:"Open Data Hub 0.6 - End of April 2020",version:.6,children:[{title:"Rebase ODH on KF operator",description:"Use Kubeflow operator as a base for ODH."},{title:"Convert ODH components to Kustomize",description:"Convert all ODH components to Kustomize to match Kubeflow deployment tooling."},{title:"Start CI for ODH",description:"Investicate and kickstart ODH CI based on OpenShift CI"},{title:"Move to Github",description:"Since the goal of this release is to get closer to KF community, we need to move to Github"},{title:"Add Apache Airflow",description:"Add Apache Airflow as a component into Open Data Hub"}]}]})}}]);
//# sourceMappingURL=c98acbd45c10d19891d35500d37f69e459ec76aa-4d025d762424bff3a1c7.js.map