{"componentChunkName":"component---src-templates-docs-page-tsx","path":"/docs/managing-resources/","result":{"data":{"allFile":{"edges":[{"node":{"childAsciidoc":{"fields":{"slug":"/docs/README/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/api-workbench/"},"sections":[{"parentId":null,"name":"Overview","level":1,"index":0,"id":"api-workbench-overview_api-workbench"},{"parentId":null,"name":"Creating a custom image by using the <code>ImageStream</code> CRD","level":1,"index":1,"id":"api-custom-image-creating_api-workbench"},{"parentId":null,"name":"Creating a workbench by using the <code>Notebook</code> CRD","level":1,"index":2,"id":"api-workbench-creating_api-workbench"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/configuring-feature-store/"},"sections":[{"parentId":null,"name":"Overview of machine learning features and Feature Store","level":1,"index":0,"id":"overview-of-features-and-feature-store_featurestore"},{"parentId":"overview-of-features-and-feature-store_featurestore","name":"Overview of machine learning features","level":2,"index":0,"id":"_overview_of_machine_learning_features"},{"parentId":"overview-of-features-and-feature-store_featurestore","name":"Overview of Feature Store","level":2,"index":1,"id":"_overview_of_feature_store"},{"parentId":"overview-of-features-and-feature-store_featurestore","name":"Audience for Feature Store","level":2,"index":2,"id":"_audience_for_feature_store"},{"parentId":null,"name":"Before you begin","level":1,"index":1,"id":"before-you-begin_featurestore"},{"parentId":null,"name":"Enabling the Feature Store component","level":1,"index":2,"id":"enabling-the-feature-store-component_featurestore"},{"parentId":null,"name":"Deploying a feature store instance in a data science project","level":1,"index":3,"id":"deploying-a-feature-store-instance-in-a-data-science-project_featurestore"},{"parentId":null,"name":"Customizing your feature store configuration","level":1,"index":4,"id":"customizing-your-feature-store-configuration_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Specifying to use a feature project from a Git repository","level":2,"index":0,"id":"specifying-to-use-a-feature-project-from-git-repository_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring an offline store","level":2,"index":1,"id":"configuring-an-offline-store_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring an online store","level":2,"index":2,"id":"configuring-an-online-store_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring the feature registry","level":2,"index":3,"id":"configuring-the-feature-registry_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Example PVC configuration","level":2,"index":4,"id":"ref-example-pvc-configuration_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring role-based access control","level":2,"index":5,"id":"configuring-role-based-access-control_featurestore"},{"parentId":"configuring-role-based-access-control_featurestore","name":"Default authorization configuration","level":3,"index":0,"id":"ref-default-authorization-configuration_featurestore"},{"parentId":"configuring-role-based-access-control_featurestore","name":"Example OIDC Authorization configuration","level":3,"index":1,"id":"ref-example-oidc-authorization-configuration_featurestore"},{"parentId":"configuring-role-based-access-control_featurestore","name":"Example Kubernetes Authorization configuration","level":3,"index":2,"id":"ref-example-kubernetes-authorization-configuration_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Editing an existing feature store instance","level":2,"index":6,"id":"editing-an-existing-feature-store-instance_featurestore"},{"parentId":null,"name":"Viewing feature store objects in the web-based UI","level":1,"index":5,"id":"viewing-feature-store-objects-in-the-web-based-ui_featurestore"},{"parentId":null,"name":"Additional resources","level":1,"index":6,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/customizing-models-with-lab-tuning/"},"sections":[{"parentId":null,"name":"Enabling LAB-tuning","level":1,"index":0,"id":"enabling-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Overview of enabling LAB-tuning","level":2,"index":0,"id":"overview-of-enabling-lab-tuning_lab-tuning"},{"parentId":"overview-of-enabling-lab-tuning_lab-tuning","name":"Requirements for LAB-tuning","level":3,"index":0,"id":"_requirements_for_lab_tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Installing the required Operators for LAB-tuning","level":2,"index":1,"id":"installing-the-required-operators-for-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Installing the required components for LAB-tuning","level":2,"index":2,"id":"installing-the-required-components-for-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Configuring a storage class for LAB-tuning","level":2,"index":3,"id":"configuring-a-storage-class-for-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Making LAB-tuning and hardware profile features visible","level":2,"index":4,"id":"making-lab-tuning-and-hardware-profile-features-visible_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Creating a model registry for LAB-tuning","level":2,"index":5,"id":"creating-a-model-registry-for-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Creating a hardware profile for LAB-tuning","level":2,"index":6,"id":"creating-a-hardware-profile-for-lab-tuning_lab-tuning"},{"parentId":null,"name":"Overview of LAB-tuning","level":1,"index":1,"id":"overview-of-lab-tuning_lab-tuning"},{"parentId":"overview-of-lab-tuning_lab-tuning","name":"LAB-tuning workflow","level":2,"index":0,"id":"_lab_tuning_workflow"},{"parentId":"overview-of-lab-tuning_lab-tuning","name":"Model customization page","level":2,"index":1,"id":"_model_customization_page"},{"parentId":null,"name":"Preparing LAB-tuning resources","level":1,"index":2,"id":"preparing-lab-tuning-resources_lab-tuning"},{"parentId":"preparing-lab-tuning-resources_lab-tuning","name":"Creating a taxonomy","level":2,"index":0,"id":"creating-a-taxonomy_lab-tuning"},{"parentId":"preparing-lab-tuning-resources_lab-tuning","name":"Preparing a storage location for the LAB-tuned model","level":2,"index":1,"id":"preparing-a-storage-location-for-the-lab-tuned-model_lab-tuning"},{"parentId":"preparing-lab-tuning-resources_lab-tuning","name":"Creating a project for LAB-tuning","level":2,"index":2,"id":"creating-a-project-for-lab-tuning_lab-tuning"},{"parentId":"preparing-lab-tuning-resources_lab-tuning","name":"Deploying teacher and judge models","level":2,"index":3,"id":"deploying-teacher-and-judge-models_lab-tuning"},{"parentId":null,"name":"Using LAB-tuning","level":1,"index":3,"id":"using-lab-tuning_lab-tuning"},{"parentId":"using-lab-tuning_lab-tuning","name":"Registering a base model","level":2,"index":0,"id":"registering-a-base-model_lab-tuning"},{"parentId":"using-lab-tuning_lab-tuning","name":"Starting a LAB-tuning run from the registered model","level":2,"index":1,"id":"starting-a-lab-tuning-run-from-the-registered-model_lab-tuning"},{"parentId":"using-lab-tuning_lab-tuning","name":"Monitoring your LAB-tuning run","level":2,"index":2,"id":"monitoring-your-lab-tuning-run_lab-tuning"},{"parentId":"using-lab-tuning_lab-tuning","name":"Reviewing and deploying your LAB-tuned model","level":2,"index":3,"id":"reviewing-and-deploying-your-lab-tuned-model_lab-tuning"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/getting-started-with-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview","level":1,"index":0,"id":"overview-for-getting-started_get-started"},{"parentId":"overview-for-getting-started_get-started","name":"Data science workflow","level":2,"index":0,"id":"_data_science_workflow"},{"parentId":"overview-for-getting-started_get-started","name":"About this guide","level":2,"index":1,"id":"_about_this_guide"},{"parentId":"overview-for-getting-started_get-started","name":"Glossary of common terms","level":2,"index":2,"id":"glossary-of-common-terms_get-started"},{"parentId":null,"name":"Logging in to Open Data Hub","level":1,"index":1,"id":"logging-in_get-started"},{"parentId":"logging-in_get-started","name":"Viewing installed Open Data Hub components","level":2,"index":0,"id":"viewing-installed-components_get-started"},{"parentId":null,"name":"Creating a data science project","level":1,"index":2,"id":"creating-a-data-science-project_get-started"},{"parentId":null,"name":"Creating a workbench and selecting an IDE","level":1,"index":3,"id":"creating-a-workbench-select-ide_get-started"},{"parentId":"creating-a-workbench-select-ide_get-started","name":"About workbench images","level":2,"index":0,"id":"about-workbench-images_get-started"},{"parentId":"creating-a-workbench-select-ide_get-started","name":"Creating a workbench","level":2,"index":1,"id":"creating-a-project-workbench_get-started"},{"parentId":null,"name":"Next steps","level":1,"index":4,"id":"next-steps_get-started"},{"parentId":"next-steps_get-started","name":"Additional resources","level":2,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/installing-open-data-hub/"},"sections":[{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":0,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Configuring custom namespaces","level":2,"index":0,"id":"configuring-custom-namespaces"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":2,"id":"installing-odh-components_installv2"},{"parentId":null,"name":"Installing Open Data Hub version 1","level":1,"index":1,"id":"installing-odh-v1_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Installing the Open Data Hub Operator version 1","level":2,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Creating a new project for your Open Data Hub instance","level":2,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Adding an Open Data Hub instance","level":2,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Accessing the Open Data Hub dashboard","level":2,"index":3,"id":"accessing-the-odh-dashboard_installv1"},{"parentId":null,"name":"Installing the distributed workloads components","level":1,"index":2,"id":"installing-the-distributed-workloads-components_install"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":3,"id":"accessing-the-odh-dashboard_install"},{"parentId":null,"name":"Working with certificates","level":1,"index":4,"id":"working-with-certificates_certs"},{"parentId":"working-with-certificates_certs","name":"Understanding how Open Data Hub handles certificates","level":2,"index":0,"id":"understanding-certificates_certs"},{"parentId":"working-with-certificates_certs","name":"Adding certificates","level":2,"index":1,"id":"_adding_certificates"},{"parentId":"working-with-certificates_certs","name":"Adding certificates to a cluster-wide CA bundle","level":2,"index":2,"id":"adding-certificates-to-a-cluster-ca-bundle_certs"},{"parentId":"working-with-certificates_certs","name":"Adding certificates to a custom CA bundle","level":2,"index":3,"id":"adding-certificates-to-a-custom-ca-bundle_certs"},{"parentId":"working-with-certificates_certs","name":"Using self-signed certificates with Open Data Hub components","level":2,"index":4,"id":"_using_self_signed_certificates_with_open_data_hub_components"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Accessing S3-compatible object storage with self-signed certificates","level":3,"index":0,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Configuring a certificate for data science pipelines","level":3,"index":1,"id":"configuring-a-certificate-for-pipelines_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Configuring a certificate for workbenches","level":3,"index":2,"id":"configuring-a-certificate-for-workbenches_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Using the cluster-wide CA bundle for the single-model serving platform","level":3,"index":3,"id":"using-the-cluster-CA-bundle-for-single-model-serving_certs"},{"parentId":"working-with-certificates_certs","name":"Managing certificates without the Open Data Hub Operator","level":2,"index":5,"id":"managing-certificates-without-the-operator_certs"},{"parentId":"working-with-certificates_certs","name":"Removing the CA bundle","level":2,"index":6,"id":"_removing_the_ca_bundle"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from all namespaces","level":3,"index":0,"id":"removing-the-ca-bundle-from-all-namespaces_certs"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from a single namespace","level":3,"index":1,"id":"removing-the-ca-bundle-from-a-single-namespace_certs"},{"parentId":null,"name":"Viewing logs and audit records","level":1,"index":5,"id":"viewing-logs-and-audit-records_install"},{"parentId":"viewing-logs-and-audit-records_install","name":"Configuring the Open Data Hub Operator logger","level":2,"index":0,"id":"configuring-the-operator-logger_install"},{"parentId":"configuring-the-operator-logger_install","name":"Viewing the Open Data Hub Operator logs","level":3,"index":0,"id":"_viewing_the_open_data_hub_operator_logs"},{"parentId":"viewing-logs-and-audit-records_install","name":"Viewing audit records","level":2,"index":1,"id":"viewing-audit-records_install"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-odh/"},"sections":[{"parentId":null,"name":"Managing users and groups","level":1,"index":0,"id":"managing-users-and-groups"},{"parentId":"managing-users-and-groups","name":"Overview of user types and permissions","level":2,"index":0,"id":"overview-of-user-types-and-permissions_managing-odh"},{"parentId":"managing-users-and-groups","name":"Viewing Open Data Hub users","level":2,"index":1,"id":"viewing-data-science-users_managing-odh"},{"parentId":"managing-users-and-groups","name":"Adding users to Open Data Hub user groups","level":2,"index":2,"id":"adding-users-to-user-groups_managing-odh"},{"parentId":"managing-users-and-groups","name":"Selecting Open Data Hub administrator and user groups","level":2,"index":3,"id":"selecting-admin-and-user-groups_managing-odh"},{"parentId":"managing-users-and-groups","name":"Deleting users","level":2,"index":4,"id":"_deleting_users"},{"parentId":"_deleting_users","name":"About deleting users and their resources","level":3,"index":0,"id":"about-deleting-users-and-resources_managing-odh"},{"parentId":"_deleting_users","name":"Stopping basic workbenches owned by other users","level":3,"index":1,"id":"stopping-basic-workbenches-owned-by-other-users_managing-odh"},{"parentId":"_deleting_users","name":"Revoking user access to basic workbenches","level":3,"index":2,"id":"revoking-user-access-to-basic-workbenches_managing-odh"},{"parentId":"_deleting_users","name":"Backing up storage data","level":3,"index":3,"id":"backing-up-storage-data_managing-odh"},{"parentId":"_deleting_users","name":"Cleaning up after deleting users","level":3,"index":4,"id":"cleaning-up-after-deleting-users_managing-odh"},{"parentId":null,"name":"Creating custom workbench images","level":1,"index":1,"id":"creating-custom-workbench-images"},{"parentId":"creating-custom-workbench-images","name":"Creating a custom image from a default Open Data Hub image","level":2,"index":0,"id":"creating-a-custom-image-from-default-image_custom-images"},{"parentId":"creating-custom-workbench-images","name":"Creating a custom image from your own image","level":2,"index":1,"id":"creating-a-custom-image-from-your-own-image_custom-images"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Basic guidelines for creating your own workbench image","level":3,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Advanced guidelines for creating your own workbench image","level":3,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-custom-workbench-images","name":"Enabling custom images in Open Data Hub","level":2,"index":2,"id":"enabling-custom-images_custom-images"},{"parentId":"creating-custom-workbench-images","name":"Importing a custom workbench image","level":2,"index":3,"id":"importing-a-custom-workbench-image_custom-images"},{"parentId":null,"name":"Managing applications that show in the dashboard","level":1,"index":2,"id":"managing-applications-that-show-in-the-dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Adding an application to the dashboard","level":2,"index":0,"id":"adding-an-application-to-the-dashboard_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Preventing users from adding applications to the dashboard","level":2,"index":1,"id":"preventing-users-from-adding-applications-to-the-dashboard_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Disabling applications connected to Open Data Hub","level":2,"index":2,"id":"disabling-applications-connected_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Showing or hiding information about available applications","level":2,"index":3,"id":"showing-hiding-information-about-available-applications_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Hiding the default basic workbench application","level":2,"index":4,"id":"hiding-the-default-basic-workbench-application_dashboard"},{"parentId":null,"name":"Creating project-scoped resources","level":1,"index":3,"id":"creating-project-scoped-resources_managing-odh"},{"parentId":null,"name":"Allocating additional resources to Open Data Hub users","level":1,"index":4,"id":"allocating-additional-resources-to-data-science-users_managing-odh"},{"parentId":null,"name":"Customizing component deployment resources","level":1,"index":5,"id":"customizing-component-deployment-resources_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Overview of component resource customization","level":2,"index":0,"id":"overview-of-component-resource-customization_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Customizing component resources","level":2,"index":1,"id":"customizing-component-resources_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Disabling component resource customization","level":2,"index":2,"id":"disabling-component-resource-customization_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Re-enabling component resource customization","level":2,"index":3,"id":"reenabling-component-resource-customization_managing-resources"},{"parentId":null,"name":"Enabling accelerators","level":1,"index":6,"id":"_enabling_accelerators"},{"parentId":"_enabling_accelerators","name":"Enabling NVIDIA GPUs","level":2,"index":0,"id":"enabling-nvidia-gpus_managing-odh"},{"parentId":"_enabling_accelerators","name":"Intel Gaudi AI Accelerator integration","level":2,"index":1,"id":"intel-gaudi-ai-accelerator-integration_managing-odh"},{"parentId":"intel-gaudi-ai-accelerator-integration_managing-odh","name":"Enabling Intel Gaudi AI accelerators","level":3,"index":0,"id":"enabling-intel-gaudi-ai-accelerators_managing-odh"},{"parentId":"_enabling_accelerators","name":"AMD GPU Integration","level":2,"index":2,"id":"amd-gpu-integration_managing-odh"},{"parentId":"amd-gpu-integration_managing-odh","name":"Verifying AMD GPU availability on your cluster","level":3,"index":0,"id":"verifying-amd-gpu-availability-on-your-cluster_managing-odh"},{"parentId":"amd-gpu-integration_managing-odh","name":"Enabling AMD GPUs","level":3,"index":1,"id":"enabling-amd-gpus_managing-odh"},{"parentId":null,"name":"Managing distributed workloads","level":1,"index":7,"id":"managing-distributed-workloads_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Overview of Kueue resources","level":2,"index":0,"id":"overview-of-kueue-resources_managing-odh"},{"parentId":"overview-of-kueue-resources_managing-odh","name":"Resource flavor","level":3,"index":0,"id":"_resource_flavor"},{"parentId":"overview-of-kueue-resources_managing-odh","name":"Cluster queue","level":3,"index":1,"id":"_cluster_queue"},{"parentId":"overview-of-kueue-resources_managing-odh","name":"Local queue","level":3,"index":2,"id":"_local_queue"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Example Kueue resource configurations","level":2,"index":1,"id":"ref-example-kueue-resource-configurations_managing-odh"},{"parentId":"ref-example-kueue-resource-configurations_managing-odh","name":"NVIDIA GPUs without shared cohort","level":3,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":4,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":4,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":4,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":4,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":"ref-example-kueue-resource-configurations_managing-odh","name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":3,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":4,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":4,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":4,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":4,"index":3,"id":"_nvidia_gpu_cluster_queue"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Configuring quota management for distributed workloads","level":2,"index":2,"id":"configuring-quota-management-for-distributed-workloads_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Enforcing the use of local queues","level":2,"index":3,"id":"enforcing-local-queues_managing-odh"},{"parentId":"enforcing-local-queues_managing-odh","name":"Enforcing the local-queue labeling policy for all projects","level":3,"index":0,"id":"enforcing-lqlabel-all_managing-odh"},{"parentId":"enforcing-local-queues_managing-odh","name":"Disabling the local-queue labeling policy for all projects","level":3,"index":1,"id":"disabling-lqlabel-all_managing-odh"},{"parentId":"enforcing-local-queues_managing-odh","name":"Enforcing the local-queue labeling policy for some projects only","level":3,"index":2,"id":"enforcing-lqlabel-some_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Configuring the CodeFlare Operator","level":2,"index":4,"id":"configuring-the-codeflare-operator_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Configuring a cluster for RDMA","level":2,"index":5,"id":"configuring-a-cluster-for-rdma_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Troubleshooting common problems with distributed workloads for administrators","level":2,"index":6,"id":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster is in a suspended state","level":3,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster is in a failed state","level":3,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user receives a \"failed to call webhook\" error message for the CodeFlare Operator","level":3,"index":2,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user receives a \"failed to call webhook\" error message for Kueue","level":3,"index":3,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster does not start","level":3,"index":4,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message","level":3,"index":5,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user receives a <strong>local_queue provided does not exist</strong> error message","level":3,"index":6,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user cannot create a Ray cluster or submit jobs","level":3,"index":7,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled","level":3,"index":8,"id":"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled"},{"parentId":null,"name":"Backing up data","level":1,"index":8,"id":"_backing_up_data"},{"parentId":"_backing_up_data","name":"Backing up storage data","level":2,"index":0,"id":"backing-up-storage-data_managing-odh"},{"parentId":"_backing_up_data","name":"Backing up your cluster","level":2,"index":1,"id":"backing-up-your-cluster_managing-odh"},{"parentId":null,"name":"Viewing logs and audit records","level":1,"index":9,"id":"viewing-logs-and-audit-records_managing-odh"},{"parentId":"viewing-logs-and-audit-records_managing-odh","name":"Configuring the Open Data Hub Operator logger","level":2,"index":0,"id":"configuring-the-operator-logger_managing-odh"},{"parentId":"configuring-the-operator-logger_managing-odh","name":"Viewing the Open Data Hub Operator logs","level":3,"index":0,"id":"_viewing_the_open_data_hub_operator_logs"},{"parentId":"viewing-logs-and-audit-records_managing-odh","name":"Viewing audit records","level":2,"index":1,"id":"viewing-audit-records_managing-odh"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-resources/"},"sections":[{"parentId":null,"name":"Selecting Open Data Hub administrator and user groups","level":1,"index":0,"id":"selecting-admin-and-user-groups_managing-resources"},{"parentId":null,"name":"Customizing the dashboard","level":1,"index":1,"id":"customizing-the-dashboard"},{"parentId":"customizing-the-dashboard","name":"Editing the dashboard configuration","level":2,"index":0,"id":"editing-the-dashboard-configuration_dashboard"},{"parentId":"customizing-the-dashboard","name":"Dashboard configuration options","level":2,"index":1,"id":"ref-dashboard-configuration-options_dashboard"},{"parentId":null,"name":"Importing a custom workbench image","level":1,"index":2,"id":"importing-a-custom-workbench-image_managing-resources"},{"parentId":null,"name":"Managing cluster PVC size","level":1,"index":3,"id":"managing-cluster-pvc-size"},{"parentId":"managing-cluster-pvc-size","name":"Configuring the default PVC size for your cluster","level":2,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":"managing-cluster-pvc-size","name":"Restoring the default PVC size for your cluster","level":2,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":null,"name":"Managing connection types","level":1,"index":4,"id":"managing-connection-types"},{"parentId":"managing-connection-types","name":"Viewing connection types","level":2,"index":0,"id":"viewing-connection-types_managing-resources"},{"parentId":"managing-connection-types","name":"Creating a connection type","level":2,"index":1,"id":"creating-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Duplicating a connection type","level":2,"index":2,"id":"duplicating-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Editing a connection type","level":2,"index":3,"id":"editing-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Enabling a connection type","level":2,"index":4,"id":"enabling-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Deleting a connection type","level":2,"index":5,"id":"deleting-a-connection-type_managing-resources"},{"parentId":null,"name":"Managing storage classes","level":1,"index":5,"id":"managing-storage-classes"},{"parentId":"managing-storage-classes","name":"About persistent storage","level":2,"index":0,"id":"about-persistent-storage_managing-resources"},{"parentId":"about-persistent-storage_managing-resources","name":"Storage classes in Open Data Hub","level":3,"index":0,"id":"_storage_classes_in_open_data_hub"},{"parentId":"about-persistent-storage_managing-resources","name":"Access modes","level":3,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":4,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":"managing-storage-classes","name":"Configuring storage class settings","level":2,"index":1,"id":"configuring-storage-class-settings_managing-resources"},{"parentId":"managing-storage-classes","name":"Configuring the default storage class for your cluster","level":2,"index":2,"id":"configuring-the-default-storage-class-for-your-cluster_managing-resources"},{"parentId":"managing-storage-classes","name":"Overview of object storage endpoints","level":2,"index":3,"id":"overview-of-object-storage-endpoints_managing-resources"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"MinIO (On-Cluster)","level":3,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Amazon S3","level":3,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Other S3-Compatible Object Stores","level":3,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Verification and Troubleshooting","level":3,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Managing basic workbenches","level":1,"index":6,"id":"managing-basic-workbenches"},{"parentId":"managing-basic-workbenches","name":"Accessing the administration interface for basic workbenches","level":2,"index":0,"id":"accessing-the-administration-interface-for-basic-workbenches_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Starting basic workbenches owned by other users","level":2,"index":1,"id":"starting-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Accessing basic workbenches owned by other users","level":2,"index":2,"id":"accessing-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Stopping basic workbenches owned by other users","level":2,"index":3,"id":"stopping-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Stopping idle workbenches","level":2,"index":4,"id":"stopping-idle-workbenches_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Adding workbench pod tolerations","level":2,"index":5,"id":"adding-workbench-pod-tolerations_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Troubleshooting common problems in workbenches for administrators","level":2,"index":6,"id":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":3,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"A user&#8217;s workbench does not start","level":3,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":3,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/monitoring-data-science-models/"},"sections":[{"parentId":null,"name":"Overview of model monitoring","level":1,"index":0,"id":"overview-of-model-monitoring_monitor"},{"parentId":null,"name":"Configuring TrustyAI","level":1,"index":1,"id":"configuring-trustyai_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Configuring monitoring for your model serving platform","level":2,"index":0,"id":"configuring-monitoring-for-your-model-serving-platform_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Enabling the TrustyAI component","level":2,"index":1,"id":"enabling-trustyai-component_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Configuring TrustyAI with a database","level":2,"index":2,"id":"configuring-trustyai-with-a-database_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Installing the TrustyAI service for a project","level":2,"index":3,"id":"installing-trustyai-service_monitor"},{"parentId":"installing-trustyai-service_monitor","name":"Installing the TrustyAI service by using the dashboard","level":3,"index":0,"id":"installing-trustyai-service-using-dashboard_monitor"},{"parentId":"installing-trustyai-service_monitor","name":"Installing the TrustyAI service by using the CLI","level":3,"index":1,"id":"installing-trustyai-service-using-cli_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Enabling TrustyAI Integration with standard model deployment","level":2,"index":4,"id":"enabling-trustyai-kserve-integration_monitor"},{"parentId":null,"name":"Setting up TrustyAI for your project","level":1,"index":2,"id":"setting-up-trustyai-for-your-project_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Authenticating the TrustyAI service","level":2,"index":0,"id":"authenticating-trustyai-service_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Uploading training data to TrustyAI","level":2,"index":1,"id":"uploading-training-data-to-trustyai_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Sending training data to TrustyAI","level":2,"index":2,"id":"sending-training-data-to-trustyai_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Labeling data fields","level":2,"index":3,"id":"labeling-data-fields_monitor"},{"parentId":null,"name":"Monitoring model bias","level":1,"index":3,"id":"monitoring-model-bias_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Creating a bias metric","level":2,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":3,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":3,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Duplicating a bias metric","level":3,"index":2,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Deleting a bias metric","level":2,"index":1,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":3,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":3,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Viewing bias metrics for a model","level":2,"index":2,"id":"viewing-bias-metrics_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Using bias metrics","level":2,"index":3,"id":"using-bias-metrics_bias-monitoring"},{"parentId":null,"name":"Monitoring data drift","level":1,"index":4,"id":"monitoring-data-drift_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Creating a drift metric","level":2,"index":0,"id":"creating-a-drift-metric_drift-monitoring"},{"parentId":"creating-a-drift-metric_drift-monitoring","name":"Creating a drift metric by using the CLI","level":3,"index":0,"id":"creating-a-drift-metric-using-cli_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Deleting a drift metric by using the CLI","level":2,"index":1,"id":"deleting-a-drift-metric-using-cli_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Viewing data drift metrics for a model","level":2,"index":2,"id":"viewing-drift-metrics_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Using drift metrics","level":2,"index":3,"id":"using-drift-metrics_drift-monitoring"},{"parentId":null,"name":"Using explainability","level":1,"index":5,"id":"using-explainability_explainers"},{"parentId":"using-explainability_explainers","name":"Requesting a LIME explanation","level":2,"index":0,"id":"requesting-a-lime-explanation_explainers"},{"parentId":"requesting-a-lime-explanation_explainers","name":"Requesting a LIME explanation by using the CLI","level":3,"index":0,"id":"requesting-a-lime-explanation-using-CLI_explainers"},{"parentId":"using-explainability_explainers","name":"Requesting a SHAP explanation","level":2,"index":1,"id":"requesting-a-shap-explanation_explainers"},{"parentId":"requesting-a-shap-explanation_explainers","name":"Requesting a SHAP explanation by using the CLI","level":3,"index":0,"id":"requesting-a-shap-explanation-using-CLI_explainers"},{"parentId":"using-explainability_explainers","name":"Using explainers","level":2,"index":2,"id":"using-explainers_explainers"},{"parentId":null,"name":"Evaluating large language models","level":1,"index":6,"id":"evaluating-large-language-models_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"Setting up LM-Eval","level":2,"index":0,"id":"setting-up-lmeval_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval evaluation job","level":2,"index":1,"id":"lmeval-evaluation-job_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval evaluation job properties","level":2,"index":2,"id":"lmeval-evaluation-job-properties_monitor"},{"parentId":"lmeval-evaluation-job-properties_monitor","name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":3,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval scenarios","level":2,"index":3,"id":"lmeval-scenarios_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Accessing Hugging Face models with an environment variable token","level":3,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using a custom Unitxt card","level":3,"index":1,"id":"using-a-custom-unitxt-card_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using PVCs as storage","level":3,"index":2,"id":"using-pvcs-as-storage_monitor"},{"parentId":"using-pvcs-as-storage_monitor","name":"Managed PVCs","level":4,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_monitor","name":"Existing PVCs","level":4,"index":1,"id":"_existing_pvcs"},{"parentId":"lmeval-scenarios_monitor","name":"Using a KServe Inference Service","level":3,"index":3,"id":"using-a-kserve-inference-service_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Setting up LM-Eval S3 Support","level":3,"index":4,"id":"setting-up-lmeval-s3-support_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using LLM-as-a-Judge metrics with LM-Eval","level":3,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_monitor"},{"parentId":null,"name":"Configuring the Guardrails Orchestrator service","level":1,"index":7,"id":"configuring-the-guardrails-orchestrator-service_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Deploying the Guardrails Orchestrator service","level":2,"index":0,"id":"deploying-the-guardrails-orchestrator-service_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Guardrails Orchestrator parameters","level":2,"index":1,"id":"guardrails-orchestrator-parameters_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Monitoring user inputs with the Guardrails Orchestrator service","level":2,"index":2,"id":"guardrails-orchestrator-hap-scenario_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Configuring the regex detector and guardrails gateway","level":2,"index":3,"id":"configuring-regex-guardrails-gateway_monitor"},{"parentId":"configuring-regex-guardrails-gateway_monitor","name":"Sending requests to the regex detector","level":3,"index":0,"id":"sending-requests-to-the-regex-detector_monitor"},{"parentId":"configuring-regex-guardrails-gateway_monitor","name":"Querying using guardrails gateway","level":3,"index":1,"id":"querying-using-guardrails-gateway_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Configuring the OpenTelemetry exporter","level":2,"index":4,"id":"configuring-the-opentelemetry-exporter_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Using Hugging Face models with Guardrails Orchestrator","level":2,"index":5,"id":"using-hugging-face-models-with-guardrails-orchestrator_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Configuring the Guardrails Detector Hugging Face serving runtime","level":2,"index":6,"id":"configuring-the-guardrails-detector-hugging-face-serving-runtime_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Using a Hugging Face Prompt Injection detector with the Guardrails Orchestrator","level":2,"index":7,"id":"using-a-hugging-face-prompt-injection-detector-with-guardrails-orchestrator_monitor"},{"parentId":null,"name":"Bias monitoring tutorial - Gender bias example","level":1,"index":8,"id":"bias-monitoring-tutorial_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Introduction","level":2,"index":0,"id":"t-bias-introduction_bias-tutorial"},{"parentId":"t-bias-introduction_bias-tutorial","name":"About the example models","level":3,"index":0,"id":"_about_the_example_models"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Setting up your environment","level":2,"index":1,"id":"t-bias-setting-up-your-environment_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Downloading the tutorial files","level":3,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Logging in to the OpenShift cluster from the command line","level":3,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Configuring monitoring for the model serving platform","level":3,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Enabling the TrustyAI component","level":3,"index":3,"id":"enabling-trustyai-component_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Setting up a project","level":3,"index":4,"id":"_setting_up_a_project"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Authenticating the TrustyAI service","level":3,"index":5,"id":"_authenticating_the_trustyai_service"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Deploying models","level":2,"index":2,"id":"t-bias-deploying-models_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Sending training data to the models","level":2,"index":3,"id":"t-bias-sending-training-data-to-the-models_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Labeling data fields","level":2,"index":4,"id":"t-bias-labeling-data-fields_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Checking model fairness","level":2,"index":5,"id":"t-bias-checking-model-fairness_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Scheduling a fairness metric request","level":2,"index":6,"id":"t-bias-scheduling-a-fairness-metric-request_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Scheduling an identity metric request","level":2,"index":7,"id":"t-bias-scheduling-an-identity-metric-request_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Simulating real world data","level":2,"index":8,"id":"t-bias-simulating-real-world-data_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Reviewing the results","level":2,"index":9,"id":"t-bias-reviewing-the-results_bias-tutorial"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"Are the models biased?","level":3,"index":0,"id":"_are_the_models_biased"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"How does the production data compare to the training data?","level":3,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/serving-models/"},"sections":[{"parentId":null,"name":"About model serving","level":1,"index":0,"id":"about-model-serving_about-model-serving"},{"parentId":"about-model-serving_about-model-serving","name":"Single-model serving platform","level":2,"index":0,"id":"_single_model_serving_platform"},{"parentId":"about-model-serving_about-model-serving","name":"Multi-model serving platform","level":2,"index":1,"id":"_multi_model_serving_platform"},{"parentId":"about-model-serving_about-model-serving","name":"NVIDIA NIM model serving platform","level":2,"index":2,"id":"_nvidia_nim_model_serving_platform"},{"parentId":null,"name":"Serving models on the single-model serving platform","level":1,"index":1,"id":"serving-large-models_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"About the single-model serving platform","level":2,"index":0,"id":"about-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Model-serving runtimes","level":2,"index":1,"id":"model-serving-runtimes_serving-large-models"},{"parentId":"model-serving-runtimes_serving-large-models","name":"ServingRuntime","level":3,"index":0,"id":"_servingruntime"},{"parentId":"model-serving-runtimes_serving-large-models","name":"InferenceService","level":3,"index":1,"id":"_inferenceservice"},{"parentId":"serving-large-models_serving-large-models","name":"About KServe deployment modes","level":2,"index":2,"id":"about-kserve-deployment-modes_serving-large-models"},{"parentId":"about-kserve-deployment-modes_serving-large-models","name":"Advanced mode","level":3,"index":0,"id":"_advanced_mode"},{"parentId":"about-kserve-deployment-modes_serving-large-models","name":"Standard mode","level":3,"index":1,"id":"_standard_mode"},{"parentId":"serving-large-models_serving-large-models","name":"Installing KServe","level":2,"index":3,"id":"installing-kserve_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Deploying models by using the single-model serving platform","level":2,"index":4,"id":"deploying-models-using-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Enabling the single-model serving platform","level":3,"index":0,"id":"enabling-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a custom model-serving runtime for the single-model serving platform","level":3,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a tested and verified model-serving runtime for the single-model serving platform","level":3,"index":2,"id":"adding-a-tested-and-verified-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models on the single-model serving platform","level":3,"index":3,"id":"deploying-models-on-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models by using multiple GPU nodes","level":3,"index":4,"id":"deploying-models-using-multiple-gpu-nodes_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Setting a timeout for KServe","level":3,"index":5,"id":"setting-timeout-for-kserve_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Customizing the parameters of a deployed model-serving runtime","level":3,"index":6,"id":"customizing-parameters-serving-runtime_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Customizable model serving runtime parameters","level":3,"index":7,"id":"customizable-model-serving-runtime-parameters_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Using accelerators with vLLM","level":3,"index":8,"id":"using-accelerators-with-vllm_serving-large-models"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"NVIDIA GPUs","level":4,"index":0,"id":"_nvidia_gpus"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"Intel Gaudi accelerators","level":4,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"AMD GPUs","level":4,"index":2,"id":"_amd_gpus"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Using OCI containers for model storage","level":3,"index":9,"id":"using-oci-containers-for-model-storage_serving-large-models"},{"parentId":"using-oci-containers-for-model-storage_serving-large-models","name":"Storing a model in an OCI image","level":4,"index":0,"id":"storing-a-model-in-oci-image_serving-large-models"},{"parentId":"using-oci-containers-for-model-storage_serving-large-models","name":"Deploying a model stored in an OCI image by using the CLI","level":4,"index":1,"id":"deploying-model-stored-in-oci-image_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the authentication token for a deployed model","level":3,"index":10,"id":"accessing-authentication-token-for-deployed-model_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the inference endpoint for a deployed model","level":3,"index":11,"id":"accessing-inference-endpoint-for-deployed-model_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Configuring monitoring for the single-model serving platform","level":2,"index":5,"id":"configuring-monitoring-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Viewing model-serving runtime metrics for the single-model serving platform","level":2,"index":6,"id":"viewing-metrics-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Monitoring model performance","level":2,"index":7,"id":"_monitoring_model_performance"},{"parentId":"_monitoring_model_performance","name":"Viewing performance metrics for a deployed model","level":3,"index":0,"id":"viewing-performance-metrics-for-deployed-model_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Deploying a Grafana metrics dashboard","level":3,"index":1,"id":"Deploying-a-grafana-metrics-dashboard_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Deploying a vLLM/GPU metrics dashboard on a Grafana instance","level":3,"index":2,"id":"deploying-vllm-gpu-metrics-dashboard-grafana_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Grafana metrics","level":3,"index":3,"id":"ref-grafana-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"Accelerator metrics","level":4,"index":0,"id":"ref-accelerator-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"CPU metrics","level":4,"index":1,"id":"ref-cpu-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"vLLM metrics","level":4,"index":2,"id":"ref-vllm-metrics_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Optimizing model-serving runtimes","level":2,"index":8,"id":"_optimizing_model_serving_runtimes"},{"parentId":"_optimizing_model_serving_runtimes","name":"Enabling speculative decoding and multi-modal inferencing","level":3,"index":0,"id":"enabling-speculative-decoding-and-multi-modal-inferencing_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Performance tuning on the single-model serving platform","level":2,"index":9,"id":"_performance_tuning_on_the_single_model_serving_platform"},{"parentId":"_performance_tuning_on_the_single_model_serving_platform","name":"Resolving CUDA out-of-memory errors","level":3,"index":0,"id":"resolving-cuda-oom-errors-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Supported model-serving runtimes","level":2,"index":10,"id":"supported-model-serving-runtimes_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Tested and verified model-serving runtimes","level":2,"index":11,"id":"tested-verified-runtimes_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Inference endpoints","level":2,"index":12,"id":"inference-endpoints_serving-large-models"},{"parentId":"inference-endpoints_serving-large-models","name":"Caikit TGIS ServingRuntime for KServe","level":3,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"Caikit Standalone ServingRuntime for KServe","level":3,"index":1,"id":"_caikit_standalone_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"TGIS Standalone ServingRuntime for KServe","level":3,"index":2,"id":"_tgis_standalone_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"OpenVINO Model Server","level":3,"index":3,"id":"_openvino_model_server"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":3,"index":4,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":3,"index":5,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM AMD GPU ServingRuntime for KServe","level":3,"index":6,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"NVIDIA Triton Inference Server","level":3,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":"inference-endpoints_serving-large-models","name":"Seldon MLServer","level":3,"index":8,"id":"_seldon_mlserver"},{"parentId":"inference-endpoints_serving-large-models","name":"Additional resources","level":3,"index":9,"id":"_additional_resources"},{"parentId":"serving-large-models_serving-large-models","name":"About the NVIDIA NIM model serving platform","level":2,"index":13,"id":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Enabling the NVIDIA NIM model serving platform","level":3,"index":0,"id":"enabling-the-nvidia-nim-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Deploying models on the NVIDIA NIM model serving platform","level":3,"index":1,"id":"deploying-models-on-the-NVIDIA-NIM-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Customizing model selection options for the NVIDIA NIM model serving platform","level":3,"index":2,"id":"Customizing-model-selection-options_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Enabling NVIDIA NIM metrics for an existing NIM deployment","level":3,"index":3,"id":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models","name":"Enabling graph generation for an existing NIM deployment","level":4,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models","name":"Enabling metrics collection for an existing NIM deployment","level":4,"index":1,"id":"_enabling_metrics_collection_for_an_existing_nim_deployment"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Viewing NVIDIA NIM metrics for a NIM model","level":3,"index":4,"id":"viewing-nvidia-nim-metrics-for-a-nim-model_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Viewing performance metrics for a NIM model","level":3,"index":5,"id":"viewing-performance-metrics-for-a-nim-model_serving-large-models"},{"parentId":null,"name":"Serving models on the multi-model serving platform","level":1,"index":2,"id":"serving-small-and-medium-sized-models_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Configuring model servers","level":2,"index":0,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the multi-model serving platform","level":3,"index":0,"id":"enabling-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime for the multi-model serving platform","level":3,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a tested and verified model-serving runtime for the multi-model serving platform","level":3,"index":2,"id":"adding-a-tested-and-verified-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a model server for the multi-model serving platform","level":3,"index":3,"id":"adding-a-model-server-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Deleting a model server","level":3,"index":4,"id":"deleting-a-model-server_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Working with deployed models","level":2,"index":1,"id":"_working_with_deployed_models"},{"parentId":"_working_with_deployed_models","name":"Deploying a model by using the multi-model serving platform","level":3,"index":0,"id":"deploying-a-model-using-the-multi-model-serving-platform_model-serving"},{"parentId":"_working_with_deployed_models","name":"Viewing a deployed model","level":3,"index":1,"id":"viewing-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Updating the deployment properties of a deployed model","level":3,"index":2,"id":"updating-the-deployment-properties-of-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Deleting a deployed model","level":3,"index":3,"id":"deleting-a-deployed-model_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Configuring monitoring for the multi-model serving platform","level":2,"index":2,"id":"configuring-monitoring-for-the-multi-model-serving-platform_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Viewing model-serving runtime metrics for the multi-model serving platform","level":2,"index":3,"id":"viewing-metrics-for-the-multi-model-serving-platform_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Monitoring model performance","level":2,"index":4,"id":"_monitoring_model_performance_2"},{"parentId":"_monitoring_model_performance_2","name":"Viewing performance metrics for all models on a model server","level":3,"index":0,"id":"viewing-performance-metrics-for-model-server_model-serving"},{"parentId":"_monitoring_model_performance_2","name":"Viewing HTTP request metrics for a deployed model","level":3,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_model-serving"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/upgrading-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview of upgrading Open Data Hub","level":1,"index":0,"id":"overview-of-upgrading-odh_upgrade"},{"parentId":null,"name":"Upgrading Open Data Hub version 2.0 to version 2.2","level":1,"index":1,"id":"upgrading-odh-v2_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Requirements for upgrading Open Data Hub version 2","level":2,"index":0,"id":"requirements-for-upgrading-odh-v2_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Installing Open Data Hub version 2","level":2,"index":1,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Configuring custom namespaces","level":3,"index":0,"id":"configuring-custom-namespaces"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":3,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":3,"index":2,"id":"installing-odh-components_installv2"},{"parentId":null,"name":"Upgrading Open Data Hub version 1 to version 2","level":1,"index":2,"id":"upgrading-odh-v1-to-v2_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Requirements for upgrading Open Data Hub version 1","level":2,"index":0,"id":"requirements-for-upgrading-odh-v1_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Upgrading the Open Data Hub Operator version 1","level":2,"index":1,"id":"upgrading-the-odh-operator-v1_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Installing Open Data Hub components","level":2,"index":2,"id":"installing-odh-components_upgradev1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-in-your-data-science-ide/"},"sections":[{"parentId":null,"name":"Accessing your workbench IDE","level":1,"index":0,"id":"accessing-your-workbench-ide_ide"},{"parentId":null,"name":"Working in JupyterLab","level":1,"index":1,"id":"_working_in_jupyterlab"},{"parentId":"_working_in_jupyterlab","name":"Creating and importing Jupyter notebooks","level":2,"index":0,"id":"creating-and-importing-jupyter-notebooks_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Creating a Jupyter notebook","level":3,"index":0,"id":"creating-a-jupyter-notebook_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Uploading an existing notebook file to JupyterLab from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Additional resources","level":3,"index":2,"id":"_additional_resources"},{"parentId":"_working_in_jupyterlab","name":"Collaborating on Jupyter notebooks by using Git","level":2,"index":1,"id":"collaborating-on-jupyter-notebooks-by-using-git_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Updating your project with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Pushing project changes to a Git repository","level":3,"index":3,"id":"pushing-project-changes-to-a-git-repository_ide"},{"parentId":"_working_in_jupyterlab","name":"Managing Python packages","level":2,"index":2,"id":"managing-python-packages_ide"},{"parentId":"managing-python-packages_ide","name":"Viewing Python packages installed on your workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_ide"},{"parentId":"managing-python-packages_ide","name":"Installing Python packages on your workbench","level":3,"index":1,"id":"installing-python-packages-on-your-workbench_ide"},{"parentId":"_working_in_jupyterlab","name":"Troubleshooting common problems in workbenches for users","level":2,"index":3,"id":"troubleshooting-common-problems-in-workbenches-for-users_ide"},{"parentId":null,"name":"Working in code-server","level":1,"index":2,"id":"_working_in_code_server"},{"parentId":"_working_in_code_server","name":"Creating code-server workbenches","level":2,"index":0,"id":"creating-code-server-workbenches_ide"},{"parentId":"creating-code-server-workbenches_ide","name":"Creating a workbench","level":3,"index":0,"id":"creating-a-project-workbench_ide"},{"parentId":"creating-code-server-workbenches_ide","name":"Uploading an existing notebook file to code-server from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-local-storage_ide"},{"parentId":"_working_in_code_server","name":"Collaborating on workbenches in code-server by using Git","level":2,"index":1,"id":"collaborating-on-workbenches-in-code-server-by-using-git_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Uploading an existing notebook file from a Git repository by using code-server","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-code-server_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Uploading an existing notebook file to code-server from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Updating your project in code-server with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-in-code-server-with-changes-from-a-remote-git-repository_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Pushing project changes in code-server to a Git repository","level":3,"index":3,"id":"pushing-project-changes-in-code-server-to-a-git-repository_ide"},{"parentId":"_working_in_code_server","name":"Managing Python packages in code-server","level":2,"index":2,"id":"managing-python-packages-in-code-server_ide"},{"parentId":"managing-python-packages-in-code-server_ide","name":"Viewing Python packages installed on your code-server workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-code-server-workbench_ide"},{"parentId":"managing-python-packages-in-code-server_ide","name":"Installing Python packages on your code-server workbench","level":3,"index":1,"id":"installing-python-packages-on-your-code-server-workbench_ide"},{"parentId":"_working_in_code_server","name":"Installing extensions with code-server","level":2,"index":3,"id":"installing-extensions-with-code-server_ide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-on-data-science-projects/"},"sections":[{"parentId":null,"name":"Using data science projects","level":1,"index":0,"id":"using-data-science-projects_projects"},{"parentId":"using-data-science-projects_projects","name":"Creating a data science project","level":2,"index":0,"id":"creating-a-data-science-project_projects"},{"parentId":"using-data-science-projects_projects","name":"Updating a data science project","level":2,"index":1,"id":"updating-a-data-science-project_projects"},{"parentId":"using-data-science-projects_projects","name":"Deleting a data science project","level":2,"index":2,"id":"deleting-a-data-science-project_projects"},{"parentId":null,"name":"Using project workbenches","level":1,"index":1,"id":"using-project-workbenches_projects"},{"parentId":"using-project-workbenches_projects","name":"Creating a workbench and selecting an IDE","level":2,"index":0,"id":"creating-a-workbench-select-ide_projects"},{"parentId":"creating-a-workbench-select-ide_projects","name":"About workbench images","level":3,"index":0,"id":"about-workbench-images_projects"},{"parentId":"creating-a-workbench-select-ide_projects","name":"Creating a workbench","level":3,"index":1,"id":"creating-a-project-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Starting a workbench","level":2,"index":1,"id":"starting-a-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Updating a project workbench","level":2,"index":2,"id":"updating-a-project-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Deleting a workbench from a data science project","level":2,"index":3,"id":"deleting-a-workbench-from-a-data-science-project_projects"},{"parentId":null,"name":"Using connections","level":1,"index":2,"id":"using-connections_projects"},{"parentId":"using-connections_projects","name":"Adding a connection to your data science project","level":2,"index":0,"id":"adding-a-connection-to-your-data-science-project_projects"},{"parentId":"using-connections_projects","name":"Updating a connection","level":2,"index":1,"id":"updating-a-connection_projects"},{"parentId":"using-connections_projects","name":"Deleting a connection","level":2,"index":2,"id":"deleting-a-connection_projects"},{"parentId":null,"name":"Configuring cluster storage","level":1,"index":3,"id":"configuring-cluster-storage_projects"},{"parentId":"configuring-cluster-storage_projects","name":"About persistent storage","level":2,"index":0,"id":"about-persistent-storage_projects"},{"parentId":"about-persistent-storage_projects","name":"Storage classes in Open Data Hub","level":3,"index":0,"id":"_storage_classes_in_open_data_hub"},{"parentId":"about-persistent-storage_projects","name":"Access modes","level":3,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":4,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":"configuring-cluster-storage_projects","name":"Adding cluster storage to your data science project","level":2,"index":1,"id":"adding-cluster-storage-to-your-data-science-project_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Updating cluster storage","level":2,"index":2,"id":"updating-cluster-storage_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Changing the storage class for an existing cluster storage instance","level":2,"index":3,"id":"changing-the-storage-class-for-an-existing-cluster-storage-instance_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Deleting cluster storage from a data science project","level":2,"index":4,"id":"deleting-cluster-storage-from-a-data-science-project_projects"},{"parentId":null,"name":"Managing access to data science projects","level":1,"index":4,"id":"managing-access-to-data-science-projects_projects"},{"parentId":"managing-access-to-data-science-projects_projects","name":"Configuring access to a data science project","level":2,"index":0,"id":"configuring-access-to-a-data-science-project_projects"},{"parentId":"managing-access-to-data-science-projects_projects","name":"Sharing access to a data science project","level":2,"index":1,"id":"sharing-access-to-a-data-science-project_projects"},{"parentId":"managing-access-to-data-science-projects_projects","name":"Updating access to a data science project","level":2,"index":2,"id":"updating-access-to-a-data-science-project_projects"},{"parentId":"managing-access-to-data-science-projects_projects","name":"Removing access to a data science project","level":2,"index":3,"id":"removing-access-to-a-data-science-project_projects"},{"parentId":null,"name":"Creating project-scoped resources for your project","level":1,"index":5,"id":"creating-project-scoped-resources-for-your-project_projects"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-accelerators/"},"sections":[{"parentId":null,"name":"Overview of accelerators","level":1,"index":0,"id":"overview-of-accelerators_accelerators"},{"parentId":null,"name":"Enabling accelerators","level":1,"index":1,"id":"enabling-accelerators_accelerators"},{"parentId":null,"name":"Enabling NVIDIA GPUs","level":1,"index":2,"id":"enabling-nvidia-gpus_accelerators"},{"parentId":null,"name":"Intel Gaudi AI Accelerator integration","level":1,"index":3,"id":"intel-gaudi-ai-accelerator-integration_accelerators"},{"parentId":null,"name":"AMD GPU Integration","level":1,"index":4,"id":"amd-gpu-integration_accelerators"},{"parentId":"amd-gpu-integration_accelerators","name":"Verifying AMD GPU availability on your cluster","level":2,"index":0,"id":"verifying-amd-gpu-availability-on-your-cluster_accelerators"},{"parentId":"amd-gpu-integration_accelerators","name":"Enabling AMD GPUs","level":2,"index":1,"id":"enabling-amd-gpus_accelerators"},{"parentId":null,"name":"Working with accelerator profiles","level":1,"index":5,"id":"working-with-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Viewing accelerator profiles","level":2,"index":0,"id":"viewing-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Creating an accelerator profile","level":2,"index":1,"id":"creating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Updating an accelerator profile","level":2,"index":2,"id":"updating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Deleting an accelerator profile","level":2,"index":3,"id":"deleting-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for workbench images","level":2,"index":4,"id":"configuring-a-recommended-accelerator-for-workbench-images_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for serving runtimes","level":2,"index":5,"id":"configuring-a-recommended-accelerator-for-serving-runtimes_accelerators"},{"parentId":null,"name":"Working with hardware profiles","level":1,"index":6,"id":"working-with-hardware-profiles_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Creating a hardware profile","level":2,"index":0,"id":"creating-a-hardware-profile_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Updating a hardware profile","level":2,"index":1,"id":"updating-a-hardware-profile_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Deleting a hardware profile","level":2,"index":2,"id":"deleting-a-hardware-profile_accelerators"},{"parentId":null,"name":"About GPU time slicing","level":1,"index":7,"id":"about-gpu-time-slicing_accelerators"},{"parentId":null,"name":"Enabling GPU time slicing","level":1,"index":8,"id":"enabling-gpu-time-slicing_accelerators"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-connected-applications/"},"sections":[{"parentId":null,"name":"Viewing applications that are connected to Open Data Hub","level":1,"index":0,"id":"viewing-connected-applications_connected-apps"},{"parentId":null,"name":"Enabling applications that are connected to Open Data Hub","level":1,"index":1,"id":"enabling-applications-connected_connected-apps"},{"parentId":null,"name":"Removing disabled applications from the dashboard","level":1,"index":2,"id":"removing-disabled-applications_connected-apps"},{"parentId":null,"name":"Using basic workbenches","level":1,"index":3,"id":"using-basic-workbenches_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Starting a basic workbench","level":2,"index":0,"id":"starting-a-basic-workbench_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Creating and importing Jupyter notebooks","level":2,"index":1,"id":"creating-and-importing-jupyter-notebooks_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Creating a Jupyter notebook","level":3,"index":0,"id":"creating-a-jupyter-notebook_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Uploading an existing notebook file to JupyterLab from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Additional resources","level":3,"index":2,"id":"_additional_resources"},{"parentId":"using-basic-workbenches_connected-apps","name":"Collaborating on Jupyter notebooks by using Git","level":2,"index":2,"id":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Updating your project with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Pushing project changes to a Git repository","level":3,"index":3,"id":"pushing-project-changes-to-a-git-repository_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Managing Python packages","level":2,"index":3,"id":"managing-python-packages_connected-apps"},{"parentId":"managing-python-packages_connected-apps","name":"Viewing Python packages installed on your workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_connected-apps"},{"parentId":"managing-python-packages_connected-apps","name":"Installing Python packages on your workbench","level":3,"index":1,"id":"installing-python-packages-on-your-workbench_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Updating workbench settings by restarting your workbench","level":2,"index":4,"id":"updating-workbench-settings-by-restarting-your-workbench_connected-apps"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-data-in-s3-compatible-object-store/"},"sections":[{"parentId":null,"name":"Prerequisites","level":1,"index":0,"id":"s3-prerequisites_s3"},{"parentId":null,"name":"Creating an S3 client","level":1,"index":1,"id":"creating-an-s3-client_s3"},{"parentId":null,"name":"Listing available buckets in your object store","level":1,"index":2,"id":"listing-available-amazon-buckets_s3"},{"parentId":null,"name":"Creating a bucket in your object store","level":1,"index":3,"id":"creating-an-s3-bucket_s3"},{"parentId":null,"name":"Listing files in your bucket","level":1,"index":4,"id":"listing-files-in-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Downloading files from your bucket","level":1,"index":5,"id":"downloading-files-from-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Uploading files to your bucket","level":1,"index":6,"id":"uploading-files-to-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Copying files between buckets","level":1,"index":7,"id":"copying-files-to-between-buckets_s3"},{"parentId":null,"name":"Deleting files from your bucket","level":1,"index":8,"id":"Deleting-files-on-your-object-store_s3"},{"parentId":null,"name":"Deleting a bucket from your object store","level":1,"index":9,"id":"deleting-a-s3-bucket_s3"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":10,"id":"overview-of-object-storage-endpoints_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Accessing S3-compatible object storage with self-signed certificates","level":1,"index":11,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_s3"},{"parentId":null,"name":"Additional resources","level":1,"index":12,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Managing data science pipelines","level":1,"index":0,"id":"managing-data-science-pipelines_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Configuring a pipeline server","level":2,"index":0,"id":"configuring-a-pipeline-server_ds-pipelines"},{"parentId":"configuring-a-pipeline-server_ds-pipelines","name":"Configuring a pipeline server with an external Amazon RDS database","level":3,"index":0,"id":"configuring-a-pipeline-server-with-an-external-amazon-rds-db_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Defining a pipeline","level":2,"index":1,"id":"defining-a-pipeline_ds-pipelines"},{"parentId":"defining-a-pipeline_ds-pipelines","name":"Defining a pipeline by using the Kubernetes API","level":3,"index":0,"id":"defining-a-pipeline-by-using-the-kubernetes-api_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Importing a data science pipeline","level":2,"index":2,"id":"importing-a-data-science-pipeline_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Deleting a data science pipeline","level":2,"index":3,"id":"deleting-a-data-science-pipeline_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Deleting a pipeline server","level":2,"index":4,"id":"deleting-a-pipeline-server_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Viewing the details of a pipeline server","level":2,"index":5,"id":"viewing-the-details-of-a-pipeline-server_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Viewing existing pipelines","level":2,"index":6,"id":"viewing-existing-pipelines_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Overview of pipeline versions","level":2,"index":7,"id":"overview-of-pipeline-versions_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Uploading a pipeline version","level":2,"index":8,"id":"uploading-a-pipeline-version_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Deleting a pipeline version","level":2,"index":9,"id":"deleting-a-pipeline-version_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Viewing the details of a pipeline version","level":2,"index":10,"id":"viewing-the-details-of-a-pipeline-version_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Downloading a data science pipeline version","level":2,"index":11,"id":"downloading-a-data-science-pipeline-version_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Overview of data science pipelines caching","level":2,"index":12,"id":"overview-of-data-science-pipelines-caching_ds-pipelines"},{"parentId":"overview-of-data-science-pipelines-caching_ds-pipelines","name":"Caching criteria","level":3,"index":0,"id":"_caching_criteria"},{"parentId":"overview-of-data-science-pipelines-caching_ds-pipelines","name":"Viewing cached steps in the Open Data Hub user interface","level":3,"index":1,"id":"_viewing_cached_steps_in_the_open_data_hub_user_interface"},{"parentId":"overview-of-data-science-pipelines-caching_ds-pipelines","name":"Controlling caching in data science pipelines","level":3,"index":2,"id":"controlling-caching-in-data-science-pipelines_ds-pipelines"},{"parentId":"controlling-caching-in-data-science-pipelines_ds-pipelines","name":"Disabling caching for individual tasks","level":4,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":"controlling-caching-in-data-science-pipelines_ds-pipelines","name":"Disabling caching for a pipeline at submit time","level":4,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":"controlling-caching-in-data-science-pipelines_ds-pipelines","name":"Disabling caching for a pipeline at compile time","level":4,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":"controlling-caching-in-data-science-pipelines_ds-pipelines","name":"Disabling caching for all pipelines (pipeline server)","level":4,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"},{"parentId":null,"name":"Managing pipeline experiments","level":1,"index":1,"id":"managing-pipeline-experiments_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Overview of pipeline experiments","level":2,"index":0,"id":"overview-of-pipeline-experiments_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Creating a pipeline experiment","level":2,"index":1,"id":"creating-a-pipeline-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Archiving a pipeline experiment","level":2,"index":2,"id":"archiving-a-pipeline-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Deleting an archived pipeline experiment","level":2,"index":3,"id":"deleting-an-archived-pipeline-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Restoring an archived pipeline experiment","level":2,"index":4,"id":"restoring-an-archived-pipeline-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Viewing pipeline task executions","level":2,"index":5,"id":"viewing-pipeline-task-executions_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Viewing pipeline artifacts","level":2,"index":6,"id":"viewing-pipeline-artifacts_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Comparing runs in an experiment","level":2,"index":7,"id":"comparing-runs-in-an-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Comparing runs in different experiments","level":2,"index":8,"id":"comparing-runs-in-different-experiments_ds-pipelines"},{"parentId":null,"name":"Managing pipeline runs","level":1,"index":2,"id":"managing-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Overview of pipeline runs","level":2,"index":0,"id":"overview-of-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Storing data with data science pipelines","level":2,"index":1,"id":"storing-data-with-data-science-pipelines_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Viewing active pipeline runs","level":2,"index":2,"id":"viewing-active-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Executing a pipeline run","level":2,"index":3,"id":"executing-a-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Stopping an active pipeline run","level":2,"index":4,"id":"stopping-an-active-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Duplicating an active pipeline run","level":2,"index":5,"id":"duplicating-an-active-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Viewing scheduled pipeline runs","level":2,"index":6,"id":"viewing-scheduled-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Scheduling a pipeline run using a cron job","level":2,"index":7,"id":"scheduling-a-pipeline-run-using-a-cron-job_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Scheduling a pipeline run","level":2,"index":8,"id":"scheduling-a-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Duplicating a scheduled pipeline run","level":2,"index":9,"id":"duplicating-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Deleting a scheduled pipeline run","level":2,"index":10,"id":"deleting-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Viewing the details of a pipeline run","level":2,"index":11,"id":"viewing-the-details-of-a-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Viewing archived pipeline runs","level":2,"index":12,"id":"viewing-archived-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Archiving a pipeline run","level":2,"index":13,"id":"archiving-a-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Restoring an archived pipeline run","level":2,"index":14,"id":"restoring-an-archived-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Deleting an archived pipeline run","level":2,"index":15,"id":"deleting-an-archived-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Duplicating an archived pipeline run","level":2,"index":16,"id":"duplicating-an-archived-pipeline-run_ds-pipelines"},{"parentId":null,"name":"Working with pipeline logs","level":1,"index":3,"id":"working-with-pipeline-logs_ds-pipelines"},{"parentId":"working-with-pipeline-logs_ds-pipelines","name":"About pipeline logs","level":2,"index":0,"id":"about-pipeline-logs_ds-pipelines"},{"parentId":"working-with-pipeline-logs_ds-pipelines","name":"Viewing pipeline step logs","level":2,"index":1,"id":"viewing-pipeline-step-logs_ds-pipelines"},{"parentId":"working-with-pipeline-logs_ds-pipelines","name":"Downloading pipeline step logs","level":2,"index":2,"id":"downloading-pipeline-step-logs_ds-pipelines"},{"parentId":null,"name":"Working with pipelines in JupyterLab","level":1,"index":4,"id":"working-with-pipelines-in-jupyterlab_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Overview of pipelines in JupyterLab","level":2,"index":0,"id":"overview-of-pipelines-in-jupyterlab_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Accessing the pipeline editor","level":2,"index":1,"id":"accessing-the-pipeline-editor_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Creating a runtime configuration","level":2,"index":2,"id":"creating-a-runtime-configuration_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Updating a runtime configuration","level":2,"index":3,"id":"updating-a-runtime-configuration_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Deleting a runtime configuration","level":2,"index":4,"id":"deleting-a-runtime-configuration_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Duplicating a runtime configuration","level":2,"index":5,"id":"duplicating-a-runtime-configuration_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Running a pipeline in JupyterLab","level":2,"index":6,"id":"running-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Exporting a pipeline in JupyterLab","level":2,"index":7,"id":"exporting-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":null,"name":"Troubleshooting DSPA component errors","level":1,"index":5,"id":"troubleshooting-dspa-component-errors_ds-pipelines"},{"parentId":"troubleshooting-dspa-component-errors_ds-pipelines","name":"Common errors across DSP components","level":2,"index":0,"id":"_common_errors_across_dsp_components"},{"parentId":null,"name":"Migrating to data science pipelines 2.0","level":1,"index":6,"id":"migrating-to-data-science-pipelines-2_ds-pipelines"},{"parentId":"migrating-to-data-science-pipelines-2_ds-pipelines","name":"Upgrading to data science pipelines 2.0","level":2,"index":0,"id":"_upgrading_to_data_science_pipelines_2_0"},{"parentId":"migrating-to-data-science-pipelines-2_ds-pipelines","name":"Removing data science pipelines 1.0 resources","level":2,"index":1,"id":"_removing_data_science_pipelines_1_0_resources"},{"parentId":null,"name":"Additional resources","level":1,"index":7,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-distributed-workloads/"},"sections":[{"parentId":null,"name":"Overview of distributed workloads","level":1,"index":0,"id":"overview-of-distributed-workloads_distributed-workloads"},{"parentId":"overview-of-distributed-workloads_distributed-workloads","name":"Distributed workloads infrastructure","level":2,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":"overview-of-distributed-workloads_distributed-workloads","name":"Types of distributed workloads","level":2,"index":1,"id":"_types_of_distributed_workloads"},{"parentId":null,"name":"Preparing the distributed training environment","level":1,"index":1,"id":"preparing-the-distributed-training-environment_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Creating a workbench for distributed training","level":2,"index":0,"id":"creating-a-workbench-for-distributed-training_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Using the cluster server and token to authenticate","level":2,"index":1,"id":"using-the-cluster-server-and-token-to-authenticate_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Managing custom training images","level":2,"index":2,"id":"managing-custom-training-images_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"About base training images","level":3,"index":0,"id":"about-base-training-images_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"Creating a custom training image","level":3,"index":1,"id":"creating-a-custom-training-image_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"Pushing an image to the integrated OpenShift image registry","level":3,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_distributed-workloads"},{"parentId":null,"name":"Running Ray-based distributed workloads","level":1,"index":2,"id":"running-ray-based-distributed-workloads_distributed-workloads"},{"parentId":"running-ray-based-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from Jupyter notebooks","level":2,"index":0,"id":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Downloading the demo Jupyter notebooks from the CodeFlare SDK","level":3,"index":0,"id":"downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Running the demo Jupyter notebooks from the CodeFlare SDK","level":3,"index":1,"id":"running-the-demo-jupyter-notebooks-from-the-codeflare-sdk_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Managing Ray clusters from within a Jupyter notebook","level":3,"index":2,"id":"managing-ray-clusters-from-within-a-jupyter-notebook_distributed-workloads"},{"parentId":"running-ray-based-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from data science pipelines","level":2,"index":1,"id":"running-distributed-data-science-workloads-from-ds-pipelines_distributed-workloads"},{"parentId":null,"name":"Running Training Operator-based distributed training workloads","level":1,"index":3,"id":"running-kfto-based-distributed-training-workloads_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Using the Kubeflow Training Operator to run distributed training workloads","level":2,"index":0,"id":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":3,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorchJob resource","level":3,"index":1,"id":"creating-a-kfto-pytorchjob-resource_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":3,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorch training scripts","level":3,"index":3,"id":"example-kfto-pytorch-training-scripts_distributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: NCCL","level":4,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccldistributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: DDP","level":4,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_distributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: FSDP","level":4,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Dockerfile for a Training Operator PyTorch training script","level":3,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorchJob resource for multi-node training","level":3,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Using the Training Operator SDK to run distributed training workloads","level":2,"index":1,"id":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"Configuring a training job by using the Training Operator SDK","level":3,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"Running a training job by using the Training Operator SDK","level":3,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"TrainingClient API: Job-related methods","level":3,"index":2,"id":"ref-trainingclient-api-job-related-methods_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Fine-tuning a model by using Kubeflow Training","level":2,"index":2,"id":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Configuring the fine-tuning job","level":3,"index":0,"id":"configuring-the-fine-tuning-job_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Running the fine-tuning job","level":3,"index":1,"id":"running-the-fine-tuning-job_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Deleting the fine-tuning job","level":3,"index":2,"id":"deleting-the-fine-tuning-job_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Creating a multi-node PyTorch training job with RDMA","level":2,"index":3,"id":"creating-a-multi-node-pytorch-training-job-with-rdma_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorchJob resource configured to run with RDMA","level":2,"index":4,"id":"ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma_distributed-workloads"},{"parentId":null,"name":"Monitoring distributed workloads","level":1,"index":4,"id":"monitoring-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing project metrics for distributed workloads","level":2,"index":0,"id":"viewing-project-metrics-for-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing the status of distributed workloads","level":2,"index":1,"id":"viewing-the-status-of-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing Kueue alerts for distributed workloads","level":2,"index":2,"id":"viewing-kueue-alerts-for-distributed-workloads_distributed-workloads"},{"parentId":null,"name":"Troubleshooting common problems with distributed workloads for users","level":1,"index":5,"id":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster is in a suspended state","level":2,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster is in a failed state","level":2,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"failed to call webhook\" error message for the CodeFlare Operator","level":2,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"failed to call webhook\" error message for Kueue","level":2,"index":3,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster does not start","level":2,"index":4,"id":"_my_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"Default Local Queue not found\" error message","level":2,"index":5,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"local_queue provided does not exist\" error message","level":2,"index":6,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I cannot create a Ray cluster or submit jobs","level":2,"index":7,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My pod provisioned by Kueue is terminated before my image is pulled","level":2,"index":8,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-model-registries/"},"sections":[{"parentId":null,"name":"Overview of model registries","level":1,"index":0,"id":"overview-of-model-registries_model-registry"},{"parentId":null,"name":"Enabling the model registry component","level":0,"index":1,"id":"_enabling_the_model_registry_component"},{"parentId":"_enabling_the_model_registry_component","name":"Enabling the model registry component","level":1,"index":0,"id":"enabling-the-model-registry-component_model-registry"},{"parentId":"_enabling_the_model_registry_component","name":"Enabling the model catalog","level":1,"index":1,"id":"enabling-the-model-catalog_model-registry"},{"parentId":null,"name":"Managing model registries","level":0,"index":2,"id":"_managing_model_registries"},{"parentId":"_managing_model_registries","name":"Creating a model registry","level":1,"index":0,"id":"creating-a-model-registry_model-registry"},{"parentId":"_managing_model_registries","name":"Editing a model registry","level":1,"index":1,"id":"editing-a-model-registry_model-registry"},{"parentId":"_managing_model_registries","name":"Managing model registry permissions","level":1,"index":2,"id":"managing-model-registry-permissions_model-registry"},{"parentId":"_managing_model_registries","name":"Deleting a model registry","level":1,"index":3,"id":"deleting-a-model-registry_model-registry"},{"parentId":null,"name":"Working with model registries","level":0,"index":3,"id":"_working_with_model_registries"},{"parentId":"_working_with_model_registries","name":"Working with model registries","level":1,"index":0,"id":"working-with-model-registries_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Registering a model","level":2,"index":0,"id":"registering-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Registering a model from the model catalog","level":2,"index":1,"id":"registering-a-model-from-the-model-catalog_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Registering a model version","level":2,"index":2,"id":"registering-a-model-version_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Viewing registered models","level":2,"index":3,"id":"viewing-registered-models_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Viewing registered model versions","level":2,"index":4,"id":"viewing-registered-model-versions_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing model metadata in a model registry","level":2,"index":5,"id":"editing-model-metadata-in-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing model version metadata in a model registry","level":2,"index":6,"id":"editing-model-version-metadata-in-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Deploying a model version from a model registry","level":2,"index":7,"id":"deploying-a-model-version-from-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Deploying a model from the model catalog","level":2,"index":8,"id":"deploying-a-model-from-the-model-catalog_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing the deployment properties of a deployed model version from a model registry","level":2,"index":9,"id":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the multi-model serving platform","level":3,"index":0,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-multi-model-serving-platform_model-registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the single-model serving platform","level":3,"index":1,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-single-model-serving-platform_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Deleting a deployed model version from a model registry","level":2,"index":10,"id":"deleting-a-deployed-model-version-from-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Archiving a model","level":2,"index":11,"id":"archiving-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Archiving a model version","level":2,"index":12,"id":"archiving-a-model-version_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Restoring a model","level":2,"index":13,"id":"restoring-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Restoring a model version","level":2,"index":14,"id":"restoring-a-model-version_model-registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-rag/"},"sections":[{"parentId":null,"name":"Overview of RAG","level":1,"index":0,"id":"overview-of-rag_rag"},{"parentId":"overview-of-rag_rag","name":"Audience for RAG","level":2,"index":0,"id":"_audience_for_rag"},{"parentId":null,"name":"Deploying a RAG stack in a data science project","level":1,"index":1,"id":"deploying-a-rag-stack-in-a-data-science-project_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Activating the Llama Stack Operator","level":2,"index":0,"id":"activating-the-llama-stack-operator_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Deploying a Llama model with KServe","level":2,"index":1,"id":"Deploying-a-llama-model-with-kserve_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Testing your vLLM model endpoints","level":2,"index":2,"id":"testing-your-vllm-model-endpoints_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Deploying a LlamaStackDistribution instance","level":2,"index":3,"id":"deploying-a-llamastackdistribution-instance_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Ingesting content into a Llama model","level":2,"index":4,"id":"ingesting-content-into-a-llama-model_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Querying ingested content in a Llama model","level":2,"index":5,"id":"querying-ingested-content-in-a-llama-model_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Preparing documents with Docling for Llama Stack retrieval","level":2,"index":6,"id":"preparing-documents-with-docling-for-llama-stack-retrieval_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"About Llama stack search types","level":2,"index":7,"id":"about-llama-stack-search-types_rag"},{"parentId":"about-llama-stack-search-types_rag","name":"Supported search modes","level":3,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":4,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":4,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":4,"index":2,"id":"_hybrid_search"},{"parentId":"about-llama-stack-search-types_rag","name":"Retrieval database support","level":3,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/_artifacts/document-attributes-global/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/bias-monitoring-tutorial/"},"sections":[{"parentId":null,"name":"Introduction","level":1,"index":0,"id":"t-bias-introduction_bias-tutorial"},{"parentId":"t-bias-introduction_bias-tutorial","name":"About the example models","level":2,"index":0,"id":"_about_the_example_models"},{"parentId":null,"name":"Setting up your environment","level":1,"index":1,"id":"t-bias-setting-up-your-environment_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Downloading the tutorial files","level":2,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Logging in to the OpenShift cluster from the command line","level":2,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Configuring monitoring for the model serving platform","level":2,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Enabling the TrustyAI component","level":2,"index":3,"id":"enabling-trustyai-component_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Setting up a project","level":2,"index":4,"id":"_setting_up_a_project"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Authenticating the TrustyAI service","level":2,"index":5,"id":"_authenticating_the_trustyai_service"},{"parentId":null,"name":"Deploying models","level":1,"index":2,"id":"t-bias-deploying-models_bias-tutorial"},{"parentId":null,"name":"Sending training data to the models","level":1,"index":3,"id":"t-bias-sending-training-data-to-the-models_bias-tutorial"},{"parentId":null,"name":"Labeling data fields","level":1,"index":4,"id":"t-bias-labeling-data-fields_bias-tutorial"},{"parentId":null,"name":"Checking model fairness","level":1,"index":5,"id":"t-bias-checking-model-fairness_bias-tutorial"},{"parentId":null,"name":"Scheduling a fairness metric request","level":1,"index":6,"id":"t-bias-scheduling-a-fairness-metric-request_bias-tutorial"},{"parentId":null,"name":"Scheduling an identity metric request","level":1,"index":7,"id":"t-bias-scheduling-an-identity-metric-request_bias-tutorial"},{"parentId":null,"name":"Simulating real world data","level":1,"index":8,"id":"t-bias-simulating-real-world-data_bias-tutorial"},{"parentId":null,"name":"Reviewing the results","level":1,"index":9,"id":"t-bias-reviewing-the-results_bias-tutorial"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"Are the models biased?","level":2,"index":0,"id":"_are_the_models_biased"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"How does the production data compare to the training data?","level":2,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/collaborating-on-jupyter-notebooks-by-using-git/"},"sections":[{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":1,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_{context}"},{"parentId":null,"name":"Updating your project with changes from a remote Git repository","level":1,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_{context}"},{"parentId":null,"name":"Pushing project changes to a Git repository","level":1,"index":3,"id":"pushing-project-changes-to-a-git-repository_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/collaborating-on-workbenches-in-code-server-by-using-git/"},"sections":[{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using code-server","level":1,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-code-server_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to code-server from a Git repository by using the CLI","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli_{context}"},{"parentId":null,"name":"Updating your project in code-server with changes from a remote Git repository","level":1,"index":2,"id":"updating-your-project-in-code-server-with-changes-from-a-remote-git-repository_{context}"},{"parentId":null,"name":"Pushing project changes in code-server to a Git repository","level":1,"index":3,"id":"pushing-project-changes-in-code-server-to-a-git-repository_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-cluster-storage/"},"sections":[{"parentId":null,"name":"About persistent storage","level":1,"index":0,"id":"about-persistent-storage_{context}"},{"parentId":"about-persistent-storage_{context}","name":"Storage classes in {productname-short}","level":2,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":"about-persistent-storage_{context}","name":"Access modes","level":2,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":3,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":null,"name":"Adding cluster storage to your data science project","level":1,"index":1,"id":"adding-cluster-storage-to-your-data-science-project_{context}"},{"parentId":null,"name":"Updating cluster storage","level":1,"index":2,"id":"updating-cluster-storage_{context}"},{"parentId":null,"name":"Changing the storage class for an existing cluster storage instance","level":1,"index":3,"id":"changing-the-storage-class-for-an-existing-cluster-storage-instance_{context}"},{"parentId":null,"name":"Deleting cluster storage from a data science project","level":1,"index":4,"id":"deleting-cluster-storage-from-a-data-science-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-the-guardrails-orchestrator-service/"},"sections":[{"parentId":null,"name":"Deploying the Guardrails Orchestrator service","level":1,"index":0,"id":"deploying-the-guardrails-orchestrator-service_{context}"},{"parentId":null,"name":"Guardrails Orchestrator parameters","level":1,"index":1,"id":"guardrails-orchestrator-parameters_{context}"},{"parentId":null,"name":"Monitoring user inputs with the Guardrails Orchestrator service","level":1,"index":2,"id":"guardrails-orchestrator-hap-scenario_{context}"},{"parentId":null,"name":"Configuring the regex detector and guardrails gateway","level":1,"index":3,"id":"configuring-regex-guardrails-gateway_{context}"},{"parentId":"configuring-regex-guardrails-gateway_{context}","name":"Sending requests to the regex detector","level":2,"index":0,"id":"sending-requests-to-the-regex-detector_{context}"},{"parentId":"configuring-regex-guardrails-gateway_{context}","name":"Querying using guardrails gateway","level":2,"index":1,"id":"querying-using-guardrails-gateway_{context}"},{"parentId":null,"name":"Configuring the OpenTelemetry exporter","level":1,"index":4,"id":"configuring-the-opentelemetry-exporter_{context}"},{"parentId":null,"name":"Using Hugging Face models with Guardrails Orchestrator","level":1,"index":5,"id":"using-hugging-face-models-with-guardrails-orchestrator_{context}"},{"parentId":null,"name":"Configuring the Guardrails Detector Hugging Face serving runtime","level":1,"index":6,"id":"configuring-the-guardrails-detector-hugging-face-serving-runtime_{context}"},{"parentId":null,"name":"Using a Hugging Face Prompt Injection detector with the Guardrails Orchestrator","level":1,"index":7,"id":"using-a-hugging-face-prompt-injection-detector-with-guardrails-orchestrator_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-trustyai/"},"sections":[{"parentId":null,"name":"Configuring monitoring for your model serving platform","level":1,"index":0,"id":"configuring-monitoring-for-your-model-serving-platform_{context}"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":1,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Configuring TrustyAI with a database","level":1,"index":2,"id":"configuring-trustyai-with-a-database_{context}"},{"parentId":null,"name":"Installing the TrustyAI service for a project","level":1,"index":3,"id":"installing-trustyai-service_{context}"},{"parentId":"installing-trustyai-service_{context}","name":"Installing the TrustyAI service by using the dashboard","level":2,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":"installing-trustyai-service_{context}","name":"Installing the TrustyAI service by using the CLI","level":2,"index":1,"id":"installing-trustyai-service-using-cli_{context}"},{"parentId":null,"name":"Enabling TrustyAI Integration with standard model deployment","level":1,"index":4,"id":"enabling-trustyai-kserve-integration_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-and-importing-jupyter-notebooks/"},"sections":[{"parentId":null,"name":"Creating a Jupyter notebook","level":1,"index":0,"id":"creating-a-jupyter-notebook_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to JupyterLab from local storage","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_{context}"},{"parentId":null,"name":"Additional resources","level":1,"index":2,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-code-server-workbenches/"},"sections":[{"parentId":null,"name":"Creating a workbench","level":1,"index":0,"id":"creating-a-project-workbench_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to code-server from local storage","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-local-storage_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-custom-workbench-images/"},"sections":[{"parentId":null,"name":"Creating a custom image from a default {productname-short} image","level":1,"index":0,"id":"creating-a-custom-image-from-default-image_custom-images"},{"parentId":null,"name":"Creating a custom image from your own image","level":1,"index":1,"id":"creating-a-custom-image-from-your-own-image_custom-images"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Basic guidelines for creating your own workbench image","level":2,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Advanced guidelines for creating your own workbench image","level":2,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Enabling custom images in {productname-short}","level":1,"index":2,"id":"enabling-custom-images_custom-images"},{"parentId":null,"name":"Importing a custom workbench image","level":1,"index":3,"id":"importing-a-custom-workbench-image_custom-images"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-component-deployment-resources/"},"sections":[{"parentId":null,"name":"Overview of component resource customization","level":1,"index":0,"id":"overview-of-component-resource-customization_managing-resources"},{"parentId":null,"name":"Customizing component resources","level":1,"index":1,"id":"customizing-component-resources_managing-resources"},{"parentId":null,"name":"Disabling component resource customization","level":1,"index":2,"id":"disabling-component-resource-customization_managing-resources"},{"parentId":null,"name":"Re-enabling component resource customization","level":1,"index":3,"id":"reenabling-component-resource-customization_managing-resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-the-dashboard/"},"sections":[{"parentId":null,"name":"Editing the dashboard configuration","level":1,"index":0,"id":"editing-the-dashboard-configuration_dashboard"},{"parentId":null,"name":"Dashboard configuration options","level":1,"index":1,"id":"ref-dashboard-configuration-options_dashboard"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-your-feature-store-configuration/"},"sections":[{"parentId":null,"name":"Specifying to use a feature project from a Git repository","level":1,"index":0,"id":"specifying-to-use-a-feature-project-from-git-repository_{context}"},{"parentId":null,"name":"Configuring an offline store","level":1,"index":1,"id":"configuring-an-offline-store_{context}"},{"parentId":null,"name":"Configuring an online store","level":1,"index":2,"id":"configuring-an-online-store_{context}"},{"parentId":null,"name":"Configuring the feature registry","level":1,"index":3,"id":"configuring-the-feature-registry_{context}"},{"parentId":null,"name":"Example PVC configuration","level":1,"index":4,"id":"ref-example-pvc-configuration_{context}"},{"parentId":null,"name":"Configuring role-based access control","level":1,"index":5,"id":"configuring-role-based-access-control_{context}"},{"parentId":"configuring-role-based-access-control_{context}","name":"Default authorization configuration","level":2,"index":0,"id":"ref-default-authorization-configuration_{context}"},{"parentId":"configuring-role-based-access-control_{context}","name":"Example OIDC Authorization configuration","level":2,"index":1,"id":"ref-example-oidc-authorization-configuration_{context}"},{"parentId":"configuring-role-based-access-control_{context}","name":"Example Kubernetes Authorization configuration","level":2,"index":2,"id":"ref-example-kubernetes-authorization-configuration_{context}"},{"parentId":null,"name":"Editing an existing feature store instance","level":1,"index":6,"id":"editing-an-existing-feature-store-instance_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/deploying-a-rag-stack-in-a-data-science-project/"},"sections":[{"parentId":null,"name":"Activating the Llama Stack Operator","level":1,"index":0,"id":"activating-the-llama-stack-operator_{context}"},{"parentId":null,"name":"Deploying a Llama model with KServe","level":1,"index":1,"id":"Deploying-a-llama-model-with-kserve_{context}"},{"parentId":null,"name":"Testing your vLLM model endpoints","level":1,"index":2,"id":"testing-your-vllm-model-endpoints_{context}"},{"parentId":null,"name":"Deploying a LlamaStackDistribution instance","level":1,"index":3,"id":"deploying-a-llamastackdistribution-instance_{context}"},{"parentId":null,"name":"Ingesting content into a Llama model","level":1,"index":4,"id":"ingesting-content-into-a-llama-model_{context}"},{"parentId":null,"name":"Querying ingested content in a Llama model","level":1,"index":5,"id":"querying-ingested-content-in-a-llama-model_{context}"},{"parentId":null,"name":"Preparing documents with Docling for Llama Stack retrieval","level":1,"index":6,"id":"preparing-documents-with-docling-for-llama-stack-retrieval_{context}"},{"parentId":null,"name":"About Llama stack search types","level":1,"index":7,"id":"about-llama-stack-search-types_{context}"},{"parentId":"about-llama-stack-search-types_{context}","name":"Supported search modes","level":2,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":3,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":3,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":3,"index":2,"id":"_hybrid_search"},{"parentId":"about-llama-stack-search-types_{context}","name":"Retrieval database support","level":2,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/enabling-lab-tuning/"},"sections":[{"parentId":null,"name":"Overview of enabling LAB-tuning","level":1,"index":0,"id":"overview-of-enabling-lab-tuning_{context}"},{"parentId":"overview-of-enabling-lab-tuning_{context}","name":"Requirements for LAB-tuning","level":2,"index":0,"id":"_requirements_for_lab_tuning"},{"parentId":null,"name":"Installing the required Operators for LAB-tuning","level":1,"index":1,"id":"installing-the-required-operators-for-lab-tuning_{context}"},{"parentId":null,"name":"Installing the required components for LAB-tuning","level":1,"index":2,"id":"installing-the-required-components-for-lab-tuning_{context}"},{"parentId":null,"name":"Configuring a storage class for LAB-tuning","level":1,"index":3,"id":"configuring-a-storage-class-for-lab-tuning_{context}"},{"parentId":null,"name":"Making LAB-tuning and hardware profile features visible","level":1,"index":4,"id":"making-lab-tuning-and-hardware-profile-features-visible_{context}"},{"parentId":null,"name":"Creating a model registry for LAB-tuning","level":1,"index":5,"id":"creating-a-model-registry-for-lab-tuning_{context}"},{"parentId":null,"name":"Creating a hardware profile for LAB-tuning","level":1,"index":6,"id":"creating-a-hardware-profile-for-lab-tuning_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/enforcing-local-queues/"},"sections":[{"parentId":null,"name":"Enforcing the local-queue labeling policy for all projects","level":1,"index":0,"id":"enforcing-lqlabel-all_{context}"},{"parentId":null,"name":"Disabling the local-queue labeling policy for all projects","level":1,"index":1,"id":"disabling-lqlabel-all_{context}"},{"parentId":null,"name":"Enforcing the local-queue labeling policy for some projects only","level":1,"index":2,"id":"enforcing-lqlabel-some_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/evaluating-large-language-models/"},"sections":[{"parentId":null,"name":"Setting up LM-Eval","level":1,"index":0,"id":"setting-up-lmeval_{context}"},{"parentId":null,"name":"LM-Eval evaluation job","level":1,"index":1,"id":"lmeval-evaluation-job_{context}"},{"parentId":null,"name":"LM-Eval evaluation job properties","level":1,"index":2,"id":"lmeval-evaluation-job-properties_{context}"},{"parentId":"lmeval-evaluation-job-properties_{context}","name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":2,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"},{"parentId":null,"name":"LM-Eval scenarios","level":1,"index":3,"id":"lmeval-scenarios_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Accessing Hugging Face models with an environment variable token","level":2,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using a custom Unitxt card","level":2,"index":1,"id":"using-a-custom-unitxt-card_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using PVCs as storage","level":2,"index":2,"id":"using-pvcs-as-storage_{context}"},{"parentId":"using-pvcs-as-storage_{context}","name":"Managed PVCs","level":3,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_{context}","name":"Existing PVCs","level":3,"index":1,"id":"_existing_pvcs"},{"parentId":"lmeval-scenarios_{context}","name":"Using a KServe Inference Service","level":2,"index":3,"id":"using-a-kserve-inference-service_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Setting up LM-Eval S3 Support","level":2,"index":4,"id":"setting-up-lmeval-s3-support_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using LLM-as-a-Judge metrics with LM-Eval","level":2,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/example-kfto-pytorch-training-scripts/"},"sections":[{"parentId":null,"name":"Example Training Operator PyTorch training script: NCCL","level":1,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training script: DDP","level":1,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training script: FSDP","level":1,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/fine-tuning-a-model-by-using-kubeflow-training/"},"sections":[{"parentId":null,"name":"Configuring the fine-tuning job","level":1,"index":0,"id":"configuring-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Running the fine-tuning job","level":1,"index":1,"id":"running-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Deleting the fine-tuning job","level":1,"index":2,"id":"deleting-the-fine-tuning-job_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v1/"},"sections":[{"parentId":null,"name":"Installing the Open Data Hub Operator version 1","level":1,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":null,"name":"Creating a new project for your Open Data Hub instance","level":1,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":null,"name":"Adding an Open Data Hub instance","level":1,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":3,"id":"accessing-the-odh-dashboard_installv1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v2/"},"sections":[{"parentId":null,"name":"Configuring custom namespaces","level":1,"index":0,"id":"configuring-custom-namespaces"},{"parentId":null,"name":"Installing the Open Data Hub Operator version 2","level":1,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":2,"id":"installing-odh-components_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/lmeval-scenarios/"},"sections":[{"parentId":null,"name":"Accessing Hugging Face models with an environment variable token","level":1,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_{context}"},{"parentId":null,"name":"Using a custom Unitxt card","level":1,"index":1,"id":"using-a-custom-unitxt-card_{context}"},{"parentId":null,"name":"Using PVCs as storage","level":1,"index":2,"id":"using-pvcs-as-storage_{context}"},{"parentId":"using-pvcs-as-storage_{context}","name":"Managed PVCs","level":2,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_{context}","name":"Existing PVCs","level":2,"index":1,"id":"_existing_pvcs"},{"parentId":null,"name":"Using a KServe Inference Service","level":1,"index":3,"id":"using-a-kserve-inference-service_{context}"},{"parentId":null,"name":"Setting up LM-Eval S3 Support","level":1,"index":4,"id":"setting-up-lmeval-s3-support_{context}"},{"parentId":null,"name":"Using LLM-as-a-Judge metrics with LM-Eval","level":1,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-access-to-data-science-projects/"},"sections":[{"parentId":null,"name":"Configuring access to a data science project","level":1,"index":0,"id":"configuring-access-to-a-data-science-project_{context}"},{"parentId":null,"name":"Sharing access to a data science project","level":1,"index":1,"id":"sharing-access-to-a-data-science-project_{context}"},{"parentId":null,"name":"Updating access to a data science project","level":1,"index":2,"id":"updating-access-to-a-data-science-project_{context}"},{"parentId":null,"name":"Removing access to a data science project","level":1,"index":3,"id":"removing-access-to-a-data-science-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-applications-that-show-in-the-dashboard/"},"sections":[{"parentId":null,"name":"Adding an application to the dashboard","level":1,"index":0,"id":"adding-an-application-to-the-dashboard_dashboard"},{"parentId":null,"name":"Preventing users from adding applications to the dashboard","level":1,"index":1,"id":"preventing-users-from-adding-applications-to-the-dashboard_dashboard"},{"parentId":null,"name":"Disabling applications connected to {productname-short}","level":1,"index":2,"id":"disabling-applications-connected_dashboard"},{"parentId":null,"name":"Showing or hiding information about available applications","level":1,"index":3,"id":"showing-hiding-information-about-available-applications_dashboard"},{"parentId":null,"name":"Hiding the default basic workbench application","level":1,"index":4,"id":"hiding-the-default-basic-workbench-application_dashboard"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-basic-workbenches/"},"sections":[{"parentId":null,"name":"Accessing the administration interface for basic workbenches","level":1,"index":0,"id":"accessing-the-administration-interface-for-basic-workbenches_{context}"},{"parentId":null,"name":"Starting basic workbenches owned by other users","level":1,"index":1,"id":"starting-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Accessing basic workbenches owned by other users","level":1,"index":2,"id":"accessing-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping basic workbenches owned by other users","level":1,"index":3,"id":"stopping-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping idle workbenches","level":1,"index":4,"id":"stopping-idle-workbenches_{context}"},{"parentId":null,"name":"Adding workbench pod tolerations","level":1,"index":5,"id":"adding-workbench-pod-tolerations_{context}"},{"parentId":null,"name":"Troubleshooting common problems in workbenches for administrators","level":1,"index":6,"id":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":2,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"A user&#8217;s workbench does not start","level":2,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":2,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-cluster-pvc-size/"},"sections":[{"parentId":null,"name":"Configuring the default PVC size for your cluster","level":1,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_{context}"},{"parentId":null,"name":"Restoring the default PVC size for your cluster","level":1,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-connection-types/"},"sections":[{"parentId":null,"name":"Viewing connection types","level":1,"index":0,"id":"viewing-connection-types_{context}"},{"parentId":null,"name":"Creating a connection type","level":1,"index":1,"id":"creating-a-connection-type_{context}"},{"parentId":null,"name":"Duplicating a connection type","level":1,"index":2,"id":"duplicating-a-connection-type_{context}"},{"parentId":null,"name":"Editing a connection type","level":1,"index":3,"id":"editing-a-connection-type_{context}"},{"parentId":null,"name":"Enabling a connection type","level":1,"index":4,"id":"enabling-a-connection-type_{context}"},{"parentId":null,"name":"Deleting a connection type","level":1,"index":5,"id":"deleting-a-connection-type_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-custom-training-images/"},"sections":[{"parentId":null,"name":"About base training images","level":1,"index":0,"id":"about-base-training-images_{context}"},{"parentId":null,"name":"Creating a custom training image","level":1,"index":1,"id":"creating-a-custom-training-image_{context}"},{"parentId":null,"name":"Pushing an image to the integrated OpenShift image registry","level":1,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Configuring a pipeline server","level":1,"index":0,"id":"configuring-a-pipeline-server_{context}"},{"parentId":"configuring-a-pipeline-server_{context}","name":"Configuring a pipeline server with an external Amazon RDS database","level":2,"index":0,"id":"configuring-a-pipeline-server-with-an-external-amazon-rds-db_{context}"},{"parentId":null,"name":"Defining a pipeline","level":1,"index":1,"id":"defining-a-pipeline_{context}"},{"parentId":"defining-a-pipeline_{context}","name":"Defining a pipeline by using the Kubernetes API","level":2,"index":0,"id":"defining-a-pipeline-by-using-the-kubernetes-api_{context}"},{"parentId":null,"name":"Importing a data science pipeline","level":1,"index":2,"id":"importing-a-data-science-pipeline_{context}"},{"parentId":null,"name":"Deleting a data science pipeline","level":1,"index":3,"id":"deleting-a-data-science-pipeline_{context}"},{"parentId":null,"name":"Deleting a pipeline server","level":1,"index":4,"id":"deleting-a-pipeline-server_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline server","level":1,"index":5,"id":"viewing-the-details-of-a-pipeline-server_{context}"},{"parentId":null,"name":"Viewing existing pipelines","level":1,"index":6,"id":"viewing-existing-pipelines_{context}"},{"parentId":null,"name":"Overview of pipeline versions","level":1,"index":7,"id":"overview-of-pipeline-versions_{context}"},{"parentId":null,"name":"Uploading a pipeline version","level":1,"index":8,"id":"uploading-a-pipeline-version_{context}"},{"parentId":null,"name":"Deleting a pipeline version","level":1,"index":9,"id":"deleting-a-pipeline-version_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline version","level":1,"index":10,"id":"viewing-the-details-of-a-pipeline-version_{context}"},{"parentId":null,"name":"Downloading a data science pipeline version","level":1,"index":11,"id":"downloading-a-data-science-pipeline-version_{context}"},{"parentId":null,"name":"Overview of data science pipelines caching","level":1,"index":12,"id":"overview-of-data-science-pipelines-caching_{context}"},{"parentId":"overview-of-data-science-pipelines-caching_{context}","name":"Caching criteria","level":2,"index":0,"id":"_caching_criteria"},{"parentId":"overview-of-data-science-pipelines-caching_{context}","name":"Viewing cached steps in the {productname-short} user interface","level":2,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"},{"parentId":"overview-of-data-science-pipelines-caching_{context}","name":"Controlling caching in data science pipelines","level":2,"index":2,"id":"controlling-caching-in-data-science-pipelines_{context}"},{"parentId":"controlling-caching-in-data-science-pipelines_{context}","name":"Disabling caching for individual tasks","level":3,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":"controlling-caching-in-data-science-pipelines_{context}","name":"Disabling caching for a pipeline at submit time","level":3,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":"controlling-caching-in-data-science-pipelines_{context}","name":"Disabling caching for a pipeline at compile time","level":3,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":"controlling-caching-in-data-science-pipelines_{context}","name":"Disabling caching for all pipelines (pipeline server)","level":3,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-distributed-workloads/"},"sections":[{"parentId":null,"name":"Overview of Kueue resources","level":1,"index":0,"id":"overview-of-kueue-resources_{context}"},{"parentId":"overview-of-kueue-resources_{context}","name":"Resource flavor","level":2,"index":0,"id":"_resource_flavor"},{"parentId":"overview-of-kueue-resources_{context}","name":"Cluster queue","level":2,"index":1,"id":"_cluster_queue"},{"parentId":"overview-of-kueue-resources_{context}","name":"Local queue","level":2,"index":2,"id":"_local_queue"},{"parentId":null,"name":"Example Kueue resource configurations","level":1,"index":1,"id":"ref-example-kueue-resource-configurations_{context}"},{"parentId":"ref-example-kueue-resource-configurations_{context}","name":"NVIDIA GPUs without shared cohort","level":2,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":3,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":3,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":3,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":3,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":"ref-example-kueue-resource-configurations_{context}","name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":2,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":3,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":3,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":3,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":3,"index":3,"id":"_nvidia_gpu_cluster_queue"},{"parentId":null,"name":"Configuring quota management for distributed workloads","level":1,"index":2,"id":"configuring-quota-management-for-distributed-workloads_{context}"},{"parentId":null,"name":"Enforcing the use of local queues","level":1,"index":3,"id":"enforcing-local-queues_{context}"},{"parentId":"enforcing-local-queues_{context}","name":"Enforcing the local-queue labeling policy for all projects","level":2,"index":0,"id":"enforcing-lqlabel-all_{context}"},{"parentId":"enforcing-local-queues_{context}","name":"Disabling the local-queue labeling policy for all projects","level":2,"index":1,"id":"disabling-lqlabel-all_{context}"},{"parentId":"enforcing-local-queues_{context}","name":"Enforcing the local-queue labeling policy for some projects only","level":2,"index":2,"id":"enforcing-lqlabel-some_{context}"},{"parentId":null,"name":"Configuring the CodeFlare Operator","level":1,"index":4,"id":"configuring-the-codeflare-operator_{context}"},{"parentId":null,"name":"Configuring a cluster for RDMA","level":1,"index":5,"id":"configuring-a-cluster-for-rdma_{context}"},{"parentId":null,"name":"Troubleshooting common problems with distributed workloads for administrators","level":1,"index":6,"id":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster is in a suspended state","level":2,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster is in a failed state","level":2,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user receives a \"failed to call webhook\" error message for the CodeFlare Operator","level":2,"index":2,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user receives a \"failed to call webhook\" error message for Kueue","level":2,"index":3,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster does not start","level":2,"index":4,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message","level":2,"index":5,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user receives a <strong>local_queue provided does not exist</strong> error message","level":2,"index":6,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user cannot create a Ray cluster or submit jobs","level":2,"index":7,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled","level":2,"index":8,"id":"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-pipeline-experiments/"},"sections":[{"parentId":null,"name":"Overview of pipeline experiments","level":1,"index":0,"id":"overview-of-pipeline-experiments_{context}"},{"parentId":null,"name":"Creating a pipeline experiment","level":1,"index":1,"id":"creating-a-pipeline-experiment_{context}"},{"parentId":null,"name":"Archiving a pipeline experiment","level":1,"index":2,"id":"archiving-a-pipeline-experiment_{context}"},{"parentId":null,"name":"Deleting an archived pipeline experiment","level":1,"index":3,"id":"deleting-an-archived-pipeline-experiment_{context}"},{"parentId":null,"name":"Restoring an archived pipeline experiment","level":1,"index":4,"id":"restoring-an-archived-pipeline-experiment_{context}"},{"parentId":null,"name":"Viewing pipeline task executions","level":1,"index":5,"id":"viewing-pipeline-task-executions_{context}"},{"parentId":null,"name":"Viewing pipeline artifacts","level":1,"index":6,"id":"viewing-pipeline-artifacts_{context}"},{"parentId":null,"name":"Comparing runs in an experiment","level":1,"index":7,"id":"comparing-runs-in-an-experiment_{context}"},{"parentId":null,"name":"Comparing runs in different experiments","level":1,"index":8,"id":"comparing-runs-in-different-experiments_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-pipeline-runs/"},"sections":[{"parentId":null,"name":"Overview of pipeline runs","level":1,"index":0,"id":"overview-of-pipeline-runs_{context}"},{"parentId":null,"name":"Storing data with data science pipelines","level":1,"index":1,"id":"storing-data-with-data-science-pipelines_{context}"},{"parentId":null,"name":"Viewing active pipeline runs","level":1,"index":2,"id":"viewing-active-pipeline-runs_{context}"},{"parentId":null,"name":"Executing a pipeline run","level":1,"index":3,"id":"executing-a-pipeline-run_{context}"},{"parentId":null,"name":"Stopping an active pipeline run","level":1,"index":4,"id":"stopping-an-active-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating an active pipeline run","level":1,"index":5,"id":"duplicating-an-active-pipeline-run_{context}"},{"parentId":null,"name":"Viewing scheduled pipeline runs","level":1,"index":6,"id":"viewing-scheduled-pipeline-runs_{context}"},{"parentId":null,"name":"Scheduling a pipeline run using a cron job","level":1,"index":7,"id":"scheduling-a-pipeline-run-using-a-cron-job_{context}"},{"parentId":null,"name":"Scheduling a pipeline run","level":1,"index":8,"id":"scheduling-a-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating a scheduled pipeline run","level":1,"index":9,"id":"duplicating-a-scheduled-pipeline-run_{context}"},{"parentId":null,"name":"Deleting a scheduled pipeline run","level":1,"index":10,"id":"deleting-a-scheduled-pipeline-run_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline run","level":1,"index":11,"id":"viewing-the-details-of-a-pipeline-run_{context}"},{"parentId":null,"name":"Viewing archived pipeline runs","level":1,"index":12,"id":"viewing-archived-pipeline-runs_{context}"},{"parentId":null,"name":"Archiving a pipeline run","level":1,"index":13,"id":"archiving-a-pipeline-run_{context}"},{"parentId":null,"name":"Restoring an archived pipeline run","level":1,"index":14,"id":"restoring-an-archived-pipeline-run_{context}"},{"parentId":null,"name":"Deleting an archived pipeline run","level":1,"index":15,"id":"deleting-an-archived-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating an archived pipeline run","level":1,"index":16,"id":"duplicating-an-archived-pipeline-run_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-python-packages-in-code-server/"},"sections":[{"parentId":null,"name":"Viewing Python packages installed on your code-server workbench","level":1,"index":0,"id":"viewing-python-packages-installed-on-your-code-server-workbench_{context}"},{"parentId":null,"name":"Installing Python packages on your code-server workbench","level":1,"index":1,"id":"installing-python-packages-on-your-code-server-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-python-packages/"},"sections":[{"parentId":null,"name":"Viewing Python packages installed on your workbench","level":1,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_{context}"},{"parentId":null,"name":"Installing Python packages on your workbench","level":1,"index":1,"id":"installing-python-packages-on-your-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-storage-classes/"},"sections":[{"parentId":null,"name":"About persistent storage","level":1,"index":0,"id":"about-persistent-storage_{context}"},{"parentId":"about-persistent-storage_{context}","name":"Storage classes in {productname-short}","level":2,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":"about-persistent-storage_{context}","name":"Access modes","level":2,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":3,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":null,"name":"Configuring storage class settings","level":1,"index":1,"id":"configuring-storage-class-settings_{context}"},{"parentId":null,"name":"Configuring the default storage class for your cluster","level":1,"index":2,"id":"configuring-the-default-storage-class-for-your-cluster_{context}"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":3,"id":"overview-of-object-storage-endpoints_{context}"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-users-and-groups/"},"sections":[{"parentId":null,"name":"Overview of user types and permissions","level":1,"index":0,"id":"overview-of-user-types-and-permissions_{context}"},{"parentId":null,"name":"Viewing {productname-short} users","level":1,"index":1,"id":"viewing-data-science-users_{context}"},{"parentId":null,"name":"Adding users to {productname-short} user groups","level":1,"index":2,"id":"adding-users-to-user-groups_{context}"},{"parentId":null,"name":"Selecting {productname-short} administrator and user groups","level":1,"index":3,"id":"selecting-admin-and-user-groups_{context}"},{"parentId":null,"name":"Deleting users","level":1,"index":4,"id":"_deleting_users"},{"parentId":"_deleting_users","name":"About deleting users and their resources","level":2,"index":0,"id":"about-deleting-users-and-resources_{context}"},{"parentId":"_deleting_users","name":"Stopping basic workbenches owned by other users","level":2,"index":1,"id":"stopping-basic-workbenches-owned-by-other-users_{context}"},{"parentId":"_deleting_users","name":"Revoking user access to basic workbenches","level":2,"index":2,"id":"revoking-user-access-to-basic-workbenches_{context}"},{"parentId":"_deleting_users","name":"Backing up storage data","level":2,"index":3,"id":"backing-up-storage-data_{context}"},{"parentId":"_deleting_users","name":"Cleaning up after deleting users","level":2,"index":4,"id":"cleaning-up-after-deleting-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-data-drift/"},"sections":[{"parentId":null,"name":"Creating a drift metric","level":1,"index":0,"id":"creating-a-drift-metric_drift-monitoring"},{"parentId":"creating-a-drift-metric_drift-monitoring","name":"Creating a drift metric by using the CLI","level":2,"index":0,"id":"creating-a-drift-metric-using-cli_drift-monitoring"},{"parentId":null,"name":"Deleting a drift metric by using the CLI","level":1,"index":1,"id":"deleting-a-drift-metric-using-cli_drift-monitoring"},{"parentId":null,"name":"Viewing data drift metrics for a model","level":1,"index":2,"id":"viewing-drift-metrics_drift-monitoring"},{"parentId":null,"name":"Using drift metrics","level":1,"index":3,"id":"using-drift-metrics_drift-monitoring"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-distributed-workloads/"},"sections":[{"parentId":null,"name":"Viewing project metrics for distributed workloads","level":1,"index":0,"id":"viewing-project-metrics-for-distributed-workloads_{context}"},{"parentId":null,"name":"Viewing the status of distributed workloads","level":1,"index":1,"id":"viewing-the-status-of-distributed-workloads_{context}"},{"parentId":null,"name":"Viewing Kueue alerts for distributed workloads","level":1,"index":2,"id":"viewing-kueue-alerts-for-distributed-workloads_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-model-bias/"},"sections":[{"parentId":null,"name":"Creating a bias metric","level":1,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":2,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":2,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Duplicating a bias metric","level":2,"index":2,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":null,"name":"Deleting a bias metric","level":1,"index":1,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":2,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":2,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":null,"name":"Viewing bias metrics for a model","level":1,"index":2,"id":"viewing-bias-metrics_bias-monitoring"},{"parentId":null,"name":"Using bias metrics","level":1,"index":3,"id":"using-bias-metrics_bias-monitoring"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-model-performance/"},"sections":[{"parentId":null,"name":"Viewing performance metrics for all models on a model server","level":1,"index":0,"id":"viewing-performance-metrics-for-model-server_monitoring-model-performance"},{"parentId":null,"name":"Viewing HTTP request metrics for a deployed model","level":1,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/preparing-lab-tuning-resources/"},"sections":[{"parentId":null,"name":"Creating a taxonomy","level":1,"index":0,"id":"creating-a-taxonomy_{context}"},{"parentId":null,"name":"Preparing a storage location for the LAB-tuned model","level":1,"index":1,"id":"preparing-a-storage-location-for-the-lab-tuned-model_{context}"},{"parentId":null,"name":"Creating a project for LAB-tuning","level":1,"index":2,"id":"creating-a-project-for-lab-tuning_{context}"},{"parentId":null,"name":"Deploying teacher and judge models","level":1,"index":3,"id":"deploying-teacher-and-judge-models_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/preparing-the-distributed-training-environment/"},"sections":[{"parentId":null,"name":"Creating a workbench for distributed training","level":1,"index":0,"id":"creating-a-workbench-for-distributed-training_{context}"},{"parentId":null,"name":"Using the cluster server and token to authenticate","level":1,"index":1,"id":"using-the-cluster-server-and-token-to-authenticate_{context}"},{"parentId":null,"name":"Managing custom training images","level":1,"index":2,"id":"managing-custom-training-images_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"About base training images","level":2,"index":0,"id":"about-base-training-images_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"Creating a custom training image","level":2,"index":1,"id":"creating-a-custom-training-image_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"Pushing an image to the integrated OpenShift image registry","level":2,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/running-kfto-based-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Using the Kubeflow Training Operator to run distributed training workloads","level":1,"index":0,"id":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":2,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorchJob resource","level":2,"index":1,"id":"creating-a-kfto-pytorchjob-resource_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":2,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Training Operator PyTorch training scripts","level":2,"index":3,"id":"example-kfto-pytorch-training-scripts_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: NCCL","level":3,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: DDP","level":3,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: FSDP","level":3,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Dockerfile for a Training Operator PyTorch training script","level":2,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Training Operator PyTorchJob resource for multi-node training","level":2,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_{context}"},{"parentId":null,"name":"Using the Training Operator SDK to run distributed training workloads","level":1,"index":1,"id":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"Configuring a training job by using the Training Operator SDK","level":2,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"Running a training job by using the Training Operator SDK","level":2,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"TrainingClient API: Job-related methods","level":2,"index":2,"id":"ref-trainingclient-api-job-related-methods_{context}"},{"parentId":null,"name":"Fine-tuning a model by using Kubeflow Training","level":1,"index":2,"id":"fine-tuning-a-model-by-using-kubeflow-training_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Configuring the fine-tuning job","level":2,"index":0,"id":"configuring-the-fine-tuning-job_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Running the fine-tuning job","level":2,"index":1,"id":"running-the-fine-tuning-job_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Deleting the fine-tuning job","level":2,"index":2,"id":"deleting-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Creating a multi-node PyTorch training job with RDMA","level":1,"index":3,"id":"creating-a-multi-node-pytorch-training-job-with-rdma_{context}"},{"parentId":null,"name":"Example Training Operator PyTorchJob resource configured to run with RDMA","level":1,"index":4,"id":"ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/running-ray-based-distributed-workloads/"},"sections":[{"parentId":null,"name":"Running distributed data science workloads from Jupyter notebooks","level":1,"index":0,"id":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Downloading the demo Jupyter notebooks from the CodeFlare SDK","level":2,"index":0,"id":"downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Running the demo Jupyter notebooks from the CodeFlare SDK","level":2,"index":1,"id":"running-the-demo-jupyter-notebooks-from-the-codeflare-sdk_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Managing Ray clusters from within a Jupyter notebook","level":2,"index":2,"id":"managing-ray-clusters-from-within-a-jupyter-notebook_{context}"},{"parentId":null,"name":"Running distributed data science workloads from data science pipelines","level":1,"index":1,"id":"running-distributed-data-science-workloads-from-ds-pipelines_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/serving-large-models/"},"sections":[{"parentId":null,"name":"About the single-model serving platform","level":1,"index":0,"id":"about-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Model-serving runtimes","level":1,"index":1,"id":"model-serving-runtimes_serving-large-models"},{"parentId":"model-serving-runtimes_serving-large-models","name":"ServingRuntime","level":2,"index":0,"id":"_servingruntime"},{"parentId":"model-serving-runtimes_serving-large-models","name":"InferenceService","level":2,"index":1,"id":"_inferenceservice"},{"parentId":null,"name":"About KServe deployment modes","level":1,"index":2,"id":"about-kserve-deployment-modes_serving-large-models"},{"parentId":"about-kserve-deployment-modes_serving-large-models","name":"Advanced mode","level":2,"index":0,"id":"_advanced_mode"},{"parentId":"about-kserve-deployment-modes_serving-large-models","name":"Standard mode","level":2,"index":1,"id":"_standard_mode"},{"parentId":null,"name":"Installing KServe","level":1,"index":3,"id":"installing-kserve_serving-large-models"},{"parentId":null,"name":"Deploying models by using the single-model serving platform","level":1,"index":4,"id":"deploying-models-using-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Enabling the single-model serving platform","level":2,"index":0,"id":"enabling-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a custom model-serving runtime for the single-model serving platform","level":2,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a tested and verified model-serving runtime for the single-model serving platform","level":2,"index":2,"id":"adding-a-tested-and-verified-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models on the single-model serving platform","level":2,"index":3,"id":"deploying-models-on-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models by using multiple GPU nodes","level":2,"index":4,"id":"deploying-models-using-multiple-gpu-nodes_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Setting a timeout for KServe","level":2,"index":5,"id":"setting-timeout-for-kserve_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Customizing the parameters of a deployed model-serving runtime","level":2,"index":6,"id":"customizing-parameters-serving-runtime_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Customizable model serving runtime parameters","level":2,"index":7,"id":"customizable-model-serving-runtime-parameters_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Using accelerators with vLLM","level":2,"index":8,"id":"using-accelerators-with-vllm_serving-large-models"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"NVIDIA GPUs","level":3,"index":0,"id":"_nvidia_gpus"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"Intel Gaudi accelerators","level":3,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"AMD GPUs","level":3,"index":2,"id":"_amd_gpus"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Using OCI containers for model storage","level":2,"index":9,"id":"using-oci-containers-for-model-storage_serving-large-models"},{"parentId":"using-oci-containers-for-model-storage_serving-large-models","name":"Storing a model in an OCI image","level":3,"index":0,"id":"storing-a-model-in-oci-image_serving-large-models"},{"parentId":"using-oci-containers-for-model-storage_serving-large-models","name":"Deploying a model stored in an OCI image by using the CLI","level":3,"index":1,"id":"deploying-model-stored-in-oci-image_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the authentication token for a deployed model","level":2,"index":10,"id":"accessing-authentication-token-for-deployed-model_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the inference endpoint for a deployed model","level":2,"index":11,"id":"accessing-inference-endpoint-for-deployed-model_serving-large-models"},{"parentId":null,"name":"Configuring monitoring for the single-model serving platform","level":1,"index":5,"id":"configuring-monitoring-for-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Viewing model-serving runtime metrics for the single-model serving platform","level":1,"index":6,"id":"viewing-metrics-for-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Monitoring model performance","level":1,"index":7,"id":"_monitoring_model_performance"},{"parentId":"_monitoring_model_performance","name":"Viewing performance metrics for a deployed model","level":2,"index":0,"id":"viewing-performance-metrics-for-deployed-model_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Deploying a Grafana metrics dashboard","level":2,"index":1,"id":"Deploying-a-grafana-metrics-dashboard_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Deploying a vLLM/GPU metrics dashboard on a Grafana instance","level":2,"index":2,"id":"deploying-vllm-gpu-metrics-dashboard-grafana_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Grafana metrics","level":2,"index":3,"id":"ref-grafana-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"Accelerator metrics","level":3,"index":0,"id":"ref-accelerator-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"CPU metrics","level":3,"index":1,"id":"ref-cpu-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"vLLM metrics","level":3,"index":2,"id":"ref-vllm-metrics_serving-large-models"},{"parentId":null,"name":"Optimizing model-serving runtimes","level":1,"index":8,"id":"_optimizing_model_serving_runtimes"},{"parentId":"_optimizing_model_serving_runtimes","name":"Enabling speculative decoding and multi-modal inferencing","level":2,"index":0,"id":"enabling-speculative-decoding-and-multi-modal-inferencing_serving-large-models"},{"parentId":null,"name":"Performance tuning on the single-model serving platform","level":1,"index":9,"id":"_performance_tuning_on_the_single_model_serving_platform"},{"parentId":"_performance_tuning_on_the_single_model_serving_platform","name":"Resolving CUDA out-of-memory errors","level":2,"index":0,"id":"resolving-cuda-oom-errors-for-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Supported model-serving runtimes","level":1,"index":10,"id":"supported-model-serving-runtimes_serving-large-models"},{"parentId":null,"name":"Tested and verified model-serving runtimes","level":1,"index":11,"id":"tested-verified-runtimes_serving-large-models"},{"parentId":null,"name":"Inference endpoints","level":1,"index":12,"id":"inference-endpoints_serving-large-models"},{"parentId":"inference-endpoints_serving-large-models","name":"Caikit TGIS ServingRuntime for KServe","level":2,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"Caikit Standalone ServingRuntime for KServe","level":2,"index":1,"id":"_caikit_standalone_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"TGIS Standalone ServingRuntime for KServe","level":2,"index":2,"id":"_tgis_standalone_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"OpenVINO Model Server","level":2,"index":3,"id":"_openvino_model_server"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":2,"index":4,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":2,"index":5,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM AMD GPU ServingRuntime for KServe","level":2,"index":6,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"NVIDIA Triton Inference Server","level":2,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":"inference-endpoints_serving-large-models","name":"Seldon MLServer","level":2,"index":8,"id":"_seldon_mlserver"},{"parentId":"inference-endpoints_serving-large-models","name":"Additional resources","level":2,"index":9,"id":"_additional_resources"},{"parentId":null,"name":"About the NVIDIA NIM model serving platform","level":1,"index":13,"id":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Enabling the NVIDIA NIM model serving platform","level":2,"index":0,"id":"enabling-the-nvidia-nim-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Deploying models on the NVIDIA NIM model serving platform","level":2,"index":1,"id":"deploying-models-on-the-NVIDIA-NIM-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Customizing model selection options for the NVIDIA NIM model serving platform","level":2,"index":2,"id":"Customizing-model-selection-options_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Enabling NVIDIA NIM metrics for an existing NIM deployment","level":2,"index":3,"id":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models","name":"Enabling graph generation for an existing NIM deployment","level":3,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models","name":"Enabling metrics collection for an existing NIM deployment","level":3,"index":1,"id":"_enabling_metrics_collection_for_an_existing_nim_deployment"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Viewing NVIDIA NIM metrics for a NIM model","level":2,"index":4,"id":"viewing-nvidia-nim-metrics-for-a-nim-model_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Viewing performance metrics for a NIM model","level":2,"index":5,"id":"viewing-performance-metrics-for-a-nim-model_serving-large-models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/serving-small-and-medium-sized-models/"},"sections":[{"parentId":null,"name":"Configuring model servers","level":1,"index":0,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the multi-model serving platform","level":2,"index":0,"id":"enabling-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime for the multi-model serving platform","level":2,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a tested and verified model-serving runtime for the multi-model serving platform","level":2,"index":2,"id":"adding-a-tested-and-verified-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a model server for the multi-model serving platform","level":2,"index":3,"id":"adding-a-model-server-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Deleting a model server","level":2,"index":4,"id":"deleting-a-model-server_model-serving"},{"parentId":null,"name":"Working with deployed models","level":1,"index":1,"id":"_working_with_deployed_models"},{"parentId":"_working_with_deployed_models","name":"Deploying a model by using the multi-model serving platform","level":2,"index":0,"id":"deploying-a-model-using-the-multi-model-serving-platform_model-serving"},{"parentId":"_working_with_deployed_models","name":"Viewing a deployed model","level":2,"index":1,"id":"viewing-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Updating the deployment properties of a deployed model","level":2,"index":2,"id":"updating-the-deployment-properties-of-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Deleting a deployed model","level":2,"index":3,"id":"deleting-a-deployed-model_model-serving"},{"parentId":null,"name":"Configuring monitoring for the multi-model serving platform","level":1,"index":2,"id":"configuring-monitoring-for-the-multi-model-serving-platform_model-serving"},{"parentId":null,"name":"Viewing model-serving runtime metrics for the multi-model serving platform","level":1,"index":3,"id":"viewing-metrics-for-the-multi-model-serving-platform_model-serving"},{"parentId":null,"name":"Monitoring model performance","level":1,"index":4,"id":"_monitoring_model_performance"},{"parentId":"_monitoring_model_performance","name":"Viewing performance metrics for all models on a model server","level":2,"index":0,"id":"viewing-performance-metrics-for-model-server_model-serving"},{"parentId":"_monitoring_model_performance","name":"Viewing HTTP request metrics for a deployed model","level":2,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_model-serving"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/setting-up-trustyai-for-your-project/"},"sections":[{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":0,"id":"authenticating-trustyai-service_{context}"},{"parentId":null,"name":"Uploading training data to TrustyAI","level":1,"index":1,"id":"uploading-training-data-to-trustyai_{context}"},{"parentId":null,"name":"Sending training data to TrustyAI","level":1,"index":2,"id":"sending-training-data-to-trustyai_{context}"},{"parentId":null,"name":"Labeling data fields","level":1,"index":3,"id":"labeling-data-fields_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v1-to-v2/"},"sections":[{"parentId":null,"name":"Requirements for upgrading {productname-short} version 1","level":1,"index":0,"id":"requirements-for-upgrading-odh-v1_upgradev1"},{"parentId":null,"name":"Upgrading the Open Data Hub Operator version 1","level":1,"index":1,"id":"upgrading-the-odh-operator-v1_upgradev1"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":2,"id":"installing-odh-components_upgradev1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v2/"},"sections":[{"parentId":null,"name":"Requirements for upgrading {productname-short} version 2","level":1,"index":0,"id":"requirements-for-upgrading-odh-v2_upgradev2"},{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":1,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Configuring custom namespaces","level":2,"index":0,"id":"configuring-custom-namespaces"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":2,"id":"installing-odh-components_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-basic-workbenches/"},"sections":[{"parentId":null,"name":"Starting a basic workbench","level":1,"index":0,"id":"starting-a-basic-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-connections/"},"sections":[{"parentId":null,"name":"Adding a connection to your data science project","level":1,"index":0,"id":"adding-a-connection-to-your-data-science-project_{context}"},{"parentId":null,"name":"Updating a connection","level":1,"index":1,"id":"updating-a-connection_{context}"},{"parentId":null,"name":"Deleting a connection","level":1,"index":2,"id":"deleting-a-connection_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-data-science-projects/"},"sections":[{"parentId":null,"name":"Creating a data science project","level":1,"index":0,"id":"creating-a-data-science-project_{context}"},{"parentId":null,"name":"Updating a data science project","level":1,"index":1,"id":"updating-a-data-science-project_{context}"},{"parentId":null,"name":"Deleting a data science project","level":1,"index":2,"id":"deleting-a-data-science-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-explainability/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation","level":1,"index":0,"id":"requesting-a-lime-explanation_explainers"},{"parentId":"requesting-a-lime-explanation_explainers","name":"Requesting a LIME explanation by using the CLI","level":2,"index":0,"id":"requesting-a-lime-explanation-using-CLI_explainers"},{"parentId":null,"name":"Requesting a SHAP explanation","level":1,"index":1,"id":"requesting-a-shap-explanation_explainers"},{"parentId":"requesting-a-shap-explanation_explainers","name":"Requesting a SHAP explanation by using the CLI","level":2,"index":0,"id":"requesting-a-shap-explanation-using-CLI_explainers"},{"parentId":null,"name":"Using explainers","level":1,"index":2,"id":"using-explainers_explainers"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-lab-tuning/"},"sections":[{"parentId":null,"name":"Registering a base model","level":1,"index":0,"id":"registering-a-base-model_{context}"},{"parentId":null,"name":"Starting a LAB-tuning run from the registered model","level":1,"index":1,"id":"starting-a-lab-tuning-run-from-the-registered-model_{context}"},{"parentId":null,"name":"Monitoring your LAB-tuning run","level":1,"index":2,"id":"monitoring-your-lab-tuning-run_{context}"},{"parentId":null,"name":"Reviewing and deploying your LAB-tuned model","level":1,"index":3,"id":"reviewing-and-deploying-your-lab-tuned-model_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-project-workbenches/"},"sections":[{"parentId":null,"name":"Creating a workbench and selecting an IDE","level":1,"index":0,"id":"creating-a-workbench-select-ide_{context}"},{"parentId":"creating-a-workbench-select-ide_{context}","name":"About workbench images","level":2,"index":0,"id":"about-workbench-images_{context}"},{"parentId":"creating-a-workbench-select-ide_{context}","name":"Creating a workbench","level":2,"index":1,"id":"creating-a-project-workbench_{context}"},{"parentId":null,"name":"Starting a workbench","level":1,"index":1,"id":"starting-a-workbench_{context}"},{"parentId":null,"name":"Updating a project workbench","level":1,"index":2,"id":"updating-a-project-workbench_{context}"},{"parentId":null,"name":"Deleting a workbench from a data science project","level":1,"index":3,"id":"deleting-a-workbench-from-a-data-science-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-the-kfto-sdk-to-run-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Configuring a training job by using the Training Operator SDK","level":1,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":null,"name":"Running a training job by using the Training Operator SDK","level":1,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":null,"name":"TrainingClient API: Job-related methods","level":1,"index":2,"id":"ref-trainingclient-api-job-related-methods_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/viewing-logs-and-audit-records/"},"sections":[{"parentId":null,"name":"Configuring the {productname-short} Operator logger","level":1,"index":0,"id":"configuring-the-operator-logger_{context}"},{"parentId":"configuring-the-operator-logger_{context}","name":"Viewing the {productname-short} Operator logs","level":2,"index":0,"id":"_viewing_the_productname_short_operator_logs"},{"parentId":null,"name":"Viewing audit records","level":1,"index":1,"id":"viewing-audit-records_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-the-kubeflow-training-operator-to-run-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":1,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_{context}"},{"parentId":null,"name":"Creating a Training Operator PyTorchJob resource","level":1,"index":1,"id":"creating-a-kfto-pytorchjob-resource_{context}"},{"parentId":null,"name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":1,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training scripts","level":1,"index":3,"id":"example-kfto-pytorch-training-scripts_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: NCCL","level":2,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: DDP","level":2,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: FSDP","level":2,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"},{"parentId":null,"name":"Example Dockerfile for a Training Operator PyTorch training script","level":1,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_{context}"},{"parentId":null,"name":"Example Training Operator PyTorchJob resource for multi-node training","level":1,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-certificates/"},"sections":[{"parentId":null,"name":"Understanding how {productname-short} handles certificates","level":1,"index":0,"id":"understanding-certificates_certs"},{"parentId":null,"name":"Adding certificates","level":1,"index":1,"id":"_adding_certificates"},{"parentId":null,"name":"Adding certificates to a cluster-wide CA bundle","level":1,"index":2,"id":"adding-certificates-to-a-cluster-ca-bundle_certs"},{"parentId":null,"name":"Adding certificates to a custom CA bundle","level":1,"index":3,"id":"adding-certificates-to-a-custom-ca-bundle_certs"},{"parentId":null,"name":"Using self-signed certificates with {productname-short} components","level":1,"index":4,"id":"_using_self_signed_certificates_with_productname_short_components"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Accessing S3-compatible object storage with self-signed certificates","level":2,"index":0,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Configuring a certificate for data science pipelines","level":2,"index":1,"id":"configuring-a-certificate-for-pipelines_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Configuring a certificate for workbenches","level":2,"index":2,"id":"configuring-a-certificate-for-workbenches_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Using the cluster-wide CA bundle for the single-model serving platform","level":2,"index":3,"id":"using-the-cluster-CA-bundle-for-single-model-serving_certs"},{"parentId":null,"name":"Managing certificates without the {productname-long} Operator","level":1,"index":5,"id":"managing-certificates-without-the-operator_certs"},{"parentId":null,"name":"Removing the CA bundle","level":1,"index":6,"id":"_removing_the_ca_bundle"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from all namespaces","level":2,"index":0,"id":"removing-the-ca-bundle-from-all-namespaces_certs"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from a single namespace","level":2,"index":1,"id":"removing-the-ca-bundle-from-a-single-namespace_certs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-data-in-s3-compatible-object-store/"},"sections":[{"parentId":null,"name":"Prerequisites","level":1,"index":0,"id":"s3-prerequisites_s3"},{"parentId":null,"name":"Creating an S3 client","level":1,"index":1,"id":"creating-an-s3-client_s3"},{"parentId":null,"name":"Listing available buckets in your object store","level":1,"index":2,"id":"listing-available-amazon-buckets_s3"},{"parentId":null,"name":"Creating a bucket in your object store","level":1,"index":3,"id":"creating-an-s3-bucket_s3"},{"parentId":null,"name":"Listing files in your bucket","level":1,"index":4,"id":"listing-files-in-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Downloading files from your bucket","level":1,"index":5,"id":"downloading-files-from-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Uploading files to your bucket","level":1,"index":6,"id":"uploading-files-to-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Copying files between buckets","level":1,"index":7,"id":"copying-files-to-between-buckets_s3"},{"parentId":null,"name":"Deleting files from your bucket","level":1,"index":8,"id":"Deleting-files-on-your-object-store_s3"},{"parentId":null,"name":"Deleting a bucket from your object store","level":1,"index":9,"id":"deleting-a-s3-bucket_s3"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":10,"id":"overview-of-object-storage-endpoints_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Accessing S3-compatible object storage with self-signed certificates","level":1,"index":11,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_s3"},{"parentId":null,"name":"Additional resources","level":0,"index":12,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-pipeline-logs/"},"sections":[{"parentId":null,"name":"About pipeline logs","level":1,"index":0,"id":"about-pipeline-logs_{context}"},{"parentId":null,"name":"Viewing pipeline step logs","level":1,"index":1,"id":"viewing-pipeline-step-logs_{context}"},{"parentId":null,"name":"Downloading pipeline step logs","level":1,"index":2,"id":"downloading-pipeline-step-logs_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-model-registries/"},"sections":[{"parentId":null,"name":"Registering a model","level":1,"index":0,"id":"registering-a-model_model-registry"},{"parentId":null,"name":"Registering a model from the model catalog","level":1,"index":1,"id":"registering-a-model-from-the-model-catalog_model-registry"},{"parentId":null,"name":"Registering a model version","level":1,"index":2,"id":"registering-a-model-version_model-registry"},{"parentId":null,"name":"Viewing registered models","level":1,"index":3,"id":"viewing-registered-models_model-registry"},{"parentId":null,"name":"Viewing registered model versions","level":1,"index":4,"id":"viewing-registered-model-versions_model-registry"},{"parentId":null,"name":"Editing model metadata in a model registry","level":1,"index":5,"id":"editing-model-metadata-in-a-model-registry_model-registry"},{"parentId":null,"name":"Editing model version metadata in a model registry","level":1,"index":6,"id":"editing-model-version-metadata-in-a-model-registry_model-registry"},{"parentId":null,"name":"Deploying a model version from a model registry","level":1,"index":7,"id":"deploying-a-model-version-from-a-model-registry_model-registry"},{"parentId":null,"name":"Deploying a model from the model catalog","level":1,"index":8,"id":"deploying-a-model-from-the-model-catalog_model-registry"},{"parentId":null,"name":"Editing the deployment properties of a deployed model version from a model registry","level":1,"index":9,"id":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the multi-model serving platform","level":2,"index":0,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-multi-model-serving-platform_model-registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the single-model serving platform","level":2,"index":1,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-single-model-serving-platform_model-registry"},{"parentId":null,"name":"Deleting a deployed model version from a model registry","level":1,"index":10,"id":"deleting-a-deployed-model-version-from-a-model-registry_model-registry"},{"parentId":null,"name":"Archiving a model","level":1,"index":11,"id":"archiving-a-model_model-registry"},{"parentId":null,"name":"Archiving a model version","level":1,"index":12,"id":"archiving-a-model-version_model-registry"},{"parentId":null,"name":"Restoring a model","level":1,"index":13,"id":"restoring-a-model_model-registry"},{"parentId":null,"name":"Restoring a model version","level":1,"index":14,"id":"restoring-a-model-version_model-registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-pipelines-in-jupyterlab/"},"sections":[{"parentId":null,"name":"Overview of pipelines in JupyterLab","level":1,"index":0,"id":"overview-of-pipelines-in-jupyterlab_{context}"},{"parentId":null,"name":"Accessing the pipeline editor","level":1,"index":1,"id":"accessing-the-pipeline-editor_{context}"},{"parentId":null,"name":"Creating a runtime configuration","level":1,"index":2,"id":"creating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Updating a runtime configuration","level":1,"index":3,"id":"updating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Deleting a runtime configuration","level":1,"index":4,"id":"deleting-a-runtime-configuration_{context}"},{"parentId":null,"name":"Duplicating a runtime configuration","level":1,"index":5,"id":"duplicating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Running a pipeline in JupyterLab","level":1,"index":6,"id":"running-a-pipeline-in-jupyterlab_{context}"},{"parentId":null,"name":"Exporting a pipeline in JupyterLab","level":1,"index":7,"id":"exporting-a-pipeline-in-jupyterlab_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-base-training-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-kserve-deployment-modes/"},"sections":[{"parentId":null,"name":"Advanced mode","level":1,"index":0,"id":"_advanced_mode"},{"parentId":null,"name":"Standard mode","level":1,"index":1,"id":"_standard_mode"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-llama-stack-search-types/"},"sections":[{"parentId":null,"name":"Supported search modes","level":1,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":2,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":2,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":2,"index":2,"id":"_hybrid_search"},{"parentId":null,"name":"Retrieval database support","level":1,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-model-serving/"},"sections":[{"parentId":null,"name":"Single-model serving platform","level":1,"index":0,"id":"_single_model_serving_platform"},{"parentId":null,"name":"Multi-model serving platform","level":1,"index":1,"id":"_multi_model_serving_platform"},{"parentId":null,"name":"NVIDIA NIM model serving platform","level":1,"index":2,"id":"_nvidia_nim_model_serving_platform"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-persistent-storage/"},"sections":[{"parentId":null,"name":"Storage classes in {productname-short}","level":1,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":null,"name":"Access modes","level":1,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":2,"index":0,"id":"_using_shared_storage_rwx"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-pipeline-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-authentication-token-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-hugging-face-models-with-an-environment-variable-token/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-inference-endpoint-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-administration-interface-for-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-s3-compatible-object-storage-with-self-signed-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-odh-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-your-workbench-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/activating-the-llama-stack-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-connection-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-model-server-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-tested-and-verified-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-tested-and-verified-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-application-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-certificates-to-a-cluster-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-certificates-to-a-custom-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-cluster-storage-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-workbench-pod-tolerations/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-users-to-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/allocating-additional-resources-to-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/amd-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-custom-image-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-workbench-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-workbench-overview/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/backing-up-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/before-you-begin/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/changing-the-storage-class-for-an-existing-cluster-storage-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/comparing-runs-in-an-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/comparing-runs-in-different-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-certificate-for-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-certificate-for-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-cluster-for-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-pipeline-server-with-an-external-amazon-rds-db/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-storage-class-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-an-offline-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-an-online-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-custom-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-your-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-quota-management-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-role-based-access-control/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-storage-class-settings/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-codeflare-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-feature-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-guardrails-detector-hugging-face-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-default-storage-class-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-opentelemetry-exporter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-operator-logger/"},"sections":[{"parentId":null,"name":"Viewing the {productname-short} Operator logs","level":1,"index":0,"id":"_viewing_the_productname_short_operator_logs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-trustyai-with-a-database/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/controlling-caching-in-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Disabling caching for individual tasks","level":1,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":null,"name":"Disabling caching for a pipeline at submit time","level":1,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":null,"name":"Disabling caching for a pipeline at compile time","level":1,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":null,"name":"Disabling caching for all pipelines (pipeline server)","level":1,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/copying-files-between-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-image-from-default-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-image-from-your-own-image/"},"sections":[{"parentId":null,"name":"Basic guidelines for creating your own workbench image","level":1,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Advanced guidelines for creating your own workbench image","level":1,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-training-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-drift-metric/"},"sections":[{"parentId":null,"name":"Creating a drift metric by using the CLI","level":1,"index":0,"id":"creating-a-drift-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-hardware-profile-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorch-training-script-configmap-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorchjob-resource-by-using-the-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-model-registry-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorchjob-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-project-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-taxonomy/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-workbench-for-distributed-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-workbench-select-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-project-scoped-resources-for-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-an-s3-client/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-project-scoped-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizable-model-serving-runtime-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-component-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-model-selection-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-parameters-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-a-pipeline-by-using-the-kubernetes-api/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-deployed-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-workbench-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-cluster-storage-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-feature-store-instance-in-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-grafana-metrics-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-llama-model-with-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-llamastackdistribution-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-model-stored-in-oci-image-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-single-node-openshift-using-kserve-raw-deployment-mode/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-multiple-gpu-nodes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-teacher-and-judge-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-vllm-gpu-metrics-dashboard-grafana/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-the-guardrails-orchestrator-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-a-data-science-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-files-from-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-an-existing-feature-store-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-dashboard-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-model-version-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-amd-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-custom-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-intel-gaudi-ai-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-metrics-for-existing-nim-deployment/"},"sections":[{"parentId":null,"name":"Enabling graph generation for an existing NIM deployment","level":1,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"},{"parentId":null,"name":"Enabling metrics collection for an existing NIM deployment","level":1,"index":1,"id":"_enabling_metrics_collection_for_an_existing_nim_deployment"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-feature-store-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-nvidia-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-model-registry-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-nvidia-nim-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-kserve-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enforcing-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enforcing-lqlabel-some/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/executing-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/glossary-of-common-terms/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-configuring-regex-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-hap-scenario/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-regex-using/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-querying-using-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/hiding-the-default-basic-workbench-application/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/importing-a-custom-workbench-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/importing-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ingesting-content-into-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-extensions-with-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-python-packages-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-python-packages-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-distributed-workloads-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-required-components-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-required-operators-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service/"},"sections":[{"parentId":null,"name":"Installing the TrustyAI service by using the dashboard","level":1,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Installing the TrustyAI service by using the CLI","level":1,"index":1,"id":"installing-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/intel-gaudi-ai-accelerator-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/listing-available-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/listing-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/lmeval-evaluation-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/lmeval-evaluation-job-properties/"},"sections":[{"parentId":null,"name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":1,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/logging-in/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/making-inference-requests-to-models-deployed-on-single-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/making-lab-tuning-and-hardware-profiles-features-visible/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-certificates-without-the-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-model-registry-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-ray-clusters-from-within-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/migrating-to-data-science-pipelines-2/"},"sections":[{"parentId":null,"name":"Upgrading to data science pipelines 2.0","level":1,"index":0,"id":"_upgrading_to_data_science_pipelines_2_0"},{"parentId":null,"name":"Removing data science pipelines 1.0 resources","level":1,"index":1,"id":"_removing_data_science_pipelines_1_0_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/model-serving-runtimes/"},"sections":[{"parentId":null,"name":"ServingRuntime","level":1,"index":0,"id":"_servingruntime"},{"parentId":null,"name":"InferenceService","level":1,"index":1,"id":"_inferenceservice"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/monitoring-your-lab-tuning-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/nvidia-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/optimizing-the-vllm-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/next-steps-getting-started/"},"sections":[{"parentId":null,"name":"Additional resources","level":1,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-for-getting-started/"},"sections":[{"parentId":null,"name":"Data science workflow","level":1,"index":0,"id":"_data_science_workflow"},{"parentId":null,"name":"About this guide","level":1,"index":1,"id":"_about_this_guide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-data-science-pipelines-caching/"},"sections":[{"parentId":null,"name":"Caching criteria","level":1,"index":0,"id":"_caching_criteria"},{"parentId":null,"name":"Viewing cached steps in the {productname-short} user interface","level":1,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-distributed-workloads/"},"sections":[{"parentId":null,"name":"Distributed workloads infrastructure","level":1,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":null,"name":"Types of distributed workloads","level":1,"index":1,"id":"_types_of_distributed_workloads"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-enabling-lab-tuning/"},"sections":[{"parentId":null,"name":"Requirements for LAB-tuning","level":1,"index":0,"id":"_requirements_for_lab_tuning"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-features-and-feature-store/"},"sections":[{"parentId":null,"name":"Overview of machine learning features","level":1,"index":0,"id":"_overview_of_machine_learning_features"},{"parentId":null,"name":"Overview of Feature Store","level":1,"index":1,"id":"_overview_of_feature_store"},{"parentId":null,"name":"Audience for Feature Store","level":1,"index":2,"id":"_audience_for_feature_store"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-kueue-resources/"},"sections":[{"parentId":null,"name":"Resource flavor","level":1,"index":0,"id":"_resource_flavor"},{"parentId":null,"name":"Cluster queue","level":1,"index":1,"id":"_cluster_queue"},{"parentId":null,"name":"Local queue","level":1,"index":2,"id":"_local_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-lab-tuning/"},"sections":[{"parentId":null,"name":"LAB-tuning workflow","level":1,"index":0,"id":"_lab_tuning_workflow"},{"parentId":null,"name":"Model customization page","level":1,"index":1,"id":"_model_customization_page"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-model-monitoring/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-object-storage-endpoints/"},"sections":[{"parentId":null,"name":"MinIO (On-Cluster)","level":1,"index":0,"id":"_minio_on_cluster"},{"parentId":null,"name":"Amazon S3","level":1,"index":1,"id":"_amazon_s3"},{"parentId":null,"name":"Other S3-Compatible Object Stores","level":1,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":null,"name":"Verification and Troubleshooting","level":1,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-model-registries/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-rag/"},"sections":[{"parentId":null,"name":"Audience for RAG","level":1,"index":0,"id":"_audience_for_rag"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preparing-a-storage-location-for-the-lab-tuned-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preparing-documents-with-docling-for-llama-stack-retrieval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preventing-users-from-adding-applications-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-an-image-to-the-integrated-openshift-image-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-project-changes-in-code-server-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/querying-ingested-content-in-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-accelerator-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-cpu-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/reenabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-default-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-dockerfile-for-a-kfto-pytorch-training-script/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-dashboard-configuration-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-ddp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-fsdp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-nccl/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorchjob-resource-for-multi-node-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kubernetes-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-oidc-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kueue-resource-configurations/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs without shared cohort","level":1,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":2,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":2,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":2,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":2,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":null,"name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":1,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":2,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":2,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":2,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":2,"index":3,"id":"_nvidia_gpu_cluster_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-pvc-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-grafana-metrics/"},"sections":[{"parentId":null,"name":"Accelerator metrics","level":1,"index":0,"id":"ref-accelerator-metrics_{context}"},{"parentId":null,"name":"CPU metrics","level":1,"index":1,"id":"ref-cpu-metrics_{context}"},{"parentId":null,"name":"vLLM metrics","level":1,"index":2,"id":"ref-vllm-metrics_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-supported-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-inference-endpoints/"},"sections":[{"parentId":null,"name":"Caikit TGIS ServingRuntime for KServe","level":1,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":null,"name":"Caikit Standalone ServingRuntime for KServe","level":1,"index":1,"id":"_caikit_standalone_servingruntime_for_kserve"},{"parentId":null,"name":"TGIS Standalone ServingRuntime for KServe","level":1,"index":2,"id":"_tgis_standalone_servingruntime_for_kserve"},{"parentId":null,"name":"OpenVINO Model Server","level":1,"index":3,"id":"_openvino_model_server"},{"parentId":null,"name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":1,"index":4,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":1,"index":5,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM AMD GPU ServingRuntime for KServe","level":1,"index":6,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"NVIDIA Triton Inference Server","level":1,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":null,"name":"Seldon MLServer","level":1,"index":8,"id":"_seldon_mlserver"},{"parentId":null,"name":"Additional resources","level":1,"index":9,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-tested-verified-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-trainingclient-api-job-related-methods/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-base-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-vllm-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-disabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-the-ca-bundle-from-a-single-namespace/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-lime-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-the-ca-bundle-from-all-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-lime-explanation/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation by using the CLI","level":1,"index":0,"id":"requesting-a-lime-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-shap-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-shap-explanation/"},"sections":[{"parentId":null,"name":"Requesting a SHAP explanation by using the CLI","level":1,"index":0,"id":"requesting-a-shap-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requirements-for-upgrading-odh-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/resolving-cuda-oom-errors/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requirements-for-upgrading-odh-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/reviewing-and-deploying-your-lab-tuned-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/revoking-user-access-to-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-jupyter-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-ds-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/s3-prerequisites/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run-using-a-cron-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/selecting-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sending-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-timeout-for-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-lmeval-s3-support/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sharing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/showing-hiding-information-about-available-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/specifying-to-use-a-feature-project-from-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-basic-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-lab-tuning-run-from-the-registered-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/storing-a-model-in-oci-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-idle-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/storing-data-with-data-science-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-deploying-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-checking-model-fairness/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-introduction/"},"sections":[{"parentId":null,"name":"About the example models","level":1,"index":0,"id":"_about_the_example_models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-reviewing-the-results/"},"sections":[{"parentId":null,"name":"Are the models biased?","level":1,"index":0,"id":"_are_the_models_biased"},{"parentId":null,"name":"How does the production data compare to the training data?","level":1,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-scheduling-a-fairness-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-scheduling-an-identity-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-sending-training-data-to-the-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-simulating-real-world-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-setting-up-your-environment/"},"sections":[{"parentId":null,"name":"Downloading the tutorial files","level":1,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":null,"name":"Logging in to the OpenShift cluster from the command line","level":1,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":null,"name":"Configuring monitoring for the model serving platform","level":1,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":3,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Setting up a project","level":1,"index":4,"id":"_setting_up_a_project"},{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":5,"id":"_authenticating_the_trustyai_service"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/testing-your-vllm-model-endpoints/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-workbenches-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s workbench does not start","level":1,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-workbenches-for-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-with-distributed-workloads-for-users/"},"sections":[{"parentId":null,"name":"My Ray cluster is in a suspended state","level":1,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"My Ray cluster is in a failed state","level":1,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for the CodeFlare Operator","level":1,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for Kueue","level":1,"index":3,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"My Ray cluster does not start","level":1,"index":4,"id":"_my_ray_cluster_does_not_start"},{"parentId":null,"name":"I see a \"Default Local Queue not found\" error message","level":1,"index":5,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"I see a \"local_queue provided does not exist\" error message","level":1,"index":6,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"I cannot create a Ray cluster or submit jobs","level":1,"index":7,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"My pod provisioned by Kueue is terminated before my image is pulled","level":1,"index":8,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-with-distributed-workloads-for-administrators/"},"sections":[{"parentId":null,"name":"A user&#8217;s Ray cluster is in a suspended state","level":1,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"A user&#8217;s Ray cluster is in a failed state","level":1,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for the CodeFlare Operator","level":1,"index":2,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for Kueue","level":1,"index":3,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"A user&#8217;s Ray cluster does not start","level":1,"index":4,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":null,"name":"A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message","level":1,"index":5,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"A user receives a <strong>local_queue provided does not exist</strong> error message","level":1,"index":6,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"A user cannot create a Ray cluster or submit jobs","level":1,"index":7,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled","level":1,"index":8,"id":"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/understanding-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-dspa-component-errors/"},"sections":[{"parentId":null,"name":"Common errors across DSP components","level":1,"index":0,"id":"_common_errors_across_dsp_components"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-workbench-settings-by-restarting-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/upgrading-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-project-in-code-server-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-code-server-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-files-to-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-custom-unitxt-card/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-accelerators-with-vllm/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs","level":1,"index":0,"id":"_nvidia_gpus"},{"parentId":null,"name":"Intel Gaudi accelerators","level":1,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":null,"name":"AMD GPUs","level":1,"index":2,"id":"_amd_gpus"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-hugging-face-prompt-injection-detector-with-the-guardrails-orchestrator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-kserve-inference-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-hugging-face-models-with-guardrails-orchestrator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-explainers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-llm-as-a-judge-metrics-with-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-model-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-oci-containers-for-model-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-pvcs-as-storage/"},"sections":[{"parentId":null,"name":"Managed PVCs","level":1,"index":0,"id":"_managed_pvcs"},{"parentId":null,"name":"Existing PVCs","level":1,"index":1,"id":"_existing_pvcs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-the-cluster-CA-bundle-for-single-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-the-cluster-server-and-token-to-authenticate/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/verifying-amd-gpu-availability-on-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-active-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-archived-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-audit-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-connected-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-connection-types/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-feature-store-objects-in-the-web-based-ui/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-installed-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-kueue-alerts-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-metrics-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-metrics-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-nvidia-nim-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-artifacts/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-task-executions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-project-metrics-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-python-packages-installed-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-python-packages-installed-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-registered-model-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-registered-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-status-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/working-with-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/working-with-hardware-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-base-training-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-kserve-deployment-modes/"},"sections":[{"parentId":null,"name":"Advanced mode","level":1,"index":0,"id":"_advanced_mode"},{"parentId":null,"name":"Standard mode","level":1,"index":1,"id":"_standard_mode"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-llama-stack-search-types/"},"sections":[{"parentId":null,"name":"Supported search modes","level":1,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":2,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":2,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":2,"index":2,"id":"_hybrid_search"},{"parentId":null,"name":"Retrieval database support","level":1,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-model-serving/"},"sections":[{"parentId":null,"name":"Single-model serving platform","level":1,"index":0,"id":"_single_model_serving_platform"},{"parentId":null,"name":"Multi-model serving platform","level":1,"index":1,"id":"_multi_model_serving_platform"},{"parentId":null,"name":"NVIDIA NIM model serving platform","level":1,"index":2,"id":"_nvidia_nim_model_serving_platform"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-persistent-storage/"},"sections":[{"parentId":null,"name":"Storage classes in {productname-short}","level":1,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":null,"name":"Access modes","level":1,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":2,"index":0,"id":"_using_shared_storage_rwx"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-pipeline-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-multi-node-pytorch-training-job-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-authentication-token-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-hugging-face-models-with-an-environment-variable-token/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-inference-endpoint-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-s3-compatible-object-storage-with-self-signed-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-administration-interface-for-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-odh-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-your-workbench-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/activating-the-llama-stack-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-connection-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-model-server-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-tested-and-verified-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-tested-and-verified-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-application-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-certificates-to-a-cluster-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-certificates-to-a-custom-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-cluster-storage-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-users-to-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-workbench-pod-tolerations/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/allocating-additional-resources-to-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/amd-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-custom-image-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-workbench-overview/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-workbench-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/backing-up-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/before-you-begin/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/changing-the-storage-class-for-an-existing-cluster-storage-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/comparing-runs-in-an-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-certificate-for-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/comparing-runs-in-different-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-certificate-for-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-pipeline-server-with-an-external-amazon-rds-db/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-cluster-for-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-storage-class-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-an-offline-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-an-online-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-custom-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-your-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-role-based-access-control/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-quota-management-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-storage-class-settings/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-codeflare-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-default-storage-class-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-feature-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-guardrails-detector-hugging-face-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-opentelemetry-exporter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-operator-logger/"},"sections":[{"parentId":null,"name":"Viewing the {productname-short} Operator logs","level":1,"index":0,"id":"_viewing_the_productname_short_operator_logs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-trustyai-with-a-database/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/copying-files-between-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/controlling-caching-in-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Disabling caching for individual tasks","level":1,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":null,"name":"Disabling caching for a pipeline at submit time","level":1,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":null,"name":"Disabling caching for a pipeline at compile time","level":1,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":null,"name":"Disabling caching for all pipelines (pipeline server)","level":1,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-image-from-default-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-image-from-your-own-image/"},"sections":[{"parentId":null,"name":"Basic guidelines for creating your own workbench image","level":1,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Advanced guidelines for creating your own workbench image","level":1,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-training-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-drift-metric/"},"sections":[{"parentId":null,"name":"Creating a drift metric by using the CLI","level":1,"index":0,"id":"creating-a-drift-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-hardware-profile-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorch-training-script-configmap-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorchjob-resource-by-using-the-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorchjob-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-model-registry-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-multi-node-pytorch-training-job-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-project-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-taxonomy/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-workbench-for-distributed-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-workbench-select-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-an-s3-client/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-project-scoped-resources-for-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-project-scoped-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizable-model-serving-runtime-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-component-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-model-selection-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-parameters-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-a-pipeline-by-using-the-kubernetes-api/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-deployed-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-workbench-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-cluster-storage-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-feature-store-instance-in-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-grafana-metrics-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-llama-model-with-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-llamastackdistribution-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-model-stored-in-oci-image-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-single-node-openshift-using-kserve-raw-deployment-mode/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-multiple-gpu-nodes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-teacher-and-judge-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-the-guardrails-orchestrator-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-vllm-gpu-metrics-dashboard-grafana/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-a-data-science-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-files-from-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-an-existing-feature-store-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-model-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-model-version-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-dashboard-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-amd-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-custom-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-intel-gaudi-ai-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-metrics-for-existing-nim-deployment/"},"sections":[{"parentId":null,"name":"Enabling graph generation for an existing NIM deployment","level":1,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"},{"parentId":null,"name":"Enabling metrics collection for an existing NIM deployment","level":1,"index":1,"id":"_enabling_metrics_collection_for_an_existing_nim_deployment"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-nvidia-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-feature-store-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-model-registry-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-kserve-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-nvidia-nim-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enforcing-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enforcing-lqlabel-some/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/glossary-of-common-terms/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/executing-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-hap-scenario/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-regex-using/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/hiding-the-default-basic-workbench-application/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-querying-using-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/importing-a-custom-workbench-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/importing-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ingesting-content-into-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-extensions-with-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-python-packages-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-distributed-workloads-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-python-packages-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-required-components-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-configuring-regex-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-required-operators-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service/"},"sections":[{"parentId":null,"name":"Installing the TrustyAI service by using the dashboard","level":1,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Installing the TrustyAI service by using the CLI","level":1,"index":1,"id":"installing-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/intel-gaudi-ai-accelerator-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/listing-available-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/listing-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/lmeval-evaluation-job-properties/"},"sections":[{"parentId":null,"name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":1,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/lmeval-evaluation-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/logging-in/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/making-inference-requests-to-models-deployed-on-single-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/making-lab-tuning-and-hardware-profiles-features-visible/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-certificates-without-the-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-model-registry-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-ray-clusters-from-within-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/migrating-to-data-science-pipelines-2/"},"sections":[{"parentId":null,"name":"Upgrading to data science pipelines 2.0","level":1,"index":0,"id":"_upgrading_to_data_science_pipelines_2_0"},{"parentId":null,"name":"Removing data science pipelines 1.0 resources","level":1,"index":1,"id":"_removing_data_science_pipelines_1_0_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/model-serving-runtimes/"},"sections":[{"parentId":null,"name":"ServingRuntime","level":1,"index":0,"id":"_servingruntime"},{"parentId":null,"name":"InferenceService","level":1,"index":1,"id":"_inferenceservice"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/monitoring-your-lab-tuning-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/next-steps-getting-started/"},"sections":[{"parentId":null,"name":"Additional resources","level":1,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/nvidia-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/optimizing-the-vllm-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-for-getting-started/"},"sections":[{"parentId":null,"name":"Data science workflow","level":1,"index":0,"id":"_data_science_workflow"},{"parentId":null,"name":"About this guide","level":1,"index":1,"id":"_about_this_guide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-data-science-pipelines-caching/"},"sections":[{"parentId":null,"name":"Caching criteria","level":1,"index":0,"id":"_caching_criteria"},{"parentId":null,"name":"Viewing cached steps in the {productname-short} user interface","level":1,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-distributed-workloads/"},"sections":[{"parentId":null,"name":"Distributed workloads infrastructure","level":1,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":null,"name":"Types of distributed workloads","level":1,"index":1,"id":"_types_of_distributed_workloads"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-enabling-lab-tuning/"},"sections":[{"parentId":null,"name":"Requirements for LAB-tuning","level":1,"index":0,"id":"_requirements_for_lab_tuning"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-features-and-feature-store/"},"sections":[{"parentId":null,"name":"Overview of machine learning features","level":1,"index":0,"id":"_overview_of_machine_learning_features"},{"parentId":null,"name":"Overview of Feature Store","level":1,"index":1,"id":"_overview_of_feature_store"},{"parentId":null,"name":"Audience for Feature Store","level":1,"index":2,"id":"_audience_for_feature_store"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-kueue-resources/"},"sections":[{"parentId":null,"name":"Resource flavor","level":1,"index":0,"id":"_resource_flavor"},{"parentId":null,"name":"Cluster queue","level":1,"index":1,"id":"_cluster_queue"},{"parentId":null,"name":"Local queue","level":1,"index":2,"id":"_local_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-lab-tuning/"},"sections":[{"parentId":null,"name":"LAB-tuning workflow","level":1,"index":0,"id":"_lab_tuning_workflow"},{"parentId":null,"name":"Model customization page","level":1,"index":1,"id":"_model_customization_page"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-model-monitoring/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-model-registries/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-object-storage-endpoints/"},"sections":[{"parentId":null,"name":"MinIO (On-Cluster)","level":1,"index":0,"id":"_minio_on_cluster"},{"parentId":null,"name":"Amazon S3","level":1,"index":1,"id":"_amazon_s3"},{"parentId":null,"name":"Other S3-Compatible Object Stores","level":1,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":null,"name":"Verification and Troubleshooting","level":1,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-rag/"},"sections":[{"parentId":null,"name":"Audience for RAG","level":1,"index":0,"id":"_audience_for_rag"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preparing-a-storage-location-for-the-lab-tuned-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preparing-documents-with-docling-for-llama-stack-retrieval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preventing-users-from-adding-applications-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-an-image-to-the-integrated-openshift-image-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-project-changes-in-code-server-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/querying-ingested-content-in-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/reenabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-accelerator-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-cpu-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-dashboard-configuration-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-default-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-dockerfile-for-a-kfto-pytorch-training-script/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-ddp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-fsdp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-nccl/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorchjob-resource-for-multi-node-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kubernetes-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kueue-resource-configurations/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs without shared cohort","level":1,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":2,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":2,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":2,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":2,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":null,"name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":1,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":2,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":2,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":2,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":2,"index":3,"id":"_nvidia_gpu_cluster_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-oidc-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-pvc-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-grafana-metrics/"},"sections":[{"parentId":null,"name":"Accelerator metrics","level":1,"index":0,"id":"ref-accelerator-metrics_{context}"},{"parentId":null,"name":"CPU metrics","level":1,"index":1,"id":"ref-cpu-metrics_{context}"},{"parentId":null,"name":"vLLM metrics","level":1,"index":2,"id":"ref-vllm-metrics_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-inference-endpoints/"},"sections":[{"parentId":null,"name":"Caikit TGIS ServingRuntime for KServe","level":1,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":null,"name":"Caikit Standalone ServingRuntime for KServe","level":1,"index":1,"id":"_caikit_standalone_servingruntime_for_kserve"},{"parentId":null,"name":"TGIS Standalone ServingRuntime for KServe","level":1,"index":2,"id":"_tgis_standalone_servingruntime_for_kserve"},{"parentId":null,"name":"OpenVINO Model Server","level":1,"index":3,"id":"_openvino_model_server"},{"parentId":null,"name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":1,"index":4,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":1,"index":5,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM AMD GPU ServingRuntime for KServe","level":1,"index":6,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"NVIDIA Triton Inference Server","level":1,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":null,"name":"Seldon MLServer","level":1,"index":8,"id":"_seldon_mlserver"},{"parentId":null,"name":"Additional resources","level":1,"index":9,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-supported-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-tested-verified-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-trainingclient-api-job-related-methods/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-vllm-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-base-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-disabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-the-ca-bundle-from-a-single-namespace/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-the-ca-bundle-from-all-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-lime-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-lime-explanation/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation by using the CLI","level":1,"index":0,"id":"requesting-a-lime-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-shap-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-shap-explanation/"},"sections":[{"parentId":null,"name":"Requesting a SHAP explanation by using the CLI","level":1,"index":0,"id":"requesting-a-shap-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requirements-for-upgrading-odh-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requirements-for-upgrading-odh-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/resolving-cuda-oom-errors/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/reviewing-and-deploying-your-lab-tuned-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/revoking-user-access-to-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-ds-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-jupyter-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/s3-prerequisites/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run-using-a-cron-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/selecting-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sending-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-timeout-for-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-lmeval-s3-support/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sharing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/showing-hiding-information-about-available-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/specifying-to-use-a-feature-project-from-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-basic-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-lab-tuning-run-from-the-registered-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-idle-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/storing-a-model-in-oci-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/storing-data-with-data-science-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-checking-model-fairness/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-deploying-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-introduction/"},"sections":[{"parentId":null,"name":"About the example models","level":1,"index":0,"id":"_about_the_example_models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-reviewing-the-results/"},"sections":[{"parentId":null,"name":"Are the models biased?","level":1,"index":0,"id":"_are_the_models_biased"},{"parentId":null,"name":"How does the production data compare to the training data?","level":1,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-scheduling-a-fairness-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-scheduling-an-identity-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-sending-training-data-to-the-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-setting-up-your-environment/"},"sections":[{"parentId":null,"name":"Downloading the tutorial files","level":1,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":null,"name":"Logging in to the OpenShift cluster from the command line","level":1,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":null,"name":"Configuring monitoring for the model serving platform","level":1,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":3,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Setting up a project","level":1,"index":4,"id":"_setting_up_a_project"},{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":5,"id":"_authenticating_the_trustyai_service"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-simulating-real-world-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/testing-your-vllm-model-endpoints/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-workbenches-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s workbench does not start","level":1,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-workbenches-for-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-with-distributed-workloads-for-administrators/"},"sections":[{"parentId":null,"name":"A user&#8217;s Ray cluster is in a suspended state","level":1,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"A user&#8217;s Ray cluster is in a failed state","level":1,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for the CodeFlare Operator","level":1,"index":2,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for Kueue","level":1,"index":3,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"A user&#8217;s Ray cluster does not start","level":1,"index":4,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":null,"name":"A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message","level":1,"index":5,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"A user receives a <strong>local_queue provided does not exist</strong> error message","level":1,"index":6,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"A user cannot create a Ray cluster or submit jobs","level":1,"index":7,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled","level":1,"index":8,"id":"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-dspa-component-errors/"},"sections":[{"parentId":null,"name":"Common errors across DSP components","level":1,"index":0,"id":"_common_errors_across_dsp_components"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/understanding-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-workbench-settings-by-restarting-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-with-distributed-workloads-for-users/"},"sections":[{"parentId":null,"name":"My Ray cluster is in a suspended state","level":1,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"My Ray cluster is in a failed state","level":1,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for the CodeFlare Operator","level":1,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for Kueue","level":1,"index":3,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"My Ray cluster does not start","level":1,"index":4,"id":"_my_ray_cluster_does_not_start"},{"parentId":null,"name":"I see a \"Default Local Queue not found\" error message","level":1,"index":5,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"I see a \"local_queue provided does not exist\" error message","level":1,"index":6,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"I cannot create a Ray cluster or submit jobs","level":1,"index":7,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"My pod provisioned by Kueue is terminated before my image is pulled","level":1,"index":8,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/upgrading-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-code-server-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-files-to-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-custom-unitxt-card/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-hugging-face-prompt-injection-detector-with-the-guardrails-orchestrator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-kserve-inference-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-accelerators-with-vllm/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs","level":1,"index":0,"id":"_nvidia_gpus"},{"parentId":null,"name":"Intel Gaudi accelerators","level":1,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":null,"name":"AMD GPUs","level":1,"index":2,"id":"_amd_gpus"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-project-in-code-server-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-oci-containers-for-model-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-explainers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-the-cluster-CA-bundle-for-single-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-the-cluster-server-and-token-to-authenticate/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/verifying-amd-gpu-availability-on-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-active-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-archived-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-audit-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-connected-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-connection-types/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-feature-store-objects-in-the-web-based-ui/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-installed-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-kueue-alerts-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-metrics-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-metrics-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-pvcs-as-storage/"},"sections":[{"parentId":null,"name":"Managed PVCs","level":1,"index":0,"id":"_managed_pvcs"},{"parentId":null,"name":"Existing PVCs","level":1,"index":1,"id":"_existing_pvcs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-hugging-face-models-with-guardrails-orchestrator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-nvidia-nim-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-llm-as-a-judge-metrics-with-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-artifacts/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-task-executions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-project-metrics-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-python-packages-installed-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-python-packages-installed-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-registered-model-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-registered-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-status-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/working-with-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/working-with-hardware-profiles/"},"sections":null}}}]},"asciidoc":{"html":"<div id=\"toc\" class=\"toc\">\n<div id=\"toctitle\">Table of Contents</div>\n<ul class=\"sectlevel1\">\n<li><a href=\"#selecting-admin-and-user-groups_managing-resources\">Selecting Open Data Hub administrator and user groups</a></li>\n<li><a href=\"#customizing-the-dashboard\">Customizing the dashboard</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#editing-the-dashboard-configuration_dashboard\">Editing the dashboard configuration</a></li>\n<li><a href=\"#ref-dashboard-configuration-options_dashboard\">Dashboard configuration options</a></li>\n</ul>\n</li>\n<li><a href=\"#importing-a-custom-workbench-image_managing-resources\">Importing a custom workbench image</a></li>\n<li><a href=\"#managing-cluster-pvc-size\">Managing cluster PVC size</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#configuring-the-default-pvc-size-for-your-cluster_managing-resources\">Configuring the default PVC size for your cluster</a></li>\n<li><a href=\"#restoring-the-default-pvc-size-for-your-cluster_managing-resources\">Restoring the default PVC size for your cluster</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-connection-types\">Managing connection types</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#viewing-connection-types_managing-resources\">Viewing connection types</a></li>\n<li><a href=\"#creating-a-connection-type_managing-resources\">Creating a connection type</a></li>\n<li><a href=\"#duplicating-a-connection-type_managing-resources\">Duplicating a connection type</a></li>\n<li><a href=\"#editing-a-connection-type_managing-resources\">Editing a connection type</a></li>\n<li><a href=\"#enabling-a-connection-type_managing-resources\">Enabling a connection type</a></li>\n<li><a href=\"#deleting-a-connection-type_managing-resources\">Deleting a connection type</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-storage-classes\">Managing storage classes</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#about-persistent-storage_managing-resources\">About persistent storage</a></li>\n<li><a href=\"#configuring-storage-class-settings_managing-resources\">Configuring storage class settings</a></li>\n<li><a href=\"#configuring-the-default-storage-class-for-your-cluster_managing-resources\">Configuring the default storage class for your cluster</a></li>\n<li><a href=\"#overview-of-object-storage-endpoints_managing-resources\">Overview of object storage endpoints</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-basic-workbenches\">Managing basic workbenches</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#accessing-the-administration-interface-for-basic-workbenches_managing-resources\">Accessing the administration interface for basic workbenches</a></li>\n<li><a href=\"#starting-basic-workbenches-owned-by-other-users_managing-resources\">Starting basic workbenches owned by other users</a></li>\n<li><a href=\"#accessing-basic-workbenches-owned-by-other-users_managing-resources\">Accessing basic workbenches owned by other users</a></li>\n<li><a href=\"#stopping-basic-workbenches-owned-by-other-users_managing-resources\">Stopping basic workbenches owned by other users</a></li>\n<li><a href=\"#stopping-idle-workbenches_managing-resources\">Stopping idle workbenches</a></li>\n<li><a href=\"#adding-workbench-pod-tolerations_managing-resources\">Adding workbench pod tolerations</a></li>\n<li><a href=\"#troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources\">Troubleshooting common problems in workbenches for administrators</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"preamble\">\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>As an Open Data Hub administrator, you can manage the following resources:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Open Data Hub admin and user groups</p>\n</li>\n<li>\n<p>Dashboard customization</p>\n</li>\n<li>\n<p>Custom workbench images</p>\n</li>\n<li>\n<p>Cluster PVC size</p>\n</li>\n<li>\n<p>Connection types</p>\n</li>\n<li>\n<p>Cluster storage classes</p>\n</li>\n<li>\n<p>Basic workbenches</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"selecting-admin-and-user-groups_managing-resources\">Selecting Open Data Hub administrator and user groups</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>By default, all users authenticated in OpenShift can access Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Also by default, users with <code>cluster-admin</code> permissions are Open Data Hub administrators. A <code>cluster admin</code> is a superuser that can perform any action in any project in the OpenShift cluster. When bound to a user with a local binding, they have full control over quota and every action on every resource in the project.</p>\n</div>\n<div class=\"paragraph\">\n<p>After a <code>cluster admin</code> user defines additional administrator and user groups in OpenShift, you can add those groups to Open Data Hub by selecting them in the Open Data Hub dashboard.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The groups that you want to select as administrator and user groups for Open Data Hub already exist in OpenShift Container Platform. For more information, see\n<a href=\"https://opendatahub.io/docs/managing-odh/#managing-users-and-groups\">Managing users and groups</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>User management</strong>.</p>\n</li>\n<li>\n<p>Select your Open Data Hub administrator groups: Under <strong>Data science administrator groups</strong>, click the text box and select an OpenShift group. Repeat this process to define multiple administrator groups.</p>\n</li>\n<li>\n<p>Select your Open Data Hub user groups: Under <strong>Data science user groups</strong>, click the text box and select an OpenShift group. Repeat this process to define multiple user groups.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\nThe <code>system:authenticated</code> setting allows all users authenticated in OpenShift to access Open Data Hub.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Administrator users can successfully log in to Open Data Hub and have access to the <strong>Settings</strong> navigation menu.</p>\n</li>\n<li>\n<p>Non-administrator users can successfully log in to Open Data Hub. They can also access and use individual components, such as projects and workbenches.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"customizing-the-dashboard\">Customizing the dashboard</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>The Open Data Hub dashboard provides features that are designed to work for most scenarios.\nThese features are configured in the <code>OdhDashboardConfig</code> custom resource (CR).</p>\n</div>\n<div class=\"paragraph\">\n<p>To see a description of the options in the Open Data Hub dashboard configuration, see <a href=\"https://opendatahub.io/docs/managing-resources/#ref-dashboard-configuration-options_dashboard\">Dashboard configuration options</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>As an Open Data Hub administrator, you can customize the interface of the dashboard.\nFor example, you can show or hide some of the dashboard navigation menu items.\nTo change the default settings of the dashboard, edit the <code>OdhDashboardConfig</code> CR as described in <a href=\"https://opendatahub.io/docs/managing-resources/#editing-the-dashboard-configuration_dashboard\">Editing the dashboard configuration</a>.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"editing-the-dashboard-configuration_dashboard\">Editing the dashboard configuration</h3>\n<div class=\"paragraph _abstract\">\n<p>As an Open Data Hub administrator, you can customize the interface of the dashboard by editing the dashboard configuration.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhDashboardConfig</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhDashboardConfig</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click the <code>odh-dashboard-config</code> instance to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Edit the values of the options that you want to change.</p>\n<div class=\"paragraph\">\n<p>For example, to show or hide a menu item in the dashboard navigation menu, update the <code>spec.dashboardConfig</code> section to edit the relevant dashboard configuration option.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If a dashboard configuration option is not included in the <code>OdhDashboardConfig</code> CR, the default value is used.</p>\n</div>\n<div class=\"paragraph\">\n<p>To change the default behavior for such options, edit the <code>OdhDashboardConfig</code> CR to add the missing entry to the <code>spec.dashboardConfig</code> section, and set the preferred value:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To show the feature, set the value to <code>false</code></p>\n</li>\n<li>\n<p>To hide the feature, set the value to <code>true</code></p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Example</div>\n<p>By default, the <strong>Distributed workloads</strong> menu item is shown in the dashboard navigation menu.\nTo hide this menu item, set the <code>disableDistributedWorkloads</code> value to <code>true</code>, as follows:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>disableDistributedWorkloads: true</code></pre>\n</div>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>For more information about dashboard configuration options and their default values, see <a href=\"https://opendatahub.io/docs/managing-resources/#ref-dashboard-configuration-options_dashboard\">Dashboard configuration options</a>.</p>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong> to apply your changes and then click <strong>Reload</strong> to synchronize your changes to the cluster.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Log in to Open Data Hub and verify that your dashboard configurations apply.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"ref-dashboard-configuration-options_dashboard\">Dashboard configuration options</h3>\n<div class=\"paragraph _abstract\">\n<p>The Open Data Hub dashboard includes a set of core features enabled by default that are designed to work for most scenarios.\nOpen Data Hub administrators can configure the Open Data Hub dashboard from the <code>OdhDashboardConfig</code> custom resource (CR) in OpenShift Container Platform.</p>\n</div>\n<div class=\"paragraph\">\n<p>If a dashboard configuration option is not included in the <code>OdhDashboardConfig</code> CR, the default value is used.\nTo change the default behavior for such options, edit the <code>OdhDashboardConfig</code> CR to add the missing entry to the <code>spec.dashboardConfig</code> section, and set the preferred value:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To show the feature, set the value to <code>false</code></p>\n</li>\n<li>\n<p>To hide the feature, set the value to <code>true</code></p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>For more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#editing-the-dashboard-configuration_dashboard\">Editing the dashboard configuration</a>.</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<caption class=\"title\">Table 1. Dashboard feature configuration options</caption>\n<colgroup>\n<col style=\"width: 28%;\">\n<col style=\"width: 7%;\">\n<col style=\"width: 65%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">Feature configuration option</th>\n<th class=\"tableblock halign-left valign-top\">Default</th>\n<th class=\"tableblock halign-left valign-top\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableAcceleratorProfiles</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Settings → Accelerator profiles</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p>\n<p class=\"tableblock\"><strong>Note:</strong> The <code>spec.dashboardConfig.disableAcceleratorProfiles</code> option is superseded by the <code>spec.dashboardConfig.disableHardwareProfiles</code> option.\nIf both options are set to <code>false</code>, the <code>disableHardwareProfiles</code> option overrides the <code>disableAcceleratorProfiles</code> option, and the <strong>Settings → Hardware profiles</strong> menu item is shown in the dashboard navigation menu.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableAdminConnectionTypes</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Settings → Connection types</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableBYONImageStream</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Settings → Workbench images</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableClusterManager</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Settings → Cluster settings</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableCustomServingRuntimes</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Settings → Serving runtimes</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableDistributedWorkloads</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Distributed workloads</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableFineTuning</code></p>\n<p class=\"tableblock\">(Technology Preview)</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>true</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Hides the <strong>Models → Model customization</strong> menu item in the dashboard navigation menu, and the <strong>LAB-tune</strong> menu item and button for registered model versions.\nTo show these items, set the value to <code>false</code>.</p>\n<p class=\"tableblock\">LAB-tuning is a Technology Preview feature in this Open Data Hub release.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableHardwareProfiles</code></p>\n<p class=\"tableblock\">(Technology Preview)</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>true</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Hides the <strong>Settings → Hardware profiles</strong> menu item in the dashboard navigation menu, and shows the <strong>Settings → Accelerator profiles</strong> menu item if the <code>spec.dashboardConfig.disableAcceleratorProfiles</code> value is set to <code>false</code>.\nTo show the <strong>Settings → Hardware profiles</strong> menu item in the dashboard navigation menu, set the value to <code>false</code>.</p>\n<p class=\"tableblock\">If both options are set to <code>false</code>, the <code>disableHardwareProfiles</code> option overrides the <code>disableAcceleratorProfiles</code> option, and the <strong>Settings → Hardware profiles</strong> menu item is shown in the dashboard navigation menu.</p>\n<p class=\"tableblock\">Hardware profiles is a Technology Preview feature in this Open Data Hub release.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableHome</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Home</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableInfo</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">On the <strong>Applications → Explore</strong> page, when a user clicks on an application tile, an information panel opens with more details about the application. To disable the information panel for all applications on the <strong>Applications → Explore</strong> page , set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableISVBadges</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the label on a tile that indicates whether the application is <code>Red&#160;Hat-managed</code>, <code>Partner managed</code>, or <code>Self-managed</code>. To hide these labels, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableKServe</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Enables the ability to select KServe as a model-serving platform. To disable this ability, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableKServeAuth</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Enables the ability to use authentication with KServe. To disable this ability, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableKServeMetrics</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Enables the ability to view KServe metrics. To disable this ability, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableKServeRaw</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">On the <strong>Settings → Cluster settings</strong> page, in the <strong>Single-model serving platform</strong> section, shows the <strong>Default deployment mode</strong> list.</p>\n<p class=\"tableblock\">On the <strong>Deploy model</strong> dialog when using the single-model serving platform:</p>\n<p class=\"tableblock\">&nbsp; &nbsp; &nbsp; - If the Red&#160;Hat OpenShift Serverless Operator and Red&#160;Hat OpenShift Service Mesh Operator are installed, shows the <strong>Deployment mode</strong> list.</p>\n<p class=\"tableblock\">&nbsp; &nbsp; &nbsp; - If the Red&#160;Hat OpenShift Serverless Operator and Red&#160;Hat OpenShift Service Mesh Operator are not installed, hides the <strong>Deployment mode</strong> list, and sets the deployment mode to <strong>Standard</strong>.</p>\n<p class=\"tableblock\">To hide these deployment-mode lists and set the deployment mode to <strong>Advanced</strong> when using the single-model serving platform, set the <code>spec.dashboardConfig.disableKServeRaw</code> value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableModelCatalog</code></p>\n<p class=\"tableblock\">(Technology Preview)</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>true</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Hides the <strong>Models → Model catalog</strong> menu item in the dashboard navigation menu.\nTo show this menu item, set the value to <code>false</code>.</p>\n<p class=\"tableblock\">Model catalog is a Technology Preview feature in this Open Data Hub release.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableModelMesh</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Enables the ability to select ModelMesh as a model-serving platform. To disable this ability, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableModelRegistry</code></p>\n<p class=\"tableblock\">(Technology Preview)</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Models → Model registry</strong> menu item and the <strong>Settings → Model registry settings</strong> menu item in the dashboard navigation menu. To hide these menu items, set the value to <code>true</code>.</p>\n<p class=\"tableblock\">Model registry is a Technology Preview feature in this Open Data Hub release.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableModelRegistrySecureDB</code></p>\n<p class=\"tableblock\">(Technology Preview)</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Add CA certificate to secure database connection</strong> section in the <strong>Create model registry</strong> dialog and the <strong>Edit model registry</strong> dialog. To hide this section, set the value to <code>true</code>.</p>\n<p class=\"tableblock\">Model registry is a Technology Preview feature in this Open Data Hub release.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableModelServing</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Models → Model deployments</strong> menu item in the dashboard navigation menu, and the <strong>Models</strong> tab in data science projects. To hide these items, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableNIMModelServing</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Enables the ability to select NVIDIA NIM as a model-serving platform. To disable this ability, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disablePerformanceMetrics</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Endpoint Performance</strong> tab on the <strong>Model deployments</strong> page. To hide this tab, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disablePipelines</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Data science pipelines</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableProjects</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Data science projects</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableProjectScoped</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Distinguishes between global items and project-scoped items (if project-scoped items exist) in the Open Data Hub web console. This option applies to workbench images, hardware profiles, accelerator profiles, and model-serving runtimes for KServe. To disable this functionality, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableProjectSharing</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Allows users to share access to their data science projects with other users. To prevent users from sharing data science projects, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableServingRuntimeParams</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Configuration parameters</strong> section in the <strong>Deploy model</strong> dialog and the <strong>Edit model</strong> dialog when using the single-model serving platform. To hide this section, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableStorageClasses</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Settings → Storage classes</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableSupport</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Support</strong> menu item when a user clicks the Help icon in the dashboard toolbar. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableTracking</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>true</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Disables the collection of data about Open Data Hub usage in your cluster. To enable data collection, set the value to <code>false</code>. You can also set this option in the Open Data Hub dashboard interface from the <strong>Settings → Cluster settings</strong> navigation menu.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableTrustyBiasMetrics</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Model Bias</strong> tab on the <strong>Models</strong> page. To hide this tab, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>disableUserManagement</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>false</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Settings → User management</strong> menu item in the dashboard navigation menu. To hide this menu item, set the value to <code>true</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.dashboardConfig.</code><br>\n<code>enablement</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>true</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Enables Open Data Hub administrators to add applications to the Open Data Hub dashboard <strong>Applications</strong> → <strong>Enabled</strong> page. To disable this ability, set the value to <code>false</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.groupsConfig</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">No longer used</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Read-only. To configure access to the Open Data Hub dashboard, use the <code>spec.adminGroups</code> and <code>spec.allowedGroups</code> options in the OpenShift Container Platform <code>Auth</code> resource in the <code>services.platform.opendatahub.io</code> API group.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.modelServerSizes</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>Small</code>, <code>Medium</code>, <code>Large</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Allows you to customize names and resources for model servers.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.notebookController.</code><br>\n<code>enabled</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>true</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Shows the <strong>Start basic workbench</strong> tile in the <strong>Applications</strong> section, and the <strong>Start basic workbench</strong> button on the <strong>Data science projects</strong> page. To hide these items, set the value to <code>false</code>.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.notebookSizes</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>Small</code>, <code>Medium</code>, <code>Large</code>, <code>X Large</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Allows you to customize names and resources for workbenches.\nThe Kubernetes-style sizes are shown in the drop-down menu that appears when launching a workbench with the Notebook Controller.</p>\n<p class=\"tableblock\"><strong>Note:</strong> These sizes must follow conventions. For example, requests must be smaller than limits.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>spec.templateOrder</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>[]</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Specifies the order of custom Serving Runtime templates.\nWhen the user creates a new template, it is added to this list.</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"importing-a-custom-workbench-image_managing-resources\">Importing a custom workbench image</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>You can import custom workbench images that cater to your Open Data Hub project&#8217;s specific requirements. From the <strong>Workbench images</strong> page, you can enable or disable a previously imported workbench image and create an accelerator profile or a hardware profile as a recommended accelerator for existing workbench images.</p>\n</div>\n<div class=\"paragraph\">\n<p>You must import it so that your Open Data Hub users (data scientists) can access it when they create a project workbench.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>Your custom image exists in an image registry that is accessible to Open Data Hub.</p>\n</li>\n<li>\n<p>The <strong>Settings</strong> &#8594; <strong>Workbench images</strong> dashboard navigation menu item is enabled, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#enabling-custom-images_custom-images\">Creating a custom image from a default Open Data Hub image</a>.</p>\n</li>\n<li>\n<p>If you want to associate an accelerator with the custom image that you want to import, you know the accelerator&#8217;s identifier - the unique string that identifies the hardware accelerator. You must also have enabled GPU support. This includes installing the Node Feature Discovery and NVIDIA GPU Operators. For more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Workbench images</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Workbench images</strong> page appears. Previously imported images are displayed. To enable or disable a previously imported image, on the row containing the relevant image, click the toggle in the <strong>Enable</strong> column.</p>\n</div>\n</li>\n<li>\n<p>Optional: If you want to associate an accelerator and you have not already created an accelerator profile or a hardware profile, click  <strong>Create profile</strong> on the row containing the image and complete the relevant fields. If the image does not contain an accelerator identifier, you must manually configure one before creating an associated accelerator profile or a hardware profile.</p>\n</li>\n<li>\n<p>Click <strong>Import new image</strong>. Alternatively, if no previously imported images were found, click <strong>Import image</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Import workbench image</strong> dialog appears.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Image location</strong> field, enter the URL of the repository containing the image. For example: <code>quay.io/my-repo/my-image:tag</code>, <code>quay.io/my-repo/my-image@sha256:xxxxxxxxxxxxx</code>, or\n<code>docker.io/my-repo/my-image:tag</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> field, enter an appropriate name for the image.</p>\n</li>\n<li>\n<p>Optional: In the <strong>Description</strong> field, enter a description for the image.</p>\n</li>\n<li>\n<p>Optional: From the <strong>Accelerator identifier</strong> list, select an identifier to set its accelerator as recommended with the image. If the image contains only one accelerator identifier, the identifier name displays by default.</p>\n</li>\n<li>\n<p>Optional: Add software to the image. After the import has completed, the software is added to the image&#8217;s meta-data and displayed on the workbench creation page.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click the <strong>Software</strong> tab.</p>\n</li>\n<li>\n<p>Click the <strong>Add software</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>Edit</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-edit-icon.png\" alt=\"The Edit icon\"></span>).</p>\n</li>\n<li>\n<p>Enter the <strong>Software</strong> name.</p>\n</li>\n<li>\n<p>Enter the software <strong>Version</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>) to confirm your entry.</p>\n</li>\n<li>\n<p>To add additional software, click <strong>Add software</strong>, complete the relevant fields, and confirm your entry.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: Add packages to the workbench images. After the import has completed, the packages are added to the image&#8217;s meta-data and displayed on the workbench creation page.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click the <strong>Packages</strong> tab.</p>\n</li>\n<li>\n<p>Click the  <strong>Add package</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>Edit</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-edit-icon.png\" alt=\"The Edit icon\"></span>).</p>\n</li>\n<li>\n<p>Enter the <strong>Package</strong> name. For example, if you want to include data science pipeline V2 automatically, as a runtime configuration, type <code>odh-elyra</code>.</p>\n</li>\n<li>\n<p>Enter the package <strong>Version</strong>. For example, type <code>3.16.7</code>.</p>\n</li>\n<li>\n<p>Click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>) to confirm your entry.</p>\n</li>\n<li>\n<p>To add an additional package, click <strong>Add package</strong>, complete the relevant fields, and confirm your entry.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Click <strong>Import</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The image that you imported is displayed in the table on the <strong>Workbench images</strong> page.</p>\n</li>\n<li>\n<p>Your custom image is available for selection when a user creates a workbench.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/images/managing-image-streams\">Managing image streams</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/builds_using_buildconfig/understanding-buildconfigs\">Understanding build configurations</a></p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-cluster-pvc-size\">Managing cluster PVC size</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"configuring-the-default-pvc-size-for-your-cluster_managing-resources\">Configuring the default PVC size for your cluster</h3>\n<div class=\"paragraph _abstract\">\n<p>To configure how resources are claimed within your Open Data Hub cluster, you can change the default size of the cluster&#8217;s persistent volume claim (PVC) ensuring that the storage requested matches your common storage workflow. PVCs are requests for resources in your cluster and also act as claim checks to the resource.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nChanging the PVC setting restarts the workbench pod and makes Jupyter unavailable for up to 30 seconds. As a workaround, it is recommended that you perform this action outside of your organization&#8217;s typical working day.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Cluster settings</strong>.</p>\n</li>\n<li>\n<p>Under <strong>PVC size</strong>, enter a new size in gibibytes or mebibytes.</p>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>New PVCs are created with the default storage size that you configured.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/storage/understanding-persistent-storage\">Understanding persistent storage</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"restoring-the-default-pvc-size-for-your-cluster_managing-resources\">Restoring the default PVC size for your cluster</h3>\n<div class=\"paragraph _abstract\">\n<p>To change the size of resources utilized within your Open Data Hub cluster, you can restore the default size of your cluster&#8217;s persistent volume claim (PVC).</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Cluster settings</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Restore Default</strong> to restore the default PVC size of 20GiB.</p>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>New PVCs are created with the default storage size of 20 GiB.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/storage/understanding-persistent-storage\">Understanding persistent storage</a></p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-connection-types\">Managing connection types</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>In Open Data Hub, a connection comprises environment variables along with their respective values. Data scientists can add connections to project resources, such as workbenches and model servers.</p>\n</div>\n<div class=\"paragraph\">\n<p>When a data scientist creates a connection, they start by selecting a connection type. Connection types are templates that include customizable fields and optional default values. Starting with a connection type decreases the time required by a user to add connections to data sources and sinks. Open Data Hub includes pre-installed connection types for S3-compatible object storage databases and URI-based repositories.</p>\n</div>\n<div class=\"paragraph\">\n<p>As an Open Data Hub administrator, you can manage connection types for users in your organization as follows:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>View connection types and preview user connection forms</p>\n</li>\n<li>\n<p>Create a connection type</p>\n</li>\n<li>\n<p>Duplicate an existing connection type</p>\n</li>\n<li>\n<p>Edit a connection type</p>\n</li>\n<li>\n<p>Delete a custom connection type</p>\n</li>\n<li>\n<p>Enable or disable a connection type in a project, to control whether it is available as an option to users when they create a connection</p>\n</li>\n</ul>\n</div>\n<div class=\"sect2\">\n<h3 id=\"viewing-connection-types_managing-resources\">Viewing connection types</h3>\n<div class=\"paragraph\">\n<p>As an Open Data Hub administrator, you can view the connection types that are available in a project.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Connection types</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Connection types</strong> page appears, displaying the available connection types for the current project.</p>\n</div>\n</li>\n<li>\n<p>Optionally, you can select the Options menu <span class=\"image\"><img src=\"/static/docs/images/osd-ellipsis.png\" alt=\"Options menu\"></span> and then click <strong>Preview</strong> to see how the connection form associated with the connection type appears to your users.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"creating-a-connection-type_managing-resources\">Creating a connection type</h3>\n<div class=\"paragraph _abstract\">\n<p>As an Open Data Hub administrator, you can create a connection type for users in your organization.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can create a new connection type as described in this procedure or you can create a copy of an existing connection type and edit it, as described\nin <a href=\"https://opendatahub.io/docs/managing-resources/#duplicating-a-connection-type_resource-mgmt\">Duplicating a connection type</a>.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>You know the environment variables that are required or optional for the connection type that you want to create.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Connection types</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Connection types</strong> page appears, displaying the available connection types.</p>\n</div>\n</li>\n<li>\n<p>Click <strong>Create connection type</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Create connection type</strong> form, enter the following information:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Enter a name for the connection type.</p>\n<div class=\"paragraph\">\n<p>A resource name is generated based on the name of the connection type. A resource name is the label for the underlying resource in OpenShift.</p>\n</div>\n</li>\n<li>\n<p>Optionally, edit the default resource name. Note that you cannot change the resource name after you create the connection type.</p>\n</li>\n<li>\n<p>Optionally, provide a description of the connection type.</p>\n</li>\n<li>\n<p>Specify at least one category label. By default, the category labels are database, model registry, object storage, and URI. Optionally, you can create a new category by typing the new category label in the field. You can specify more than one category.</p>\n<div class=\"paragraph\">\n<p>The category label is for descriptive purposes only. It allows you and the users in your origanization to sort the available connection types when viewing them in the Open Data Hub dashboard interface.</p>\n</div>\n</li>\n<li>\n<p>Check the <strong>Enable users in your organization to use this connection type when adding connections\"</strong> option if you want the connection type to appear in the list of connections available to users, for example, when they configure a workbench, a model server, or a pipeline.</p>\n<div class=\"paragraph\">\n<p>Note that you can also enable/disable the connection type after you create it.</p>\n</div>\n</li>\n<li>\n<p>For the <strong>Fields</strong> section, add the fields and section headings that you want your users to see in the form when they add a connection to a project resource (such as a workbench or a model server).</p>\n<div class=\"paragraph\">\n<p>Note that the connection name and description fields are included by default, so you do not need to add them.</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Optionally, select a model serving compatible type to automatically add the fields required to use its corresponding model serving method.</p>\n</li>\n<li>\n<p>Click <strong>Add field</strong> to add a field to prompt users to input information, and optionally assign default values to those fields.</p>\n</li>\n<li>\n<p>Click <strong>Add section heading</strong> to organize the fields under headings.</p>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Click <strong>Preview</strong> to open a preview of the connection form as it will appear to your users.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>On the <strong>Settings</strong> &#8594; <strong>Connection types</strong> page, the new connection type appears in the list.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"duplicating-a-connection-type_managing-resources\">Duplicating a connection type</h3>\n<div class=\"paragraph _abstract\">\n<p>As an Open Data Hub administrator, you can create a new connection type by duplicating an existing one, as described in this procedure, or you can create a new connection type as described in <a href=\"https://opendatahub.io/docs/managing-resources/#creating-a-connection-type_resource-mgmt\">Creating a connection type</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>You might also want to duplicate a connection type if you want to create versions of a specific connection type.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Connection types</strong>.</p>\n</li>\n<li>\n<p>From the list of available connection types, find the connection type that you want to duplicate.</p>\n<div class=\"paragraph\">\n<p>Optionally, you can select the Options menu <span class=\"image\"><img src=\"/static/docs/images/osd-ellipsis.png\" alt=\"Options menu\"></span> and then click <strong>Preview</strong> to see how the related connection form appears to your users.</p>\n</div>\n</li>\n<li>\n<p>Click the Options menu <span class=\"image\"><img src=\"/static/docs/images/osd-ellipsis.png\" alt=\"Options menu\"></span>, and then click <strong>Duplicate</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Create connection type</strong> form appears populated with the information from the connection type that you duplicated.</p>\n</div>\n</li>\n<li>\n<p>Edit the form according to your use case.</p>\n</li>\n<li>\n<p>Click <strong>Preview</strong> to open a preview of the connection form as it will appear to your users and verify that the form appears as you expect.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>In the <strong>Settings</strong> &#8594; <strong>Connection types</strong> page, the duplicated connection type appears in the list.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"editing-a-connection-type_managing-resources\">Editing a connection type</h3>\n<div class=\"paragraph _abstract\">\n<p>As an Open Data Hub administrator, you can edit a connection type for users in your organization.</p>\n</div>\n<div class=\"paragraph\">\n<p>Note that you cannot edit the connection types that are pre-installed with Open Data Hub. Instead, you have the option of duplicating a pre-installed connection type, as described in <a href=\"https://opendatahub.io/docs/managing-resources/#duplicating-a-connection-type_resource-mgmt\">Duplicating a connection type</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>When you edit a connection type, your edits do not apply to any existing connections that users previously created. If you want to keep track of previous versions of this connection type, consider duplicating it instead of editing it.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The connection type must exist and must not be a pre-installed connection type (which you are unable to edit).</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Connection types</strong>.</p>\n</li>\n<li>\n<p>From the list of available connection types, find the connection type that you want to edit.</p>\n</li>\n<li>\n<p>Click the Options menu <span class=\"image\"><img src=\"/static/docs/images/osd-ellipsis.png\" alt=\"Options menu\"></span>, and then click <strong>Edit</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Edit connection type</strong> form appears.</p>\n</div>\n</li>\n<li>\n<p>Edit the form fields and sections.</p>\n</li>\n<li>\n<p>Click <strong>Preview</strong> to open a preview of the connection form as it will appear to your users and verify that the form appears as you expect.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>In the <strong>Settings</strong> &#8594; <strong>Connection types</strong> page, the duplicated connection type appears in the list.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"enabling-a-connection-type_managing-resources\">Enabling a connection type</h3>\n<div class=\"paragraph\">\n<p>As an Open Data Hub administrator, you can enable or disable a connection type to control whether it is available as an option to your users when they create a connection.</p>\n</div>\n<div class=\"paragraph\">\n<p>Note that if you disable a connection type, any existing connections that your users created based on that connection type are not effected.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The connection type that you want to enable exists in your project, either pre-installed or created by a user with administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Connection types</strong>.</p>\n</li>\n<li>\n<p>From the list of available connection types, find the connection type that you want to enable or disable.</p>\n</li>\n<li>\n<p>On the row containing the connection type, click the toggle in the <strong>Enable</strong> column.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>If you enabled a connection type, it is available for selection when a user adds a connection to a project resource (for example, a workbench or model server).</p>\n</li>\n<li>\n<p>If you disabled a connection type, it does not show in the list of available connection types when a user adds a connection to a project resource.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"deleting-a-connection-type_managing-resources\">Deleting a connection type</h3>\n<div class=\"paragraph\">\n<p>As an Open Data Hub administrator, you can delete a connection type that you or another administrator created.</p>\n</div>\n<div class=\"paragraph\">\n<p>Note that you cannot delete the connection types that are pre-installed with Open Data Hub. Instead, you have the option of disabling them so that they are not visible to your users, as described in <a href=\"https://opendatahub.io/docs/managing-resources/#enabling-a-connection-type_resource-mgmt\">Enabling a connection type</a>.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The connection type must exist and must not be a pre-installed connection type (which you are unable to delete).</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Connection types</strong>.</p>\n</li>\n<li>\n<p>From the list of available connection types, find the connection type that you want to delete.</p>\n<div class=\"paragraph\">\n<p>Optionally, you can select the Options menu <span class=\"image\"><img src=\"/static/docs/images/osd-ellipsis.png\" alt=\"Options menu\"></span> and then click <strong>Preview</strong> to see how the related connection form appears to your users.</p>\n</div>\n</li>\n<li>\n<p>Click the Options menu <span class=\"image\"><img src=\"/static/docs/images/osd-ellipsis.png\" alt=\"Options menu\"></span>, and then click <strong>Delete</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Delete connection type?</strong> form, type the name of the connection type that you want to delete and then click <strong>Delete</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>In the <strong>Settings</strong> &#8594; <strong>Connection types</strong> page, the connection type no longer appears in the list.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-storage-classes\">Managing storage classes</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>OpenShift Container Platform cluster administrators use storage classes to describe the different types of storage that is available in their cluster. These storage types can represent different quality-of-service levels, backup policies, or other custom policies set by cluster administrators.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"about-persistent-storage_managing-resources\">About persistent storage</h3>\n<div class=\"paragraph _abstract\">\n<p>Open Data Hub uses persistent storage to support workbenches, project data, and model training.</p>\n</div>\n<div class=\"paragraph\">\n<p>Persistent storage is provisioned through OpenShift Container Platform storage classes and persistent volumes. Volume provisioning and data access are determined by access modes.</p>\n</div>\n<div class=\"paragraph\">\n<p>Understanding storage classes and access modes can help you choose the right storage for your use case and avoid potential risks when sharing data across multiple workbenches.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_storage_classes_in_open_data_hub\">Storage classes in Open Data Hub</h4>\n<div class=\"paragraph\">\n<p>Storage classes in Open Data Hub are available from the underlying OpenShift cluster. A storage class defines how persistent volumes are provisioned, including which storage backend is used and what access modes the provisioned volumes can support. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/storage/understanding-persistent-storage\">Dynamic provisioning</a> in the OpenShift documentation.</p>\n</div>\n<div class=\"paragraph\">\n<p>Cluster administrators create and configure storage classes in the OpenShift cluster. These storage classes provision persistent volumes that support one or more access modes, depending on the capabilities of the storage backend. Open Data Hub administrators then enable specific storage classes and access modes for use in Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>When adding cluster storage to your project or workbench, you can choose from any enabled storage classes and access modes.</p>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_access_modes\">Access modes</h4>\n<div class=\"paragraph\">\n<p>Storage classes create persistent volumes that can support different access modes, depending on the storage backend. Access modes control how a volume can be mounted and used by one or more workbenches. If a storage class allows more than one access mode, you can select the one that best fits your needs when you request storage. All persistent volumes support <code>ReadWriteOnce (RWO)</code> by default.</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<colgroup>\n<col style=\"width: 25%;\">\n<col style=\"width: 75%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">Access mode</th>\n<th class=\"tableblock halign-left valign-top\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>ReadWriteOnce (RWO)</code> (Default)</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">The storage can be attached to a single workbench or pod at a time and is ideal for most individual workloads. <code>RWO</code> is always enabled by default and cannot be disabled by the administrator.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>ReadWriteMany (RWX)</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">The storage can be attached to many workbenches simultaneously. <code>RWX</code> enables shared data access, but can introduce data risks.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>ReadOnlyMany (ROX)</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">The storage can be attached to many workbenches as read-only. <code>ROX</code> is useful for sharing reference data without allowing changes.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>ReadWriteOncePod (RWOP)</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">The storage can be attached to a single pod on a single node with read-write permissions. <code>RWOP</code> is similar to <code>RWO</code> but includes additional node-level restrictions.</p></td>\n</tr>\n</tbody>\n</table>\n<div class=\"sect4\">\n<h5 id=\"_using_shared_storage_rwx\">Using shared storage (RWX)</h5>\n<div class=\"paragraph\">\n<p>The <code>ReadWriteMany (RWX)</code> access mode allows multiple workbenches to access and write to the same storage volume at the same time. Use <code>RWX</code> access mode for collaborative work where multiple users need to access shared datasets or project files.</p>\n</div>\n<div class=\"paragraph\">\n<p>However, shared storage introduces several risks:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Data corruption or data loss</strong>: If multiple workbenches modify the same part of a file simultaneously, the data can become corrupted or lost. Ensure your applications or workflows are designed to safely handle shared access, for example, by using file locking or database transactions.</p>\n</li>\n<li>\n<p><strong>Security and privacy</strong>: If a workbench with access to shared storage is compromised, all data on that volume might be at risk. Only share sensitive data with trusted workbenches and users.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>To use shared storage safely:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Ensure that your tools or workflows are designed to work with shared storage and can manage simultaneous writes. For example, use databases or distributed data processing frameworks.</p>\n</li>\n<li>\n<p>Be cautious with changes. Deleting or editing files affects everyone who shares the volume.</p>\n</li>\n<li>\n<p>Back up your data regularly, which can help prevent data loss due to mistakes or misconfigurations.</p>\n</li>\n<li>\n<p>Limit access to RWX volumes to trusted users and secure workbenches.</p>\n</li>\n<li>\n<p>Use <code>ReadWriteMany (RWX)</code> only when collaboration on a shared volume is required. For most individual tasks, <code>ReadWriteOnce (RWO)</code> is ideal because only one workbench can write to the volume at a time.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-storage-class-settings_managing-resources\">Configuring storage class settings</h3>\n<div class=\"paragraph _abstract\">\n<p>As an Open Data Hub administrator, you can manage the following OpenShift Container Platform cluster storage class settings for use within Open Data Hub:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Display name</p>\n</li>\n<li>\n<p>Description</p>\n</li>\n<li>\n<p>Access modes</p>\n</li>\n<li>\n<p>Whether users can use the storage class when creating or editing cluster storage</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>These settings do not impact the storage class within OpenShift Container Platform.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Storage classes</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Storage classes</strong> page appears, displaying the storage classes for your cluster as defined in OpenShift Container Platform.</p>\n</div>\n</li>\n<li>\n<p>To enable or disable a storage class for users, on the row containing the storage class, click the toggle in the <strong>Enable</strong> column.</p>\n</li>\n<li>\n<p>To edit a storage class, on the row containing the storage class, click the action menu (&#8942;) and then select <strong>Edit</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Edit storage class details</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Optional: In the <strong>Display Name</strong> field, update the name for the storage class. This name is used only in Open Data Hub and does not impact the storage class within OpenShift Container Platform.</p>\n</li>\n<li>\n<p>Optional: In the <strong>Description</strong> field, update the description for the storage class. This description is used only in Open Data Hub and does not impact the storage class within OpenShift Container Platform.</p>\n</li>\n<li>\n<p>For storage classes that support multiple access modes, select an <strong>Access mode</strong> to define how the volume can be accessed. For more information, see <a href=\"https://opendatahub.io/docs/managing-resources/#about-persistent-storage_managing-resources\">About persistent storage</a>.</p>\n<div class=\"paragraph\">\n<p>Only the access modes that have been enabled for the storage class by your cluster and Open Data Hub administrators are visible.</p>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>If you enabled a storage class, the storage class is available for selection when a user adds cluster storage to a data science project or workbench.</p>\n</li>\n<li>\n<p>If you disabled a storage class, the storage class is not available for selection when a user adds cluster storage to a data science project or workbench.</p>\n</li>\n<li>\n<p>If you edited a storage class name, the updated storage class name is displayed when a user adds cluster storage to a data science project or workbench.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/storage/understanding-persistent-storage#pvc-storage-class_understanding-persistent-storage\">Storage classes in OpenShift Container Platform</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-the-default-storage-class-for-your-cluster_managing-resources\">Configuring the default storage class for your cluster</h3>\n<div class=\"paragraph _abstract\">\n<p>As an Open Data Hub administrator, you can configure the default storage class for Open Data Hub to be different from the default storage class in OpenShift Container Platform.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Storage classes</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Storage classes</strong> page appears, displaying the storage classes for your cluster as defined in OpenShift Container Platform.</p>\n</div>\n</li>\n<li>\n<p>If the storage class that you want to set as the default is not enabled, on the row containing the storage class, click the toggle in the <strong>Enable</strong> column.</p>\n</li>\n<li>\n<p>To set a storage class as the default for Open Data Hub, on the row containing the storage class, select <strong>Set as default</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>When a user adds cluster storage to a data science project or workbench, the default storage class that you configured is automatically selected.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/storage/understanding-persistent-storage#pvc-storage-class_understanding-persistent-storage\">Storage classes in OpenShift Container Platform</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"overview-of-object-storage-endpoints_managing-resources\">Overview of object storage endpoints</h3>\n<div class=\"paragraph _abstract\">\n<p>To ensure correct configuration of object storage in Open Data Hub, you must format endpoints correctly for the different types of object storage supported. These instructions are for formatting endpoints for Amazon S3, MinIO, or other S3-compatible storage solutions, minimizing configuration errors and ensuring compatibility.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Properly formatted endpoints enable connectivity and reduce the risk of misconfigurations. Use the appropriate endpoint format for your object storage type. Improper formatting might cause connection errors or restrict access to storage resources.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_minio_on_cluster\">MinIO (On-Cluster)</h4>\n<div class=\"paragraph\">\n<p>For on-cluster MinIO instances, use a local endpoint URL format. Ensure the following when configuring MinIO endpoints:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Prefix the endpoint with <code>http://</code> or <code>https://</code> depending on your MinIO security setup.</p>\n</li>\n<li>\n<p>Include the cluster IP or hostname, followed by the port number if specified.</p>\n</li>\n<li>\n<p>Use a port number if your MinIO instance requires one (default is typically <code>9000</code>).</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>Example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>http://minio-cluster.local:9000</pre>\n</div>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Verify that the MinIO instance is accessible within the cluster by checking your cluster DNS settings and network configurations.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_amazon_s3\">Amazon S3</h4>\n<div class=\"paragraph\">\n<p>When configuring endpoints for Amazon S3, use region-specific URLs. Amazon S3 endpoints generally follow this format:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Prefix the endpoint with <code>https://</code>.</p>\n</li>\n<li>\n<p>Format as <code>&lt;bucket-name&gt;.s3.&lt;region&gt;.amazonaws.com</code>, where <code>&lt;bucket-name&gt;</code> is the name of your S3 bucket, and <code>&lt;region&gt;</code> is the AWS region code (for example, <code>us-west-1</code>, <code>eu-central-1</code>).</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>Example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>https://my-bucket.s3.us-west-2.amazonaws.com</pre>\n</div>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>For improved security and compliance, ensure that your Amazon S3 bucket is in the correct region.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_other_s3_compatible_object_stores\">Other S3-Compatible Object Stores</h4>\n<div class=\"paragraph\">\n<p>For S3-compatible storage solutions other than Amazon S3, follow the specific endpoint format required by your provider. Generally, these endpoints include the following items:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>The provider base URL, prefixed with <code>https://</code>.</p>\n</li>\n<li>\n<p>The bucket name and region parameters as specified by the provider.</p>\n</li>\n<li>\n<p>Review the documentation from your S3-compatible provider to confirm required endpoint formats.</p>\n</li>\n<li>\n<p>Replace placeholder values like <code>&lt;bucket-name&gt;</code> and <code>&lt;region&gt;</code> with your specific configuration details.</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock warning\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Warning</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Incorrectly formatted endpoints for S3-compatible providers might lead to access denial. Always verify the format in your storage provider documentation to ensure compatibility.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_verification_and_troubleshooting\">Verification and Troubleshooting</h4>\n<div class=\"paragraph\">\n<p>After configuring endpoints, verify connectivity by performing a test upload or accessing the object storage directly through the Open Data Hub dashboard. For troubleshooting, check the following items:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Network Accessibility</strong>: Confirm that the endpoint is reachable from your Open Data Hub cluster.</p>\n</li>\n<li>\n<p><strong>Authentication</strong>: Ensure correct access credentials for each storage type.</p>\n</li>\n<li>\n<p><strong>Endpoint Accuracy</strong>: Double-check the endpoint URL format for any typos or missing components.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p>Amazon S3 Region and Endpoint Documentation: <a href=\"https://docs.aws.amazon.com/general/latest/gr/s3.html\">AWS S3 Documentation</a></p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-basic-workbenches\">Managing basic workbenches</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"accessing-the-administration-interface-for-basic-workbenches_managing-resources\">Accessing the administration interface for basic workbenches</h3>\n<div class=\"paragraph _abstract\">\n<p>You can use the administration interface to control basic workbenches in your Open Data Hub environment.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisite</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Procedure</div>\n<ul>\n<li>\n<p>To access the administration interface for basic workbenches from Open Data Hub, perform the following actions:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>In Open Data Hub, in the <strong>Applications</strong> section of the left menu, click <strong>Enabled</strong>.</p>\n</li>\n<li>\n<p>Locate the <strong>Start basic workbench</strong> tile and click <strong>Launch application</strong>.</p>\n</li>\n<li>\n<p>On the page that opens when you launch a basic workbench, click the <strong>Administration</strong> tab.</p>\n<div class=\"paragraph\">\n<p>The <strong>Administration</strong> page opens.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>To access the administration interface for basic workbenches from JupyterLab, perform the following actions:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>Click <strong>File</strong> &#8594; <strong>Hub Control Panel</strong>.</p>\n</li>\n<li>\n<p>On the page that opens in Open Data Hub, click the <strong>Administration</strong> tab.</p>\n<div class=\"paragraph\">\n<p>The <strong>Administration</strong> page opens.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>You can see the administration interface for basic workbenches.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"starting-basic-workbenches-owned-by-other-users_managing-resources\">Starting basic workbenches owned by other users</h3>\n<div class=\"paragraph _abstract\">\n<p>Open Data Hub administrators can start a basic workbench for another existing user from the administration interface for basic workbenches.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>You have launched the <strong>Start basic workbench</strong> application, as described in <a href=\"https://opendatahub.io/docs/working-with-connected-applications/#starting-a-basic-workbench_connected-apps\">Starting a basic workbench</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>On the page that opens when you launch a basic workbench, click the <strong>Administration</strong> tab.</p>\n</li>\n<li>\n<p>On the <strong>Administration</strong> tab, perform the following actions:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Users</strong> section, locate the user whose workbench you want to start.</p>\n</li>\n<li>\n<p>Click <strong>Start workbench</strong> beside the relevant user.</p>\n</li>\n<li>\n<p>Complete the <strong>Start a basic workbench</strong> page.</p>\n</li>\n<li>\n<p>Optional: Select the <strong>Start workbench in current tab</strong> checkbox if necessary.</p>\n</li>\n<li>\n<p>Click <strong>Start workbench</strong>.</p>\n<div class=\"paragraph\">\n<p>After the server starts, you see one of the following behaviors:</p>\n</div>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you previously selected the <strong>Start workbench in current tab</strong> checkbox, the JupyterLab interface opens in the current tab of your web browser.</p>\n</li>\n<li>\n<p>If you did not previously select the <strong>Start workbench in current tab</strong> checkbox, the <strong>Workbench status</strong> dialog box prompts you to open the server in a new browser tab or in the current tab.</p>\n<div class=\"paragraph\">\n<p>The JupyterLab interface opens according to your selection.</p>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The JupyterLab interface opens.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"accessing-basic-workbenches-owned-by-other-users_managing-resources\">Accessing basic workbenches owned by other users</h3>\n<div class=\"paragraph _abstract\">\n<p>Open Data Hub administrators can access basic workbenches that are owned by other users to correct configuration errors or to help them troubleshoot problems with their environment.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>You have launched the <strong>Start basic workbench</strong> application, as described in <a href=\"https://opendatahub.io/docs/working-with-connected-applications/#starting-a-basic-workbench_connected-apps\">Starting a basic workbench</a>.</p>\n</li>\n<li>\n<p>The workbench that you want to access is running.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>On the page that opens when you launch a basic workbench, click the <strong>Administration</strong> tab.</p>\n</li>\n<li>\n<p>On the <strong>Administration</strong> page, perform the following actions:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Users</strong> section, locate the user that the workbench belongs to.</p>\n</li>\n<li>\n<p>Click <strong>View server</strong> beside the relevant user.</p>\n</li>\n<li>\n<p>On the <strong>Workbench control panel</strong> page, click <strong>Access workbench</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The JupyterLab interface opens in the user&#8217;s workbench.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"stopping-basic-workbenches-owned-by-other-users_managing-resources\">Stopping basic workbenches owned by other users</h3>\n<div class=\"paragraph _abstract\">\n<p>Open Data Hub administrators can stop basic workbenches that are owned by other users to reduce resource consumption on the cluster, or as part of removing a user and their resources from the cluster.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>You have launched the <strong>Start basic workbench</strong> application, as described in <a href=\"https://opendatahub.io/docs/working-with-connected-applications/#starting-a-basic-workbench_connected-apps\">Starting a basic workbench</a>.</p>\n</li>\n<li>\n<p>The workbench that you want to stop is running.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>On the page that opens when you launch a basic workbench, click the <strong>Administration</strong> tab.</p>\n</li>\n<li>\n<p>Stop one or more servers.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you want to stop one or more specific servers, perform the following actions:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>In the <strong>Users</strong> section, locate the user that the workbench belongs to.</p>\n</li>\n<li>\n<p>To stop the workbench, perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the relevant user and select <strong>Stop server</strong>.</p>\n</li>\n<li>\n<p>Click <strong>View server</strong> beside the relevant user and then click <strong>Stop workbench</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Stop server</strong> dialog box appears.</p>\n</div>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Stop server</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>If you want to stop all workbenches, perform the following actions:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>Click the <strong>Stop all workbenches</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>OK</strong> to confirm stopping all servers.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <strong>Stop server</strong> link beside each server changes to a <strong>Start workbench</strong> link when the workbench has stopped.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"stopping-idle-workbenches_managing-resources\">Stopping idle workbenches</h3>\n<div class=\"paragraph _abstract\">\n<p>You can reduce resource usage in your Open Data Hub deployment by stopping workbenches that have been idle (without logged in users) for a period of time. This is useful when resource demand in the cluster is high. By default, idle workbenches are not stopped after a specific time limit.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you have configured your cluster settings to disconnect all users from a cluster after a specified time limit, then this setting takes precedence over the idle workbench time limit. Users are logged out of the cluster when their session duration reaches the cluster-wide time limit.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Cluster settings</strong>.</p>\n</li>\n<li>\n<p>Under <strong>Stop idle workbenches</strong>, select <strong>Stop idle workbenches after</strong>.</p>\n</li>\n<li>\n<p>Enter a time limit, in <strong>hours</strong> and <strong>minutes</strong>, for when idle workbenches are stopped.</p>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <code>notebook-controller-culler-config</code> ConfigMap, located in the <code>redhat-ods-applications</code> project on the <strong>Workloads</strong> &#8594; <strong>ConfigMaps</strong> page, contains the following culling configuration settings:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>ENABLE_CULLING</code>: Specifies if the culling feature is enabled or disabled (this is <code>false</code> by default).</p>\n</li>\n<li>\n<p><code>IDLENESS_CHECK_PERIOD</code>: The polling frequency to check for a notebook&#8217;s last known activity (in minutes).</p>\n</li>\n<li>\n<p><code>CULL_IDLE_TIME</code>: The maximum allotted time to scale an inactive notebook to zero (in minutes).</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Idle workbenches stop at the time limit that you set.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"adding-workbench-pod-tolerations_managing-resources\">Adding workbench pod tolerations</h3>\n<div class=\"paragraph _abstract\">\n<p>If you want to dedicate certain machine pools to only running workbench pods, you can allow workbench pods to be scheduled on specific nodes by adding a toleration. Taints and tolerations allow a node to control which pods should (or should not) be scheduled on them. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/nodes/controlling-pod-placement-onto-nodes-scheduling#nodes-scheduler-taints-tolerations-about_nodes-scheduler-taints-tolerations\">Understanding taints and tolerations</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>This capability is useful if you want to make sure that workbenches are placed on nodes that can handle their needs. By preventing other workloads from running on these specific nodes, you can ensure that the necessary resources are available to users who need to work with large workbench sizes.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>You are familiar with OpenShift Container Platform taints and tolerations, as described in <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/nodes/controlling-pod-placement-onto-nodes-scheduling#nodes-scheduler-taints-tolerations-about_nodes-scheduler-taints-tolerations\">Understanding taints and tolerations</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Cluster settings</strong>.</p>\n</li>\n<li>\n<p>Under <strong>Workbench pod tolerations</strong>, select <strong>Add a toleration to workbench pods to allow them to be scheduled to tainted nodes</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Toleration key for workbench pods</strong> field, enter a toleration key. The key is any string, up to 253 characters. The key must begin with a letter or number, and can contain letters, numbers, hyphens, dots, and underscores. For example, <code>workbenches-only</code>.</p>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>. The toleration key is applied to new workbench pods when they are created.</p>\n<div class=\"paragraph\">\n<p>For existing workbench pods, the toleration key is applied when the workbench pods are restarted.\nIf you are using a basic workbench, see <a href=\"https://opendatahub.io/docs/working-with-connected-applications/#updating-workbench-settings-by-restarting-your-workbench_connected-apps\">Updating workbench settings by restarting your workbench</a>.\nIf you are using a workbench in a data science project, see <a href=\"https://opendatahub.io/docs/working-on-data-science-projects/#starting-a-workbench_projects\">Starting a workbench</a>.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Next step</div>\n<p>In OpenShift Container Platform, add a matching taint key (with any value) to the machine pools that you want to dedicate to workbenches. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/nodes/controlling-pod-placement-onto-nodes-scheduling#nodes-scheduler-taints-tolerations\">Controlling pod placement using node taints</a>.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, for a pod that is running, click <strong>Workloads</strong> &#8594; <strong>Pods</strong>. Otherwise, for a pod that is stopped, click <strong>Workloads</strong> &#8594; <strong>StatefulSet</strong>.</p>\n</li>\n<li>\n<p>Search for your workbench pod name and then click the name to open the pod details page.</p>\n</li>\n<li>\n<p>Confirm that the assigned <strong>Node</strong> and <strong>Tolerations</strong> are correct.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources\">Troubleshooting common problems in workbenches for administrators</h3>\n<div class=\"paragraph _abstract\">\n<p>If your users are experiencing errors in Open Data Hub relating to Jupyter, their Jupyter notebooks, or their workbench, read this section to understand what could be causing the problem, and how to resolve the problem.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter\">A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>If you have configured Open Data Hub user groups, the user name might not be added to the default user group for Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>Check whether the user is part of the default user group.</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Find the names of groups allowed access to Jupyter.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Log in to the OpenShift Container Platform web console.</p>\n</li>\n<li>\n<p>Click <strong>User Management</strong> &#8594; <strong>Groups</strong>.</p>\n</li>\n<li>\n<p>Click the name of your user group, for example, {oai-user-group}.</p>\n<div class=\"paragraph\">\n<p>The <strong>Group details</strong> page for that group appears.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Click the <strong>Details</strong> tab for the group and confirm that the <strong>Users</strong> section for the relevant group contains the users who have permission to access Jupyter.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Resolution</div>\n<ul>\n<li>\n<p>If the user is not added to any of the groups allowed access to Jupyter, add them.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_users_workbench_does_not_start\">A user&#8217;s workbench does not start</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>The OpenShift Container Platform cluster that hosts the user&#8217;s workbench might not have access to enough resources, or the workbench pod may have failed.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Diagnosis</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform web console.</p>\n</li>\n<li>\n<p>Delete and restart the workbench pod for this user.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Workloads</strong> &#8594; <strong>Pods</strong> and set the <strong>Project</strong> to <code>rhods-notebooks</code>.</p>\n</li>\n<li>\n<p>Search for the workbench pod that belongs to this user, for example, <code>jupyter-nb-&lt;username&gt;-*</code>.</p>\n<div class=\"paragraph\">\n<p>If the workbench pod exists, an intermittent failure may have occurred in the workbench pod.</p>\n</div>\n<div class=\"paragraph\">\n<p>If the workbench pod for the user does not exist, continue with diagnosis.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Check the resources currently available in the OpenShift Container Platform cluster against the resources required by the selected workbench image.</p>\n<div class=\"paragraph\">\n<p>If worker nodes with sufficient CPU and RAM are available for scheduling in the cluster, continue with diagnosis.</p>\n</div>\n</li>\n<li>\n<p>Check the state of the workbench pod.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Resolution</div>\n<ul>\n<li>\n<p>If there was an intermittent failure of the workbench pod:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Delete the workbench pod that belongs to the user.</p>\n</li>\n<li>\n<p>Ask the user to start their workbench again.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>If the workbench does not have sufficient resources to run the selected workbench image, either add more resources to the OpenShift Container Platform cluster, or choose a smaller image size.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells\">The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>The user might have run out of storage space on their workbench.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Diagnosis</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to Jupyter and start the workbench that belongs to the user having problems. If the workbench does not start, follow these steps to check whether the user has run out of storage space:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Log in to the OpenShift Container Platform web console.</p>\n</li>\n<li>\n<p>Click <strong>Workloads</strong> &#8594; <strong>Pods</strong> and set the <strong>Project</strong> to <code>rhods-notebooks</code>.</p>\n</li>\n<li>\n<p>Click the workbench pod that belongs to this user, for example, <code>jupyter-nb-&lt;idp&gt;-&lt;username&gt;-*</code>.</p>\n</li>\n<li>\n<p>Click <strong>Logs</strong>. The user has exceeded their available capacity if you see lines similar to the following:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>Unexpected error while saving file: XXXX database or disk is full</pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Resolution</div>\n<ul>\n<li>\n<p>Increase the user&#8217;s available storage by expanding their persistent volume.</p>\n</li>\n<li>\n<p>Work with the user to identify files that can be deleted from the <code>/opt/app-root/src</code> directory on their workbench to free up their existing storage space.</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>When you delete files using the JupyterLab file explorer, the files move to the hidden <code>/opt/app-root/src/.local/share/Trash/files</code> folder in the persistent storage for the workbench. To free up storage space for workbenches, you must permanently delete these files.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n</div>\n</div>\n</div>","id":"1d8ec221-2d9e-5abd-b04e-50177b108419","document":{"title":"Managing resources"}},"markdownRemark":null},"pageContext":{"id":"1d8ec221-2d9e-5abd-b04e-50177b108419"}},"staticQueryHashes":["2604506565"],"slicesMap":{}}