{"componentChunkName":"component---src-templates-docs-page-tsx","path":"/docs/managing-odh/","result":{"data":{"allFile":{"edges":[{"node":{"childAsciidoc":{"fields":{"slug":"/docs/README/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/api-workbench/"},"sections":[{"parentId":null,"name":"Overview","level":1,"index":0,"id":"api-workbench-overview_api-workbench"},{"parentId":null,"name":"Creating a custom image by using the <code>ImageStream</code> CRD","level":1,"index":1,"id":"api-custom-image-creating_api-workbench"},{"parentId":null,"name":"Creating a workbench by using the <code>Notebook</code> CRD","level":1,"index":2,"id":"api-workbench-creating_api-workbench"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/configuring-feature-store/"},"sections":[{"parentId":null,"name":"Overview of machine learning features and Feature Store","level":1,"index":0,"id":"overview-of-features-and-feature-store_featurestore"},{"parentId":"overview-of-features-and-feature-store_featurestore","name":"Overview of machine learning features","level":2,"index":0,"id":"_overview_of_machine_learning_features"},{"parentId":"overview-of-features-and-feature-store_featurestore","name":"Overview of Feature Store","level":2,"index":1,"id":"_overview_of_feature_store"},{"parentId":"overview-of-features-and-feature-store_featurestore","name":"Audience for Feature Store","level":2,"index":2,"id":"_audience_for_feature_store"},{"parentId":null,"name":"Before you begin","level":1,"index":1,"id":"before-you-begin_featurestore"},{"parentId":null,"name":"Enabling the Feature Store component","level":1,"index":2,"id":"enabling-the-feature-store-component_featurestore"},{"parentId":null,"name":"Deploying a feature store instance in a data science project","level":1,"index":3,"id":"deploying-a-feature-store-instance-in-a-data-science-project_featurestore"},{"parentId":null,"name":"Customizing your feature store configuration","level":1,"index":4,"id":"customizing-your-feature-store-configuration_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Specifying to use a feature project from a Git repository","level":2,"index":0,"id":"specifying-to-use-a-feature-project-from-git-repository_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring an offline store","level":2,"index":1,"id":"configuring-an-offline-store_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring an online store","level":2,"index":2,"id":"configuring-an-online-store_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring the feature registry","level":2,"index":3,"id":"configuring-the-feature-registry_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Example PVC configuration","level":2,"index":4,"id":"ref-example-pvc-configuration_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring role-based access control","level":2,"index":5,"id":"configuring-role-based-access-control_featurestore"},{"parentId":"configuring-role-based-access-control_featurestore","name":"Default authorization configuration","level":3,"index":0,"id":"ref-default-authorization-configuration_featurestore"},{"parentId":"configuring-role-based-access-control_featurestore","name":"Example OIDC Authorization configuration","level":3,"index":1,"id":"ref-example-oidc-authorization-configuration_featurestore"},{"parentId":"configuring-role-based-access-control_featurestore","name":"Example Kubernetes Authorization configuration","level":3,"index":2,"id":"ref-example-kubernetes-authorization-configuration_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Editing an existing feature store instance","level":2,"index":6,"id":"editing-an-existing-feature-store-instance_featurestore"},{"parentId":null,"name":"Viewing feature store objects in the web-based UI","level":1,"index":5,"id":"viewing-feature-store-objects-in-the-web-based-ui_featurestore"},{"parentId":null,"name":"Additional resources","level":1,"index":6,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/customizing-models-with-lab-tuning/"},"sections":[{"parentId":null,"name":"Enabling LAB-tuning","level":1,"index":0,"id":"enabling-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Overview of enabling LAB-tuning","level":2,"index":0,"id":"overview-of-enabling-lab-tuning_lab-tuning"},{"parentId":"overview-of-enabling-lab-tuning_lab-tuning","name":"Requirements for LAB-tuning","level":3,"index":0,"id":"_requirements_for_lab_tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Installing the required Operators for LAB-tuning","level":2,"index":1,"id":"installing-the-required-operators-for-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Installing the required components for LAB-tuning","level":2,"index":2,"id":"installing-the-required-components-for-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Configuring a storage class for LAB-tuning","level":2,"index":3,"id":"configuring-a-storage-class-for-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Making LAB-tuning and hardware profile features visible","level":2,"index":4,"id":"making-lab-tuning-and-hardware-profile-features-visible_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Creating a model registry for LAB-tuning","level":2,"index":5,"id":"creating-a-model-registry-for-lab-tuning_lab-tuning"},{"parentId":"enabling-lab-tuning_lab-tuning","name":"Creating a hardware profile for LAB-tuning","level":2,"index":6,"id":"creating-a-hardware-profile-for-lab-tuning_lab-tuning"},{"parentId":null,"name":"Overview of LAB-tuning","level":1,"index":1,"id":"overview-of-lab-tuning_lab-tuning"},{"parentId":"overview-of-lab-tuning_lab-tuning","name":"LAB-tuning workflow","level":2,"index":0,"id":"_lab_tuning_workflow"},{"parentId":"overview-of-lab-tuning_lab-tuning","name":"Model customization page","level":2,"index":1,"id":"_model_customization_page"},{"parentId":null,"name":"Preparing LAB-tuning resources","level":1,"index":2,"id":"preparing-lab-tuning-resources_lab-tuning"},{"parentId":"preparing-lab-tuning-resources_lab-tuning","name":"Creating a taxonomy","level":2,"index":0,"id":"creating-a-taxonomy_lab-tuning"},{"parentId":"preparing-lab-tuning-resources_lab-tuning","name":"Preparing a storage location for the LAB-tuned model","level":2,"index":1,"id":"preparing-a-storage-location-for-the-lab-tuned-model_lab-tuning"},{"parentId":"preparing-lab-tuning-resources_lab-tuning","name":"Creating a project for LAB-tuning","level":2,"index":2,"id":"creating-a-project-for-lab-tuning_lab-tuning"},{"parentId":"preparing-lab-tuning-resources_lab-tuning","name":"Deploying teacher and judge models","level":2,"index":3,"id":"deploying-teacher-and-judge-models_lab-tuning"},{"parentId":null,"name":"Using LAB-tuning","level":1,"index":3,"id":"using-lab-tuning_lab-tuning"},{"parentId":"using-lab-tuning_lab-tuning","name":"Registering a base model","level":2,"index":0,"id":"registering-a-base-model_lab-tuning"},{"parentId":"using-lab-tuning_lab-tuning","name":"Starting a LAB-tuning run from the registered model","level":2,"index":1,"id":"starting-a-lab-tuning-run-from-the-registered-model_lab-tuning"},{"parentId":"using-lab-tuning_lab-tuning","name":"Monitoring your LAB-tuning run","level":2,"index":2,"id":"monitoring-your-lab-tuning-run_lab-tuning"},{"parentId":"using-lab-tuning_lab-tuning","name":"Reviewing and deploying your LAB-tuned model","level":2,"index":3,"id":"reviewing-and-deploying-your-lab-tuned-model_lab-tuning"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/getting-started-with-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview","level":1,"index":0,"id":"overview-for-getting-started_get-started"},{"parentId":"overview-for-getting-started_get-started","name":"Data science workflow","level":2,"index":0,"id":"_data_science_workflow"},{"parentId":"overview-for-getting-started_get-started","name":"About this guide","level":2,"index":1,"id":"_about_this_guide"},{"parentId":"overview-for-getting-started_get-started","name":"Glossary of common terms","level":2,"index":2,"id":"glossary-of-common-terms_get-started"},{"parentId":null,"name":"Logging in to Open Data Hub","level":1,"index":1,"id":"logging-in_get-started"},{"parentId":"logging-in_get-started","name":"Viewing installed Open Data Hub components","level":2,"index":0,"id":"viewing-installed-components_get-started"},{"parentId":null,"name":"Creating a data science project","level":1,"index":2,"id":"creating-a-data-science-project_get-started"},{"parentId":null,"name":"Creating a workbench and selecting an IDE","level":1,"index":3,"id":"creating-a-workbench-select-ide_get-started"},{"parentId":"creating-a-workbench-select-ide_get-started","name":"About workbench images","level":2,"index":0,"id":"about-workbench-images_get-started"},{"parentId":"creating-a-workbench-select-ide_get-started","name":"Creating a workbench","level":2,"index":1,"id":"creating-a-project-workbench_get-started"},{"parentId":null,"name":"Next steps","level":1,"index":4,"id":"next-steps_get-started"},{"parentId":"next-steps_get-started","name":"Additional resources","level":2,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/installing-open-data-hub/"},"sections":[{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":0,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Configuring custom namespaces","level":2,"index":0,"id":"configuring-custom-namespaces"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":2,"id":"installing-odh-components_installv2"},{"parentId":null,"name":"Installing Open Data Hub version 1","level":1,"index":1,"id":"installing-odh-v1_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Installing the Open Data Hub Operator version 1","level":2,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Creating a new project for your Open Data Hub instance","level":2,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Adding an Open Data Hub instance","level":2,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":"installing-odh-v1_installv1","name":"Accessing the Open Data Hub dashboard","level":2,"index":3,"id":"accessing-the-odh-dashboard_installv1"},{"parentId":null,"name":"Installing the distributed workloads components","level":1,"index":2,"id":"installing-the-distributed-workloads-components_install"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":3,"id":"accessing-the-odh-dashboard_install"},{"parentId":null,"name":"Working with certificates","level":1,"index":4,"id":"working-with-certificates_certs"},{"parentId":"working-with-certificates_certs","name":"Understanding how Open Data Hub handles certificates","level":2,"index":0,"id":"understanding-certificates_certs"},{"parentId":"working-with-certificates_certs","name":"Adding certificates","level":2,"index":1,"id":"_adding_certificates"},{"parentId":"working-with-certificates_certs","name":"Adding certificates to a cluster-wide CA bundle","level":2,"index":2,"id":"adding-certificates-to-a-cluster-ca-bundle_certs"},{"parentId":"working-with-certificates_certs","name":"Adding certificates to a custom CA bundle","level":2,"index":3,"id":"adding-certificates-to-a-custom-ca-bundle_certs"},{"parentId":"working-with-certificates_certs","name":"Using self-signed certificates with Open Data Hub components","level":2,"index":4,"id":"_using_self_signed_certificates_with_open_data_hub_components"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Accessing S3-compatible object storage with self-signed certificates","level":3,"index":0,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Configuring a certificate for data science pipelines","level":3,"index":1,"id":"configuring-a-certificate-for-pipelines_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Configuring a certificate for workbenches","level":3,"index":2,"id":"configuring-a-certificate-for-workbenches_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Using the cluster-wide CA bundle for the single-model serving platform","level":3,"index":3,"id":"using-the-cluster-CA-bundle-for-single-model-serving_certs"},{"parentId":"working-with-certificates_certs","name":"Managing certificates without the Open Data Hub Operator","level":2,"index":5,"id":"managing-certificates-without-the-operator_certs"},{"parentId":"working-with-certificates_certs","name":"Removing the CA bundle","level":2,"index":6,"id":"_removing_the_ca_bundle"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from all namespaces","level":3,"index":0,"id":"removing-the-ca-bundle-from-all-namespaces_certs"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from a single namespace","level":3,"index":1,"id":"removing-the-ca-bundle-from-a-single-namespace_certs"},{"parentId":null,"name":"Viewing logs and audit records","level":1,"index":5,"id":"viewing-logs-and-audit-records_install"},{"parentId":"viewing-logs-and-audit-records_install","name":"Configuring the Open Data Hub Operator logger","level":2,"index":0,"id":"configuring-the-operator-logger_install"},{"parentId":"configuring-the-operator-logger_install","name":"Viewing the Open Data Hub Operator logs","level":3,"index":0,"id":"_viewing_the_open_data_hub_operator_logs"},{"parentId":"viewing-logs-and-audit-records_install","name":"Viewing audit records","level":2,"index":1,"id":"viewing-audit-records_install"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-odh/"},"sections":[{"parentId":null,"name":"Managing users and groups","level":1,"index":0,"id":"managing-users-and-groups"},{"parentId":"managing-users-and-groups","name":"Overview of user types and permissions","level":2,"index":0,"id":"overview-of-user-types-and-permissions_managing-odh"},{"parentId":"managing-users-and-groups","name":"Viewing Open Data Hub users","level":2,"index":1,"id":"viewing-data-science-users_managing-odh"},{"parentId":"managing-users-and-groups","name":"Adding users to Open Data Hub user groups","level":2,"index":2,"id":"adding-users-to-user-groups_managing-odh"},{"parentId":"managing-users-and-groups","name":"Selecting Open Data Hub administrator and user groups","level":2,"index":3,"id":"selecting-admin-and-user-groups_managing-odh"},{"parentId":"managing-users-and-groups","name":"Deleting users","level":2,"index":4,"id":"_deleting_users"},{"parentId":"_deleting_users","name":"About deleting users and their resources","level":3,"index":0,"id":"about-deleting-users-and-resources_managing-odh"},{"parentId":"_deleting_users","name":"Stopping basic workbenches owned by other users","level":3,"index":1,"id":"stopping-basic-workbenches-owned-by-other-users_managing-odh"},{"parentId":"_deleting_users","name":"Revoking user access to basic workbenches","level":3,"index":2,"id":"revoking-user-access-to-basic-workbenches_managing-odh"},{"parentId":"_deleting_users","name":"Backing up storage data","level":3,"index":3,"id":"backing-up-storage-data_managing-odh"},{"parentId":"_deleting_users","name":"Cleaning up after deleting users","level":3,"index":4,"id":"cleaning-up-after-deleting-users_managing-odh"},{"parentId":null,"name":"Creating custom workbench images","level":1,"index":1,"id":"creating-custom-workbench-images"},{"parentId":"creating-custom-workbench-images","name":"Creating a custom image from a default Open Data Hub image","level":2,"index":0,"id":"creating-a-custom-image-from-default-image_custom-images"},{"parentId":"creating-custom-workbench-images","name":"Creating a custom image from your own image","level":2,"index":1,"id":"creating-a-custom-image-from-your-own-image_custom-images"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Basic guidelines for creating your own workbench image","level":3,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Advanced guidelines for creating your own workbench image","level":3,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-custom-workbench-images","name":"Enabling custom images in Open Data Hub","level":2,"index":2,"id":"enabling-custom-images_custom-images"},{"parentId":"creating-custom-workbench-images","name":"Importing a custom workbench image","level":2,"index":3,"id":"importing-a-custom-workbench-image_custom-images"},{"parentId":null,"name":"Managing applications that show in the dashboard","level":1,"index":2,"id":"managing-applications-that-show-in-the-dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Adding an application to the dashboard","level":2,"index":0,"id":"adding-an-application-to-the-dashboard_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Preventing users from adding applications to the dashboard","level":2,"index":1,"id":"preventing-users-from-adding-applications-to-the-dashboard_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Disabling applications connected to Open Data Hub","level":2,"index":2,"id":"disabling-applications-connected_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Showing or hiding information about available applications","level":2,"index":3,"id":"showing-hiding-information-about-available-applications_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Hiding the default basic workbench application","level":2,"index":4,"id":"hiding-the-default-basic-workbench-application_dashboard"},{"parentId":null,"name":"Creating project-scoped resources","level":1,"index":3,"id":"creating-project-scoped-resources_managing-odh"},{"parentId":null,"name":"Allocating additional resources to Open Data Hub users","level":1,"index":4,"id":"allocating-additional-resources-to-data-science-users_managing-odh"},{"parentId":null,"name":"Customizing component deployment resources","level":1,"index":5,"id":"customizing-component-deployment-resources_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Overview of component resource customization","level":2,"index":0,"id":"overview-of-component-resource-customization_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Customizing component resources","level":2,"index":1,"id":"customizing-component-resources_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Disabling component resource customization","level":2,"index":2,"id":"disabling-component-resource-customization_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Re-enabling component resource customization","level":2,"index":3,"id":"reenabling-component-resource-customization_managing-resources"},{"parentId":null,"name":"Enabling accelerators","level":1,"index":6,"id":"_enabling_accelerators"},{"parentId":"_enabling_accelerators","name":"Enabling NVIDIA GPUs","level":2,"index":0,"id":"enabling-nvidia-gpus_managing-odh"},{"parentId":"_enabling_accelerators","name":"Intel Gaudi AI Accelerator integration","level":2,"index":1,"id":"intel-gaudi-ai-accelerator-integration_managing-odh"},{"parentId":"intel-gaudi-ai-accelerator-integration_managing-odh","name":"Enabling Intel Gaudi AI accelerators","level":3,"index":0,"id":"enabling-intel-gaudi-ai-accelerators_managing-odh"},{"parentId":"_enabling_accelerators","name":"AMD GPU Integration","level":2,"index":2,"id":"amd-gpu-integration_managing-odh"},{"parentId":"amd-gpu-integration_managing-odh","name":"Verifying AMD GPU availability on your cluster","level":3,"index":0,"id":"verifying-amd-gpu-availability-on-your-cluster_managing-odh"},{"parentId":"amd-gpu-integration_managing-odh","name":"Enabling AMD GPUs","level":3,"index":1,"id":"enabling-amd-gpus_managing-odh"},{"parentId":null,"name":"Managing distributed workloads","level":1,"index":7,"id":"managing-distributed-workloads_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Overview of Kueue resources","level":2,"index":0,"id":"overview-of-kueue-resources_managing-odh"},{"parentId":"overview-of-kueue-resources_managing-odh","name":"Resource flavor","level":3,"index":0,"id":"_resource_flavor"},{"parentId":"overview-of-kueue-resources_managing-odh","name":"Cluster queue","level":3,"index":1,"id":"_cluster_queue"},{"parentId":"overview-of-kueue-resources_managing-odh","name":"Local queue","level":3,"index":2,"id":"_local_queue"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Example Kueue resource configurations","level":2,"index":1,"id":"ref-example-kueue-resource-configurations_managing-odh"},{"parentId":"ref-example-kueue-resource-configurations_managing-odh","name":"NVIDIA GPUs without shared cohort","level":3,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":4,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":4,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":4,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":4,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":"ref-example-kueue-resource-configurations_managing-odh","name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":3,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":4,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":4,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":4,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":4,"index":3,"id":"_nvidia_gpu_cluster_queue"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Configuring quota management for distributed workloads","level":2,"index":2,"id":"configuring-quota-management-for-distributed-workloads_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Enforcing the use of local queues","level":2,"index":3,"id":"enforcing-local-queues_managing-odh"},{"parentId":"enforcing-local-queues_managing-odh","name":"Enforcing the local-queue labeling policy for all projects","level":3,"index":0,"id":"enforcing-lqlabel-all_managing-odh"},{"parentId":"enforcing-local-queues_managing-odh","name":"Disabling the local-queue labeling policy for all projects","level":3,"index":1,"id":"disabling-lqlabel-all_managing-odh"},{"parentId":"enforcing-local-queues_managing-odh","name":"Enforcing the local-queue labeling policy for some projects only","level":3,"index":2,"id":"enforcing-lqlabel-some_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Configuring the CodeFlare Operator","level":2,"index":4,"id":"configuring-the-codeflare-operator_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Configuring a cluster for RDMA","level":2,"index":5,"id":"configuring-a-cluster-for-rdma_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Troubleshooting common problems with distributed workloads for administrators","level":2,"index":6,"id":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster is in a suspended state","level":3,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster is in a failed state","level":3,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user receives a \"failed to call webhook\" error message for the CodeFlare Operator","level":3,"index":2,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user receives a \"failed to call webhook\" error message for Kueue","level":3,"index":3,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster does not start","level":3,"index":4,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message","level":3,"index":5,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user receives a <strong>local_queue provided does not exist</strong> error message","level":3,"index":6,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user cannot create a Ray cluster or submit jobs","level":3,"index":7,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled","level":3,"index":8,"id":"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled"},{"parentId":null,"name":"Backing up data","level":1,"index":8,"id":"_backing_up_data"},{"parentId":"_backing_up_data","name":"Backing up storage data","level":2,"index":0,"id":"backing-up-storage-data_managing-odh"},{"parentId":"_backing_up_data","name":"Backing up your cluster","level":2,"index":1,"id":"backing-up-your-cluster_managing-odh"},{"parentId":null,"name":"Viewing logs and audit records","level":1,"index":9,"id":"viewing-logs-and-audit-records_managing-odh"},{"parentId":"viewing-logs-and-audit-records_managing-odh","name":"Configuring the Open Data Hub Operator logger","level":2,"index":0,"id":"configuring-the-operator-logger_managing-odh"},{"parentId":"configuring-the-operator-logger_managing-odh","name":"Viewing the Open Data Hub Operator logs","level":3,"index":0,"id":"_viewing_the_open_data_hub_operator_logs"},{"parentId":"viewing-logs-and-audit-records_managing-odh","name":"Viewing audit records","level":2,"index":1,"id":"viewing-audit-records_managing-odh"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-resources/"},"sections":[{"parentId":null,"name":"Selecting Open Data Hub administrator and user groups","level":1,"index":0,"id":"selecting-admin-and-user-groups_managing-resources"},{"parentId":null,"name":"Customizing the dashboard","level":1,"index":1,"id":"customizing-the-dashboard"},{"parentId":"customizing-the-dashboard","name":"Editing the dashboard configuration","level":2,"index":0,"id":"editing-the-dashboard-configuration_dashboard"},{"parentId":"customizing-the-dashboard","name":"Dashboard configuration options","level":2,"index":1,"id":"ref-dashboard-configuration-options_dashboard"},{"parentId":null,"name":"Importing a custom workbench image","level":1,"index":2,"id":"importing-a-custom-workbench-image_managing-resources"},{"parentId":null,"name":"Managing cluster PVC size","level":1,"index":3,"id":"managing-cluster-pvc-size"},{"parentId":"managing-cluster-pvc-size","name":"Configuring the default PVC size for your cluster","level":2,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":"managing-cluster-pvc-size","name":"Restoring the default PVC size for your cluster","level":2,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":null,"name":"Managing connection types","level":1,"index":4,"id":"managing-connection-types"},{"parentId":"managing-connection-types","name":"Viewing connection types","level":2,"index":0,"id":"viewing-connection-types_managing-resources"},{"parentId":"managing-connection-types","name":"Creating a connection type","level":2,"index":1,"id":"creating-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Duplicating a connection type","level":2,"index":2,"id":"duplicating-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Editing a connection type","level":2,"index":3,"id":"editing-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Enabling a connection type","level":2,"index":4,"id":"enabling-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Deleting a connection type","level":2,"index":5,"id":"deleting-a-connection-type_managing-resources"},{"parentId":null,"name":"Managing storage classes","level":1,"index":5,"id":"managing-storage-classes"},{"parentId":"managing-storage-classes","name":"About persistent storage","level":2,"index":0,"id":"about-persistent-storage_managing-resources"},{"parentId":"about-persistent-storage_managing-resources","name":"Storage classes in Open Data Hub","level":3,"index":0,"id":"_storage_classes_in_open_data_hub"},{"parentId":"about-persistent-storage_managing-resources","name":"Access modes","level":3,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":4,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":"managing-storage-classes","name":"Configuring storage class settings","level":2,"index":1,"id":"configuring-storage-class-settings_managing-resources"},{"parentId":"managing-storage-classes","name":"Configuring the default storage class for your cluster","level":2,"index":2,"id":"configuring-the-default-storage-class-for-your-cluster_managing-resources"},{"parentId":"managing-storage-classes","name":"Overview of object storage endpoints","level":2,"index":3,"id":"overview-of-object-storage-endpoints_managing-resources"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"MinIO (On-Cluster)","level":3,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Amazon S3","level":3,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Other S3-Compatible Object Stores","level":3,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Verification and Troubleshooting","level":3,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Managing basic workbenches","level":1,"index":6,"id":"managing-basic-workbenches"},{"parentId":"managing-basic-workbenches","name":"Accessing the administration interface for basic workbenches","level":2,"index":0,"id":"accessing-the-administration-interface-for-basic-workbenches_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Starting basic workbenches owned by other users","level":2,"index":1,"id":"starting-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Accessing basic workbenches owned by other users","level":2,"index":2,"id":"accessing-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Stopping basic workbenches owned by other users","level":2,"index":3,"id":"stopping-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Stopping idle workbenches","level":2,"index":4,"id":"stopping-idle-workbenches_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Adding workbench pod tolerations","level":2,"index":5,"id":"adding-workbench-pod-tolerations_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Troubleshooting common problems in workbenches for administrators","level":2,"index":6,"id":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":3,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"A user&#8217;s workbench does not start","level":3,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":3,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/monitoring-data-science-models/"},"sections":[{"parentId":null,"name":"Overview of model monitoring","level":1,"index":0,"id":"overview-of-model-monitoring_monitor"},{"parentId":null,"name":"Configuring TrustyAI","level":1,"index":1,"id":"configuring-trustyai_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Configuring monitoring for your model serving platform","level":2,"index":0,"id":"configuring-monitoring-for-your-model-serving-platform_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Enabling the TrustyAI component","level":2,"index":1,"id":"enabling-trustyai-component_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Configuring TrustyAI with a database","level":2,"index":2,"id":"configuring-trustyai-with-a-database_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Installing the TrustyAI service for a project","level":2,"index":3,"id":"installing-trustyai-service_monitor"},{"parentId":"installing-trustyai-service_monitor","name":"Installing the TrustyAI service by using the dashboard","level":3,"index":0,"id":"installing-trustyai-service-using-dashboard_monitor"},{"parentId":"installing-trustyai-service_monitor","name":"Installing the TrustyAI service by using the CLI","level":3,"index":1,"id":"installing-trustyai-service-using-cli_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Enabling TrustyAI Integration with standard model deployment","level":2,"index":4,"id":"enabling-trustyai-kserve-integration_monitor"},{"parentId":null,"name":"Setting up TrustyAI for your project","level":1,"index":2,"id":"setting-up-trustyai-for-your-project_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Authenticating the TrustyAI service","level":2,"index":0,"id":"authenticating-trustyai-service_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Uploading training data to TrustyAI","level":2,"index":1,"id":"uploading-training-data-to-trustyai_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Sending training data to TrustyAI","level":2,"index":2,"id":"sending-training-data-to-trustyai_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Labeling data fields","level":2,"index":3,"id":"labeling-data-fields_monitor"},{"parentId":null,"name":"Monitoring model bias","level":1,"index":3,"id":"monitoring-model-bias_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Creating a bias metric","level":2,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":3,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":3,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Duplicating a bias metric","level":3,"index":2,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Deleting a bias metric","level":2,"index":1,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":3,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":3,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Viewing bias metrics for a model","level":2,"index":2,"id":"viewing-bias-metrics_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Using bias metrics","level":2,"index":3,"id":"using-bias-metrics_bias-monitoring"},{"parentId":null,"name":"Monitoring data drift","level":1,"index":4,"id":"monitoring-data-drift_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Creating a drift metric","level":2,"index":0,"id":"creating-a-drift-metric_drift-monitoring"},{"parentId":"creating-a-drift-metric_drift-monitoring","name":"Creating a drift metric by using the CLI","level":3,"index":0,"id":"creating-a-drift-metric-using-cli_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Deleting a drift metric by using the CLI","level":2,"index":1,"id":"deleting-a-drift-metric-using-cli_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Viewing data drift metrics for a model","level":2,"index":2,"id":"viewing-drift-metrics_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Using drift metrics","level":2,"index":3,"id":"using-drift-metrics_drift-monitoring"},{"parentId":null,"name":"Using explainability","level":1,"index":5,"id":"using-explainability_explainers"},{"parentId":"using-explainability_explainers","name":"Requesting a LIME explanation","level":2,"index":0,"id":"requesting-a-lime-explanation_explainers"},{"parentId":"requesting-a-lime-explanation_explainers","name":"Requesting a LIME explanation by using the CLI","level":3,"index":0,"id":"requesting-a-lime-explanation-using-CLI_explainers"},{"parentId":"using-explainability_explainers","name":"Requesting a SHAP explanation","level":2,"index":1,"id":"requesting-a-shap-explanation_explainers"},{"parentId":"requesting-a-shap-explanation_explainers","name":"Requesting a SHAP explanation by using the CLI","level":3,"index":0,"id":"requesting-a-shap-explanation-using-CLI_explainers"},{"parentId":"using-explainability_explainers","name":"Using explainers","level":2,"index":2,"id":"using-explainers_explainers"},{"parentId":null,"name":"Evaluating large language models","level":1,"index":6,"id":"evaluating-large-language-models_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"Setting up LM-Eval","level":2,"index":0,"id":"setting-up-lmeval_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval evaluation job","level":2,"index":1,"id":"lmeval-evaluation-job_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval evaluation job properties","level":2,"index":2,"id":"lmeval-evaluation-job-properties_monitor"},{"parentId":"lmeval-evaluation-job-properties_monitor","name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":3,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval scenarios","level":2,"index":3,"id":"lmeval-scenarios_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Accessing Hugging Face models with an environment variable token","level":3,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using a custom Unitxt card","level":3,"index":1,"id":"using-a-custom-unitxt-card_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using PVCs as storage","level":3,"index":2,"id":"using-pvcs-as-storage_monitor"},{"parentId":"using-pvcs-as-storage_monitor","name":"Managed PVCs","level":4,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_monitor","name":"Existing PVCs","level":4,"index":1,"id":"_existing_pvcs"},{"parentId":"lmeval-scenarios_monitor","name":"Using a KServe Inference Service","level":3,"index":3,"id":"using-a-kserve-inference-service_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Setting up LM-Eval S3 Support","level":3,"index":4,"id":"setting-up-lmeval-s3-support_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using LLM-as-a-Judge metrics with LM-Eval","level":3,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_monitor"},{"parentId":null,"name":"Configuring the Guardrails Orchestrator service","level":1,"index":7,"id":"configuring-the-guardrails-orchestrator-service_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Deploying the Guardrails Orchestrator service","level":2,"index":0,"id":"deploying-the-guardrails-orchestrator-service_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Guardrails Orchestrator parameters","level":2,"index":1,"id":"guardrails-orchestrator-parameters_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Monitoring user inputs with the Guardrails Orchestrator service","level":2,"index":2,"id":"guardrails-orchestrator-hap-scenario_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Configuring the regex detector and guardrails gateway","level":2,"index":3,"id":"configuring-regex-guardrails-gateway_monitor"},{"parentId":"configuring-regex-guardrails-gateway_monitor","name":"Sending requests to the regex detector","level":3,"index":0,"id":"sending-requests-to-the-regex-detector_monitor"},{"parentId":"configuring-regex-guardrails-gateway_monitor","name":"Querying using guardrails gateway","level":3,"index":1,"id":"querying-using-guardrails-gateway_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Configuring the OpenTelemetry exporter","level":2,"index":4,"id":"configuring-the-opentelemetry-exporter_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Using Hugging Face models with Guardrails Orchestrator","level":2,"index":5,"id":"using-hugging-face-models-with-guardrails-orchestrator_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Configuring the Guardrails Detector Hugging Face serving runtime","level":2,"index":6,"id":"configuring-the-guardrails-detector-hugging-face-serving-runtime_monitor"},{"parentId":"configuring-the-guardrails-orchestrator-service_monitor","name":"Using a Hugging Face Prompt Injection detector with the Guardrails Orchestrator","level":2,"index":7,"id":"using-a-hugging-face-prompt-injection-detector-with-guardrails-orchestrator_monitor"},{"parentId":null,"name":"Bias monitoring tutorial - Gender bias example","level":1,"index":8,"id":"bias-monitoring-tutorial_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Introduction","level":2,"index":0,"id":"t-bias-introduction_bias-tutorial"},{"parentId":"t-bias-introduction_bias-tutorial","name":"About the example models","level":3,"index":0,"id":"_about_the_example_models"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Setting up your environment","level":2,"index":1,"id":"t-bias-setting-up-your-environment_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Downloading the tutorial files","level":3,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Logging in to the OpenShift cluster from the command line","level":3,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Configuring monitoring for the model serving platform","level":3,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Enabling the TrustyAI component","level":3,"index":3,"id":"enabling-trustyai-component_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Setting up a project","level":3,"index":4,"id":"_setting_up_a_project"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Authenticating the TrustyAI service","level":3,"index":5,"id":"_authenticating_the_trustyai_service"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Deploying models","level":2,"index":2,"id":"t-bias-deploying-models_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Sending training data to the models","level":2,"index":3,"id":"t-bias-sending-training-data-to-the-models_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Labeling data fields","level":2,"index":4,"id":"t-bias-labeling-data-fields_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Checking model fairness","level":2,"index":5,"id":"t-bias-checking-model-fairness_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Scheduling a fairness metric request","level":2,"index":6,"id":"t-bias-scheduling-a-fairness-metric-request_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Scheduling an identity metric request","level":2,"index":7,"id":"t-bias-scheduling-an-identity-metric-request_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Simulating real world data","level":2,"index":8,"id":"t-bias-simulating-real-world-data_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Reviewing the results","level":2,"index":9,"id":"t-bias-reviewing-the-results_bias-tutorial"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"Are the models biased?","level":3,"index":0,"id":"_are_the_models_biased"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"How does the production data compare to the training data?","level":3,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/serving-models/"},"sections":[{"parentId":null,"name":"About model serving","level":1,"index":0,"id":"about-model-serving_about-model-serving"},{"parentId":"about-model-serving_about-model-serving","name":"Single-model serving platform","level":2,"index":0,"id":"_single_model_serving_platform"},{"parentId":"about-model-serving_about-model-serving","name":"Multi-model serving platform","level":2,"index":1,"id":"_multi_model_serving_platform"},{"parentId":"about-model-serving_about-model-serving","name":"NVIDIA NIM model serving platform","level":2,"index":2,"id":"_nvidia_nim_model_serving_platform"},{"parentId":null,"name":"Serving models on the single-model serving platform","level":1,"index":1,"id":"serving-large-models_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"About the single-model serving platform","level":2,"index":0,"id":"about-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Model-serving runtimes","level":2,"index":1,"id":"model-serving-runtimes_serving-large-models"},{"parentId":"model-serving-runtimes_serving-large-models","name":"ServingRuntime","level":3,"index":0,"id":"_servingruntime"},{"parentId":"model-serving-runtimes_serving-large-models","name":"InferenceService","level":3,"index":1,"id":"_inferenceservice"},{"parentId":"serving-large-models_serving-large-models","name":"About KServe deployment modes","level":2,"index":2,"id":"about-kserve-deployment-modes_serving-large-models"},{"parentId":"about-kserve-deployment-modes_serving-large-models","name":"Advanced mode","level":3,"index":0,"id":"_advanced_mode"},{"parentId":"about-kserve-deployment-modes_serving-large-models","name":"Standard mode","level":3,"index":1,"id":"_standard_mode"},{"parentId":"serving-large-models_serving-large-models","name":"Installing KServe","level":2,"index":3,"id":"installing-kserve_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Deploying models by using the single-model serving platform","level":2,"index":4,"id":"deploying-models-using-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Enabling the single-model serving platform","level":3,"index":0,"id":"enabling-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a custom model-serving runtime for the single-model serving platform","level":3,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a tested and verified model-serving runtime for the single-model serving platform","level":3,"index":2,"id":"adding-a-tested-and-verified-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models on the single-model serving platform","level":3,"index":3,"id":"deploying-models-on-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models by using multiple GPU nodes","level":3,"index":4,"id":"deploying-models-using-multiple-gpu-nodes_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Setting a timeout for KServe","level":3,"index":5,"id":"setting-timeout-for-kserve_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Customizing the parameters of a deployed model-serving runtime","level":3,"index":6,"id":"customizing-parameters-serving-runtime_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Customizable model serving runtime parameters","level":3,"index":7,"id":"customizable-model-serving-runtime-parameters_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Using accelerators with vLLM","level":3,"index":8,"id":"using-accelerators-with-vllm_serving-large-models"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"NVIDIA GPUs","level":4,"index":0,"id":"_nvidia_gpus"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"Intel Gaudi accelerators","level":4,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"AMD GPUs","level":4,"index":2,"id":"_amd_gpus"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Using OCI containers for model storage","level":3,"index":9,"id":"using-oci-containers-for-model-storage_serving-large-models"},{"parentId":"using-oci-containers-for-model-storage_serving-large-models","name":"Storing a model in an OCI image","level":4,"index":0,"id":"storing-a-model-in-oci-image_serving-large-models"},{"parentId":"using-oci-containers-for-model-storage_serving-large-models","name":"Deploying a model stored in an OCI image by using the CLI","level":4,"index":1,"id":"deploying-model-stored-in-oci-image_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the authentication token for a deployed model","level":3,"index":10,"id":"accessing-authentication-token-for-deployed-model_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the inference endpoint for a deployed model","level":3,"index":11,"id":"accessing-inference-endpoint-for-deployed-model_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Configuring monitoring for the single-model serving platform","level":2,"index":5,"id":"configuring-monitoring-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Viewing model-serving runtime metrics for the single-model serving platform","level":2,"index":6,"id":"viewing-metrics-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Monitoring model performance","level":2,"index":7,"id":"_monitoring_model_performance"},{"parentId":"_monitoring_model_performance","name":"Viewing performance metrics for a deployed model","level":3,"index":0,"id":"viewing-performance-metrics-for-deployed-model_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Deploying a Grafana metrics dashboard","level":3,"index":1,"id":"Deploying-a-grafana-metrics-dashboard_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Deploying a vLLM/GPU metrics dashboard on a Grafana instance","level":3,"index":2,"id":"deploying-vllm-gpu-metrics-dashboard-grafana_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Grafana metrics","level":3,"index":3,"id":"ref-grafana-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"Accelerator metrics","level":4,"index":0,"id":"ref-accelerator-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"CPU metrics","level":4,"index":1,"id":"ref-cpu-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"vLLM metrics","level":4,"index":2,"id":"ref-vllm-metrics_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Optimizing model-serving runtimes","level":2,"index":8,"id":"_optimizing_model_serving_runtimes"},{"parentId":"_optimizing_model_serving_runtimes","name":"Enabling speculative decoding and multi-modal inferencing","level":3,"index":0,"id":"enabling-speculative-decoding-and-multi-modal-inferencing_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Performance tuning on the single-model serving platform","level":2,"index":9,"id":"_performance_tuning_on_the_single_model_serving_platform"},{"parentId":"_performance_tuning_on_the_single_model_serving_platform","name":"Resolving CUDA out-of-memory errors","level":3,"index":0,"id":"resolving-cuda-oom-errors-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Supported model-serving runtimes","level":2,"index":10,"id":"supported-model-serving-runtimes_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Tested and verified model-serving runtimes","level":2,"index":11,"id":"tested-verified-runtimes_serving-large-models"},{"parentId":"serving-large-models_serving-large-models","name":"Inference endpoints","level":2,"index":12,"id":"inference-endpoints_serving-large-models"},{"parentId":"inference-endpoints_serving-large-models","name":"Caikit TGIS ServingRuntime for KServe","level":3,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"Caikit Standalone ServingRuntime for KServe","level":3,"index":1,"id":"_caikit_standalone_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"TGIS Standalone ServingRuntime for KServe","level":3,"index":2,"id":"_tgis_standalone_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"OpenVINO Model Server","level":3,"index":3,"id":"_openvino_model_server"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":3,"index":4,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":3,"index":5,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM AMD GPU ServingRuntime for KServe","level":3,"index":6,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"NVIDIA Triton Inference Server","level":3,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":"inference-endpoints_serving-large-models","name":"Seldon MLServer","level":3,"index":8,"id":"_seldon_mlserver"},{"parentId":"inference-endpoints_serving-large-models","name":"Additional resources","level":3,"index":9,"id":"_additional_resources"},{"parentId":"serving-large-models_serving-large-models","name":"About the NVIDIA NIM model serving platform","level":2,"index":13,"id":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Enabling the NVIDIA NIM model serving platform","level":3,"index":0,"id":"enabling-the-nvidia-nim-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Deploying models on the NVIDIA NIM model serving platform","level":3,"index":1,"id":"deploying-models-on-the-NVIDIA-NIM-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Customizing model selection options for the NVIDIA NIM model serving platform","level":3,"index":2,"id":"Customizing-model-selection-options_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Enabling NVIDIA NIM metrics for an existing NIM deployment","level":3,"index":3,"id":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models","name":"Enabling graph generation for an existing NIM deployment","level":4,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models","name":"Enabling metrics collection for an existing NIM deployment","level":4,"index":1,"id":"_enabling_metrics_collection_for_an_existing_nim_deployment"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Viewing NVIDIA NIM metrics for a NIM model","level":3,"index":4,"id":"viewing-nvidia-nim-metrics-for-a-nim-model_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Viewing performance metrics for a NIM model","level":3,"index":5,"id":"viewing-performance-metrics-for-a-nim-model_serving-large-models"},{"parentId":null,"name":"Serving models on the multi-model serving platform","level":1,"index":2,"id":"serving-small-and-medium-sized-models_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Configuring model servers","level":2,"index":0,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the multi-model serving platform","level":3,"index":0,"id":"enabling-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime for the multi-model serving platform","level":3,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a tested and verified model-serving runtime for the multi-model serving platform","level":3,"index":2,"id":"adding-a-tested-and-verified-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a model server for the multi-model serving platform","level":3,"index":3,"id":"adding-a-model-server-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Deleting a model server","level":3,"index":4,"id":"deleting-a-model-server_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Working with deployed models","level":2,"index":1,"id":"_working_with_deployed_models"},{"parentId":"_working_with_deployed_models","name":"Deploying a model by using the multi-model serving platform","level":3,"index":0,"id":"deploying-a-model-using-the-multi-model-serving-platform_model-serving"},{"parentId":"_working_with_deployed_models","name":"Viewing a deployed model","level":3,"index":1,"id":"viewing-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Updating the deployment properties of a deployed model","level":3,"index":2,"id":"updating-the-deployment-properties-of-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Deleting a deployed model","level":3,"index":3,"id":"deleting-a-deployed-model_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Configuring monitoring for the multi-model serving platform","level":2,"index":2,"id":"configuring-monitoring-for-the-multi-model-serving-platform_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Viewing model-serving runtime metrics for the multi-model serving platform","level":2,"index":3,"id":"viewing-metrics-for-the-multi-model-serving-platform_model-serving"},{"parentId":"serving-small-and-medium-sized-models_model-serving","name":"Monitoring model performance","level":2,"index":4,"id":"_monitoring_model_performance_2"},{"parentId":"_monitoring_model_performance_2","name":"Viewing performance metrics for all models on a model server","level":3,"index":0,"id":"viewing-performance-metrics-for-model-server_model-serving"},{"parentId":"_monitoring_model_performance_2","name":"Viewing HTTP request metrics for a deployed model","level":3,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_model-serving"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/upgrading-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview of upgrading Open Data Hub","level":1,"index":0,"id":"overview-of-upgrading-odh_upgrade"},{"parentId":null,"name":"Upgrading Open Data Hub version 2.0 to version 2.2","level":1,"index":1,"id":"upgrading-odh-v2_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Requirements for upgrading Open Data Hub version 2","level":2,"index":0,"id":"requirements-for-upgrading-odh-v2_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Installing Open Data Hub version 2","level":2,"index":1,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Configuring custom namespaces","level":3,"index":0,"id":"configuring-custom-namespaces"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":3,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":3,"index":2,"id":"installing-odh-components_installv2"},{"parentId":null,"name":"Upgrading Open Data Hub version 1 to version 2","level":1,"index":2,"id":"upgrading-odh-v1-to-v2_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Requirements for upgrading Open Data Hub version 1","level":2,"index":0,"id":"requirements-for-upgrading-odh-v1_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Upgrading the Open Data Hub Operator version 1","level":2,"index":1,"id":"upgrading-the-odh-operator-v1_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Installing Open Data Hub components","level":2,"index":2,"id":"installing-odh-components_upgradev1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-in-your-data-science-ide/"},"sections":[{"parentId":null,"name":"Accessing your workbench IDE","level":1,"index":0,"id":"accessing-your-workbench-ide_ide"},{"parentId":null,"name":"Working in JupyterLab","level":1,"index":1,"id":"_working_in_jupyterlab"},{"parentId":"_working_in_jupyterlab","name":"Creating and importing Jupyter notebooks","level":2,"index":0,"id":"creating-and-importing-jupyter-notebooks_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Creating a Jupyter notebook","level":3,"index":0,"id":"creating-a-jupyter-notebook_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Uploading an existing notebook file to JupyterLab from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Additional resources","level":3,"index":2,"id":"_additional_resources"},{"parentId":"_working_in_jupyterlab","name":"Collaborating on Jupyter notebooks by using Git","level":2,"index":1,"id":"collaborating-on-jupyter-notebooks-by-using-git_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Updating your project with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Pushing project changes to a Git repository","level":3,"index":3,"id":"pushing-project-changes-to-a-git-repository_ide"},{"parentId":"_working_in_jupyterlab","name":"Managing Python packages","level":2,"index":2,"id":"managing-python-packages_ide"},{"parentId":"managing-python-packages_ide","name":"Viewing Python packages installed on your workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_ide"},{"parentId":"managing-python-packages_ide","name":"Installing Python packages on your workbench","level":3,"index":1,"id":"installing-python-packages-on-your-workbench_ide"},{"parentId":"_working_in_jupyterlab","name":"Troubleshooting common problems in workbenches for users","level":2,"index":3,"id":"troubleshooting-common-problems-in-workbenches-for-users_ide"},{"parentId":null,"name":"Working in code-server","level":1,"index":2,"id":"_working_in_code_server"},{"parentId":"_working_in_code_server","name":"Creating code-server workbenches","level":2,"index":0,"id":"creating-code-server-workbenches_ide"},{"parentId":"creating-code-server-workbenches_ide","name":"Creating a workbench","level":3,"index":0,"id":"creating-a-project-workbench_ide"},{"parentId":"creating-code-server-workbenches_ide","name":"Uploading an existing notebook file to code-server from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-local-storage_ide"},{"parentId":"_working_in_code_server","name":"Collaborating on workbenches in code-server by using Git","level":2,"index":1,"id":"collaborating-on-workbenches-in-code-server-by-using-git_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Uploading an existing notebook file from a Git repository by using code-server","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-code-server_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Uploading an existing notebook file to code-server from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Updating your project in code-server with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-in-code-server-with-changes-from-a-remote-git-repository_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Pushing project changes in code-server to a Git repository","level":3,"index":3,"id":"pushing-project-changes-in-code-server-to-a-git-repository_ide"},{"parentId":"_working_in_code_server","name":"Managing Python packages in code-server","level":2,"index":2,"id":"managing-python-packages-in-code-server_ide"},{"parentId":"managing-python-packages-in-code-server_ide","name":"Viewing Python packages installed on your code-server workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-code-server-workbench_ide"},{"parentId":"managing-python-packages-in-code-server_ide","name":"Installing Python packages on your code-server workbench","level":3,"index":1,"id":"installing-python-packages-on-your-code-server-workbench_ide"},{"parentId":"_working_in_code_server","name":"Installing extensions with code-server","level":2,"index":3,"id":"installing-extensions-with-code-server_ide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-on-data-science-projects/"},"sections":[{"parentId":null,"name":"Using data science projects","level":1,"index":0,"id":"using-data-science-projects_projects"},{"parentId":"using-data-science-projects_projects","name":"Creating a data science project","level":2,"index":0,"id":"creating-a-data-science-project_projects"},{"parentId":"using-data-science-projects_projects","name":"Updating a data science project","level":2,"index":1,"id":"updating-a-data-science-project_projects"},{"parentId":"using-data-science-projects_projects","name":"Deleting a data science project","level":2,"index":2,"id":"deleting-a-data-science-project_projects"},{"parentId":null,"name":"Using project workbenches","level":1,"index":1,"id":"using-project-workbenches_projects"},{"parentId":"using-project-workbenches_projects","name":"Creating a workbench and selecting an IDE","level":2,"index":0,"id":"creating-a-workbench-select-ide_projects"},{"parentId":"creating-a-workbench-select-ide_projects","name":"About workbench images","level":3,"index":0,"id":"about-workbench-images_projects"},{"parentId":"creating-a-workbench-select-ide_projects","name":"Creating a workbench","level":3,"index":1,"id":"creating-a-project-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Starting a workbench","level":2,"index":1,"id":"starting-a-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Updating a project workbench","level":2,"index":2,"id":"updating-a-project-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Deleting a workbench from a data science project","level":2,"index":3,"id":"deleting-a-workbench-from-a-data-science-project_projects"},{"parentId":null,"name":"Using connections","level":1,"index":2,"id":"using-connections_projects"},{"parentId":"using-connections_projects","name":"Adding a connection to your data science project","level":2,"index":0,"id":"adding-a-connection-to-your-data-science-project_projects"},{"parentId":"using-connections_projects","name":"Updating a connection","level":2,"index":1,"id":"updating-a-connection_projects"},{"parentId":"using-connections_projects","name":"Deleting a connection","level":2,"index":2,"id":"deleting-a-connection_projects"},{"parentId":null,"name":"Configuring cluster storage","level":1,"index":3,"id":"configuring-cluster-storage_projects"},{"parentId":"configuring-cluster-storage_projects","name":"About persistent storage","level":2,"index":0,"id":"about-persistent-storage_projects"},{"parentId":"about-persistent-storage_projects","name":"Storage classes in Open Data Hub","level":3,"index":0,"id":"_storage_classes_in_open_data_hub"},{"parentId":"about-persistent-storage_projects","name":"Access modes","level":3,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":4,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":"configuring-cluster-storage_projects","name":"Adding cluster storage to your data science project","level":2,"index":1,"id":"adding-cluster-storage-to-your-data-science-project_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Updating cluster storage","level":2,"index":2,"id":"updating-cluster-storage_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Changing the storage class for an existing cluster storage instance","level":2,"index":3,"id":"changing-the-storage-class-for-an-existing-cluster-storage-instance_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Deleting cluster storage from a data science project","level":2,"index":4,"id":"deleting-cluster-storage-from-a-data-science-project_projects"},{"parentId":null,"name":"Managing access to data science projects","level":1,"index":4,"id":"managing-access-to-data-science-projects_projects"},{"parentId":"managing-access-to-data-science-projects_projects","name":"Configuring access to a data science project","level":2,"index":0,"id":"configuring-access-to-a-data-science-project_projects"},{"parentId":"managing-access-to-data-science-projects_projects","name":"Sharing access to a data science project","level":2,"index":1,"id":"sharing-access-to-a-data-science-project_projects"},{"parentId":"managing-access-to-data-science-projects_projects","name":"Updating access to a data science project","level":2,"index":2,"id":"updating-access-to-a-data-science-project_projects"},{"parentId":"managing-access-to-data-science-projects_projects","name":"Removing access to a data science project","level":2,"index":3,"id":"removing-access-to-a-data-science-project_projects"},{"parentId":null,"name":"Creating project-scoped resources for your project","level":1,"index":5,"id":"creating-project-scoped-resources-for-your-project_projects"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-connected-applications/"},"sections":[{"parentId":null,"name":"Viewing applications that are connected to Open Data Hub","level":1,"index":0,"id":"viewing-connected-applications_connected-apps"},{"parentId":null,"name":"Enabling applications that are connected to Open Data Hub","level":1,"index":1,"id":"enabling-applications-connected_connected-apps"},{"parentId":null,"name":"Removing disabled applications from the dashboard","level":1,"index":2,"id":"removing-disabled-applications_connected-apps"},{"parentId":null,"name":"Using basic workbenches","level":1,"index":3,"id":"using-basic-workbenches_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Starting a basic workbench","level":2,"index":0,"id":"starting-a-basic-workbench_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Creating and importing Jupyter notebooks","level":2,"index":1,"id":"creating-and-importing-jupyter-notebooks_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Creating a Jupyter notebook","level":3,"index":0,"id":"creating-a-jupyter-notebook_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Uploading an existing notebook file to JupyterLab from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Additional resources","level":3,"index":2,"id":"_additional_resources"},{"parentId":"using-basic-workbenches_connected-apps","name":"Collaborating on Jupyter notebooks by using Git","level":2,"index":2,"id":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Updating your project with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Pushing project changes to a Git repository","level":3,"index":3,"id":"pushing-project-changes-to-a-git-repository_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Managing Python packages","level":2,"index":3,"id":"managing-python-packages_connected-apps"},{"parentId":"managing-python-packages_connected-apps","name":"Viewing Python packages installed on your workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_connected-apps"},{"parentId":"managing-python-packages_connected-apps","name":"Installing Python packages on your workbench","level":3,"index":1,"id":"installing-python-packages-on-your-workbench_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Updating workbench settings by restarting your workbench","level":2,"index":4,"id":"updating-workbench-settings-by-restarting-your-workbench_connected-apps"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-accelerators/"},"sections":[{"parentId":null,"name":"Overview of accelerators","level":1,"index":0,"id":"overview-of-accelerators_accelerators"},{"parentId":null,"name":"Enabling accelerators","level":1,"index":1,"id":"enabling-accelerators_accelerators"},{"parentId":null,"name":"Enabling NVIDIA GPUs","level":1,"index":2,"id":"enabling-nvidia-gpus_accelerators"},{"parentId":null,"name":"Intel Gaudi AI Accelerator integration","level":1,"index":3,"id":"intel-gaudi-ai-accelerator-integration_accelerators"},{"parentId":null,"name":"AMD GPU Integration","level":1,"index":4,"id":"amd-gpu-integration_accelerators"},{"parentId":"amd-gpu-integration_accelerators","name":"Verifying AMD GPU availability on your cluster","level":2,"index":0,"id":"verifying-amd-gpu-availability-on-your-cluster_accelerators"},{"parentId":"amd-gpu-integration_accelerators","name":"Enabling AMD GPUs","level":2,"index":1,"id":"enabling-amd-gpus_accelerators"},{"parentId":null,"name":"Working with accelerator profiles","level":1,"index":5,"id":"working-with-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Viewing accelerator profiles","level":2,"index":0,"id":"viewing-accelerator-profiles_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Creating an accelerator profile","level":2,"index":1,"id":"creating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Updating an accelerator profile","level":2,"index":2,"id":"updating-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Deleting an accelerator profile","level":2,"index":3,"id":"deleting-an-accelerator-profile_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for workbench images","level":2,"index":4,"id":"configuring-a-recommended-accelerator-for-workbench-images_accelerators"},{"parentId":"working-with-accelerator-profiles_accelerators","name":"Configuring a recommended accelerator for serving runtimes","level":2,"index":5,"id":"configuring-a-recommended-accelerator-for-serving-runtimes_accelerators"},{"parentId":null,"name":"Working with hardware profiles","level":1,"index":6,"id":"working-with-hardware-profiles_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Creating a hardware profile","level":2,"index":0,"id":"creating-a-hardware-profile_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Updating a hardware profile","level":2,"index":1,"id":"updating-a-hardware-profile_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Deleting a hardware profile","level":2,"index":2,"id":"deleting-a-hardware-profile_accelerators"},{"parentId":null,"name":"About GPU time slicing","level":1,"index":7,"id":"about-gpu-time-slicing_accelerators"},{"parentId":null,"name":"Enabling GPU time slicing","level":1,"index":8,"id":"enabling-gpu-time-slicing_accelerators"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-data-in-s3-compatible-object-store/"},"sections":[{"parentId":null,"name":"Prerequisites","level":1,"index":0,"id":"s3-prerequisites_s3"},{"parentId":null,"name":"Creating an S3 client","level":1,"index":1,"id":"creating-an-s3-client_s3"},{"parentId":null,"name":"Listing available buckets in your object store","level":1,"index":2,"id":"listing-available-amazon-buckets_s3"},{"parentId":null,"name":"Creating a bucket in your object store","level":1,"index":3,"id":"creating-an-s3-bucket_s3"},{"parentId":null,"name":"Listing files in your bucket","level":1,"index":4,"id":"listing-files-in-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Downloading files from your bucket","level":1,"index":5,"id":"downloading-files-from-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Uploading files to your bucket","level":1,"index":6,"id":"uploading-files-to-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Copying files between buckets","level":1,"index":7,"id":"copying-files-to-between-buckets_s3"},{"parentId":null,"name":"Deleting files from your bucket","level":1,"index":8,"id":"Deleting-files-on-your-object-store_s3"},{"parentId":null,"name":"Deleting a bucket from your object store","level":1,"index":9,"id":"deleting-a-s3-bucket_s3"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":10,"id":"overview-of-object-storage-endpoints_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Accessing S3-compatible object storage with self-signed certificates","level":1,"index":11,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_s3"},{"parentId":null,"name":"Additional resources","level":1,"index":12,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Managing data science pipelines","level":1,"index":0,"id":"managing-data-science-pipelines_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Configuring a pipeline server","level":2,"index":0,"id":"configuring-a-pipeline-server_ds-pipelines"},{"parentId":"configuring-a-pipeline-server_ds-pipelines","name":"Configuring a pipeline server with an external Amazon RDS database","level":3,"index":0,"id":"configuring-a-pipeline-server-with-an-external-amazon-rds-db_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Defining a pipeline","level":2,"index":1,"id":"defining-a-pipeline_ds-pipelines"},{"parentId":"defining-a-pipeline_ds-pipelines","name":"Defining a pipeline by using the Kubernetes API","level":3,"index":0,"id":"defining-a-pipeline-by-using-the-kubernetes-api_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Importing a data science pipeline","level":2,"index":2,"id":"importing-a-data-science-pipeline_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Deleting a data science pipeline","level":2,"index":3,"id":"deleting-a-data-science-pipeline_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Deleting a pipeline server","level":2,"index":4,"id":"deleting-a-pipeline-server_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Viewing the details of a pipeline server","level":2,"index":5,"id":"viewing-the-details-of-a-pipeline-server_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Viewing existing pipelines","level":2,"index":6,"id":"viewing-existing-pipelines_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Overview of pipeline versions","level":2,"index":7,"id":"overview-of-pipeline-versions_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Uploading a pipeline version","level":2,"index":8,"id":"uploading-a-pipeline-version_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Deleting a pipeline version","level":2,"index":9,"id":"deleting-a-pipeline-version_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Viewing the details of a pipeline version","level":2,"index":10,"id":"viewing-the-details-of-a-pipeline-version_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Downloading a data science pipeline version","level":2,"index":11,"id":"downloading-a-data-science-pipeline-version_ds-pipelines"},{"parentId":"managing-data-science-pipelines_ds-pipelines","name":"Overview of data science pipelines caching","level":2,"index":12,"id":"overview-of-data-science-pipelines-caching_ds-pipelines"},{"parentId":"overview-of-data-science-pipelines-caching_ds-pipelines","name":"Caching criteria","level":3,"index":0,"id":"_caching_criteria"},{"parentId":"overview-of-data-science-pipelines-caching_ds-pipelines","name":"Viewing cached steps in the Open Data Hub user interface","level":3,"index":1,"id":"_viewing_cached_steps_in_the_open_data_hub_user_interface"},{"parentId":"overview-of-data-science-pipelines-caching_ds-pipelines","name":"Controlling caching in data science pipelines","level":3,"index":2,"id":"controlling-caching-in-data-science-pipelines_ds-pipelines"},{"parentId":"controlling-caching-in-data-science-pipelines_ds-pipelines","name":"Disabling caching for individual tasks","level":4,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":"controlling-caching-in-data-science-pipelines_ds-pipelines","name":"Disabling caching for a pipeline at submit time","level":4,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":"controlling-caching-in-data-science-pipelines_ds-pipelines","name":"Disabling caching for a pipeline at compile time","level":4,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":"controlling-caching-in-data-science-pipelines_ds-pipelines","name":"Disabling caching for all pipelines (pipeline server)","level":4,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"},{"parentId":null,"name":"Managing pipeline experiments","level":1,"index":1,"id":"managing-pipeline-experiments_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Overview of pipeline experiments","level":2,"index":0,"id":"overview-of-pipeline-experiments_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Creating a pipeline experiment","level":2,"index":1,"id":"creating-a-pipeline-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Archiving a pipeline experiment","level":2,"index":2,"id":"archiving-a-pipeline-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Deleting an archived pipeline experiment","level":2,"index":3,"id":"deleting-an-archived-pipeline-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Restoring an archived pipeline experiment","level":2,"index":4,"id":"restoring-an-archived-pipeline-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Viewing pipeline task executions","level":2,"index":5,"id":"viewing-pipeline-task-executions_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Viewing pipeline artifacts","level":2,"index":6,"id":"viewing-pipeline-artifacts_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Comparing runs in an experiment","level":2,"index":7,"id":"comparing-runs-in-an-experiment_ds-pipelines"},{"parentId":"managing-pipeline-experiments_ds-pipelines","name":"Comparing runs in different experiments","level":2,"index":8,"id":"comparing-runs-in-different-experiments_ds-pipelines"},{"parentId":null,"name":"Managing pipeline runs","level":1,"index":2,"id":"managing-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Overview of pipeline runs","level":2,"index":0,"id":"overview-of-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Storing data with data science pipelines","level":2,"index":1,"id":"storing-data-with-data-science-pipelines_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Viewing active pipeline runs","level":2,"index":2,"id":"viewing-active-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Executing a pipeline run","level":2,"index":3,"id":"executing-a-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Stopping an active pipeline run","level":2,"index":4,"id":"stopping-an-active-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Duplicating an active pipeline run","level":2,"index":5,"id":"duplicating-an-active-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Viewing scheduled pipeline runs","level":2,"index":6,"id":"viewing-scheduled-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Scheduling a pipeline run using a cron job","level":2,"index":7,"id":"scheduling-a-pipeline-run-using-a-cron-job_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Scheduling a pipeline run","level":2,"index":8,"id":"scheduling-a-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Duplicating a scheduled pipeline run","level":2,"index":9,"id":"duplicating-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Deleting a scheduled pipeline run","level":2,"index":10,"id":"deleting-a-scheduled-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Viewing the details of a pipeline run","level":2,"index":11,"id":"viewing-the-details-of-a-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Viewing archived pipeline runs","level":2,"index":12,"id":"viewing-archived-pipeline-runs_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Archiving a pipeline run","level":2,"index":13,"id":"archiving-a-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Restoring an archived pipeline run","level":2,"index":14,"id":"restoring-an-archived-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Deleting an archived pipeline run","level":2,"index":15,"id":"deleting-an-archived-pipeline-run_ds-pipelines"},{"parentId":"managing-pipeline-runs_ds-pipelines","name":"Duplicating an archived pipeline run","level":2,"index":16,"id":"duplicating-an-archived-pipeline-run_ds-pipelines"},{"parentId":null,"name":"Working with pipeline logs","level":1,"index":3,"id":"working-with-pipeline-logs_ds-pipelines"},{"parentId":"working-with-pipeline-logs_ds-pipelines","name":"About pipeline logs","level":2,"index":0,"id":"about-pipeline-logs_ds-pipelines"},{"parentId":"working-with-pipeline-logs_ds-pipelines","name":"Viewing pipeline step logs","level":2,"index":1,"id":"viewing-pipeline-step-logs_ds-pipelines"},{"parentId":"working-with-pipeline-logs_ds-pipelines","name":"Downloading pipeline step logs","level":2,"index":2,"id":"downloading-pipeline-step-logs_ds-pipelines"},{"parentId":null,"name":"Working with pipelines in JupyterLab","level":1,"index":4,"id":"working-with-pipelines-in-jupyterlab_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Overview of pipelines in JupyterLab","level":2,"index":0,"id":"overview-of-pipelines-in-jupyterlab_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Accessing the pipeline editor","level":2,"index":1,"id":"accessing-the-pipeline-editor_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Creating a runtime configuration","level":2,"index":2,"id":"creating-a-runtime-configuration_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Updating a runtime configuration","level":2,"index":3,"id":"updating-a-runtime-configuration_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Deleting a runtime configuration","level":2,"index":4,"id":"deleting-a-runtime-configuration_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Duplicating a runtime configuration","level":2,"index":5,"id":"duplicating-a-runtime-configuration_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Running a pipeline in JupyterLab","level":2,"index":6,"id":"running-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ds-pipelines","name":"Exporting a pipeline in JupyterLab","level":2,"index":7,"id":"exporting-a-pipeline-in-jupyterlab_ds-pipelines"},{"parentId":null,"name":"Troubleshooting DSPA component errors","level":1,"index":5,"id":"troubleshooting-dspa-component-errors_ds-pipelines"},{"parentId":"troubleshooting-dspa-component-errors_ds-pipelines","name":"Common errors across DSP components","level":2,"index":0,"id":"_common_errors_across_dsp_components"},{"parentId":null,"name":"Migrating to data science pipelines 2.0","level":1,"index":6,"id":"migrating-to-data-science-pipelines-2_ds-pipelines"},{"parentId":"migrating-to-data-science-pipelines-2_ds-pipelines","name":"Upgrading to data science pipelines 2.0","level":2,"index":0,"id":"_upgrading_to_data_science_pipelines_2_0"},{"parentId":"migrating-to-data-science-pipelines-2_ds-pipelines","name":"Removing data science pipelines 1.0 resources","level":2,"index":1,"id":"_removing_data_science_pipelines_1_0_resources"},{"parentId":null,"name":"Additional resources","level":1,"index":7,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-distributed-workloads/"},"sections":[{"parentId":null,"name":"Overview of distributed workloads","level":1,"index":0,"id":"overview-of-distributed-workloads_distributed-workloads"},{"parentId":"overview-of-distributed-workloads_distributed-workloads","name":"Distributed workloads infrastructure","level":2,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":"overview-of-distributed-workloads_distributed-workloads","name":"Types of distributed workloads","level":2,"index":1,"id":"_types_of_distributed_workloads"},{"parentId":null,"name":"Preparing the distributed training environment","level":1,"index":1,"id":"preparing-the-distributed-training-environment_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Creating a workbench for distributed training","level":2,"index":0,"id":"creating-a-workbench-for-distributed-training_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Using the cluster server and token to authenticate","level":2,"index":1,"id":"using-the-cluster-server-and-token-to-authenticate_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Managing custom training images","level":2,"index":2,"id":"managing-custom-training-images_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"About base training images","level":3,"index":0,"id":"about-base-training-images_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"Creating a custom training image","level":3,"index":1,"id":"creating-a-custom-training-image_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"Pushing an image to the integrated OpenShift image registry","level":3,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_distributed-workloads"},{"parentId":null,"name":"Running Ray-based distributed workloads","level":1,"index":2,"id":"running-ray-based-distributed-workloads_distributed-workloads"},{"parentId":"running-ray-based-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from Jupyter notebooks","level":2,"index":0,"id":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Downloading the demo Jupyter notebooks from the CodeFlare SDK","level":3,"index":0,"id":"downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Running the demo Jupyter notebooks from the CodeFlare SDK","level":3,"index":1,"id":"running-the-demo-jupyter-notebooks-from-the-codeflare-sdk_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Managing Ray clusters from within a Jupyter notebook","level":3,"index":2,"id":"managing-ray-clusters-from-within-a-jupyter-notebook_distributed-workloads"},{"parentId":"running-ray-based-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from data science pipelines","level":2,"index":1,"id":"running-distributed-data-science-workloads-from-ds-pipelines_distributed-workloads"},{"parentId":null,"name":"Running Training Operator-based distributed training workloads","level":1,"index":3,"id":"running-kfto-based-distributed-training-workloads_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Using the Kubeflow Training Operator to run distributed training workloads","level":2,"index":0,"id":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":3,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorchJob resource","level":3,"index":1,"id":"creating-a-kfto-pytorchjob-resource_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":3,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorch training scripts","level":3,"index":3,"id":"example-kfto-pytorch-training-scripts_distributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: NCCL","level":4,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccldistributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: DDP","level":4,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_distributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: FSDP","level":4,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Dockerfile for a Training Operator PyTorch training script","level":3,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorchJob resource for multi-node training","level":3,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Using the Training Operator SDK to run distributed training workloads","level":2,"index":1,"id":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"Configuring a training job by using the Training Operator SDK","level":3,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"Running a training job by using the Training Operator SDK","level":3,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"TrainingClient API: Job-related methods","level":3,"index":2,"id":"ref-trainingclient-api-job-related-methods_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Fine-tuning a model by using Kubeflow Training","level":2,"index":2,"id":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Configuring the fine-tuning job","level":3,"index":0,"id":"configuring-the-fine-tuning-job_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Running the fine-tuning job","level":3,"index":1,"id":"running-the-fine-tuning-job_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Deleting the fine-tuning job","level":3,"index":2,"id":"deleting-the-fine-tuning-job_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Creating a multi-node PyTorch training job with RDMA","level":2,"index":3,"id":"creating-a-multi-node-pytorch-training-job-with-rdma_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorchJob resource configured to run with RDMA","level":2,"index":4,"id":"ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma_distributed-workloads"},{"parentId":null,"name":"Monitoring distributed workloads","level":1,"index":4,"id":"monitoring-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing project metrics for distributed workloads","level":2,"index":0,"id":"viewing-project-metrics-for-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing the status of distributed workloads","level":2,"index":1,"id":"viewing-the-status-of-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing Kueue alerts for distributed workloads","level":2,"index":2,"id":"viewing-kueue-alerts-for-distributed-workloads_distributed-workloads"},{"parentId":null,"name":"Troubleshooting common problems with distributed workloads for users","level":1,"index":5,"id":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster is in a suspended state","level":2,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster is in a failed state","level":2,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"failed to call webhook\" error message for the CodeFlare Operator","level":2,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"failed to call webhook\" error message for Kueue","level":2,"index":3,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster does not start","level":2,"index":4,"id":"_my_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"Default Local Queue not found\" error message","level":2,"index":5,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"local_queue provided does not exist\" error message","level":2,"index":6,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I cannot create a Ray cluster or submit jobs","level":2,"index":7,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My pod provisioned by Kueue is terminated before my image is pulled","level":2,"index":8,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-model-registries/"},"sections":[{"parentId":null,"name":"Overview of model registries","level":1,"index":0,"id":"overview-of-model-registries_model-registry"},{"parentId":null,"name":"Enabling the model registry component","level":0,"index":1,"id":"_enabling_the_model_registry_component"},{"parentId":"_enabling_the_model_registry_component","name":"Enabling the model registry component","level":1,"index":0,"id":"enabling-the-model-registry-component_model-registry"},{"parentId":"_enabling_the_model_registry_component","name":"Enabling the model catalog","level":1,"index":1,"id":"enabling-the-model-catalog_model-registry"},{"parentId":null,"name":"Managing model registries","level":0,"index":2,"id":"_managing_model_registries"},{"parentId":"_managing_model_registries","name":"Creating a model registry","level":1,"index":0,"id":"creating-a-model-registry_model-registry"},{"parentId":"_managing_model_registries","name":"Editing a model registry","level":1,"index":1,"id":"editing-a-model-registry_model-registry"},{"parentId":"_managing_model_registries","name":"Managing model registry permissions","level":1,"index":2,"id":"managing-model-registry-permissions_model-registry"},{"parentId":"_managing_model_registries","name":"Deleting a model registry","level":1,"index":3,"id":"deleting-a-model-registry_model-registry"},{"parentId":null,"name":"Working with model registries","level":0,"index":3,"id":"_working_with_model_registries"},{"parentId":"_working_with_model_registries","name":"Working with model registries","level":1,"index":0,"id":"working-with-model-registries_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Registering a model","level":2,"index":0,"id":"registering-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Registering a model from the model catalog","level":2,"index":1,"id":"registering-a-model-from-the-model-catalog_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Registering a model version","level":2,"index":2,"id":"registering-a-model-version_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Viewing registered models","level":2,"index":3,"id":"viewing-registered-models_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Viewing registered model versions","level":2,"index":4,"id":"viewing-registered-model-versions_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing model metadata in a model registry","level":2,"index":5,"id":"editing-model-metadata-in-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing model version metadata in a model registry","level":2,"index":6,"id":"editing-model-version-metadata-in-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Deploying a model version from a model registry","level":2,"index":7,"id":"deploying-a-model-version-from-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Deploying a model from the model catalog","level":2,"index":8,"id":"deploying-a-model-from-the-model-catalog_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing the deployment properties of a deployed model version from a model registry","level":2,"index":9,"id":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the multi-model serving platform","level":3,"index":0,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-multi-model-serving-platform_model-registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the single-model serving platform","level":3,"index":1,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-single-model-serving-platform_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Deleting a deployed model version from a model registry","level":2,"index":10,"id":"deleting-a-deployed-model-version-from-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Archiving a model","level":2,"index":11,"id":"archiving-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Archiving a model version","level":2,"index":12,"id":"archiving-a-model-version_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Restoring a model","level":2,"index":13,"id":"restoring-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Restoring a model version","level":2,"index":14,"id":"restoring-a-model-version_model-registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-rag/"},"sections":[{"parentId":null,"name":"Overview of RAG","level":1,"index":0,"id":"overview-of-rag_rag"},{"parentId":"overview-of-rag_rag","name":"Audience for RAG","level":2,"index":0,"id":"_audience_for_rag"},{"parentId":null,"name":"Deploying a RAG stack in a data science project","level":1,"index":1,"id":"deploying-a-rag-stack-in-a-data-science-project_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Activating the Llama Stack Operator","level":2,"index":0,"id":"activating-the-llama-stack-operator_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Deploying a Llama model with KServe","level":2,"index":1,"id":"Deploying-a-llama-model-with-kserve_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Testing your vLLM model endpoints","level":2,"index":2,"id":"testing-your-vllm-model-endpoints_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Deploying a LlamaStackDistribution instance","level":2,"index":3,"id":"deploying-a-llamastackdistribution-instance_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Ingesting content into a Llama model","level":2,"index":4,"id":"ingesting-content-into-a-llama-model_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Querying ingested content in a Llama model","level":2,"index":5,"id":"querying-ingested-content-in-a-llama-model_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"Preparing documents with Docling for Llama Stack retrieval","level":2,"index":6,"id":"preparing-documents-with-docling-for-llama-stack-retrieval_rag"},{"parentId":"deploying-a-rag-stack-in-a-data-science-project_rag","name":"About Llama stack search types","level":2,"index":7,"id":"about-llama-stack-search-types_rag"},{"parentId":"about-llama-stack-search-types_rag","name":"Supported search modes","level":3,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":4,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":4,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":4,"index":2,"id":"_hybrid_search"},{"parentId":"about-llama-stack-search-types_rag","name":"Retrieval database support","level":3,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/_artifacts/document-attributes-global/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/bias-monitoring-tutorial/"},"sections":[{"parentId":null,"name":"Introduction","level":1,"index":0,"id":"t-bias-introduction_bias-tutorial"},{"parentId":"t-bias-introduction_bias-tutorial","name":"About the example models","level":2,"index":0,"id":"_about_the_example_models"},{"parentId":null,"name":"Setting up your environment","level":1,"index":1,"id":"t-bias-setting-up-your-environment_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Downloading the tutorial files","level":2,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Logging in to the OpenShift cluster from the command line","level":2,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Configuring monitoring for the model serving platform","level":2,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Enabling the TrustyAI component","level":2,"index":3,"id":"enabling-trustyai-component_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Setting up a project","level":2,"index":4,"id":"_setting_up_a_project"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Authenticating the TrustyAI service","level":2,"index":5,"id":"_authenticating_the_trustyai_service"},{"parentId":null,"name":"Deploying models","level":1,"index":2,"id":"t-bias-deploying-models_bias-tutorial"},{"parentId":null,"name":"Sending training data to the models","level":1,"index":3,"id":"t-bias-sending-training-data-to-the-models_bias-tutorial"},{"parentId":null,"name":"Labeling data fields","level":1,"index":4,"id":"t-bias-labeling-data-fields_bias-tutorial"},{"parentId":null,"name":"Checking model fairness","level":1,"index":5,"id":"t-bias-checking-model-fairness_bias-tutorial"},{"parentId":null,"name":"Scheduling a fairness metric request","level":1,"index":6,"id":"t-bias-scheduling-a-fairness-metric-request_bias-tutorial"},{"parentId":null,"name":"Scheduling an identity metric request","level":1,"index":7,"id":"t-bias-scheduling-an-identity-metric-request_bias-tutorial"},{"parentId":null,"name":"Simulating real world data","level":1,"index":8,"id":"t-bias-simulating-real-world-data_bias-tutorial"},{"parentId":null,"name":"Reviewing the results","level":1,"index":9,"id":"t-bias-reviewing-the-results_bias-tutorial"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"Are the models biased?","level":2,"index":0,"id":"_are_the_models_biased"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"How does the production data compare to the training data?","level":2,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/collaborating-on-jupyter-notebooks-by-using-git/"},"sections":[{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":1,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_{context}"},{"parentId":null,"name":"Updating your project with changes from a remote Git repository","level":1,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_{context}"},{"parentId":null,"name":"Pushing project changes to a Git repository","level":1,"index":3,"id":"pushing-project-changes-to-a-git-repository_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/collaborating-on-workbenches-in-code-server-by-using-git/"},"sections":[{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using code-server","level":1,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-code-server_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to code-server from a Git repository by using the CLI","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli_{context}"},{"parentId":null,"name":"Updating your project in code-server with changes from a remote Git repository","level":1,"index":2,"id":"updating-your-project-in-code-server-with-changes-from-a-remote-git-repository_{context}"},{"parentId":null,"name":"Pushing project changes in code-server to a Git repository","level":1,"index":3,"id":"pushing-project-changes-in-code-server-to-a-git-repository_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-cluster-storage/"},"sections":[{"parentId":null,"name":"About persistent storage","level":1,"index":0,"id":"about-persistent-storage_{context}"},{"parentId":"about-persistent-storage_{context}","name":"Storage classes in {productname-short}","level":2,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":"about-persistent-storage_{context}","name":"Access modes","level":2,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":3,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":null,"name":"Adding cluster storage to your data science project","level":1,"index":1,"id":"adding-cluster-storage-to-your-data-science-project_{context}"},{"parentId":null,"name":"Updating cluster storage","level":1,"index":2,"id":"updating-cluster-storage_{context}"},{"parentId":null,"name":"Changing the storage class for an existing cluster storage instance","level":1,"index":3,"id":"changing-the-storage-class-for-an-existing-cluster-storage-instance_{context}"},{"parentId":null,"name":"Deleting cluster storage from a data science project","level":1,"index":4,"id":"deleting-cluster-storage-from-a-data-science-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-the-guardrails-orchestrator-service/"},"sections":[{"parentId":null,"name":"Deploying the Guardrails Orchestrator service","level":1,"index":0,"id":"deploying-the-guardrails-orchestrator-service_{context}"},{"parentId":null,"name":"Guardrails Orchestrator parameters","level":1,"index":1,"id":"guardrails-orchestrator-parameters_{context}"},{"parentId":null,"name":"Monitoring user inputs with the Guardrails Orchestrator service","level":1,"index":2,"id":"guardrails-orchestrator-hap-scenario_{context}"},{"parentId":null,"name":"Configuring the regex detector and guardrails gateway","level":1,"index":3,"id":"configuring-regex-guardrails-gateway_{context}"},{"parentId":"configuring-regex-guardrails-gateway_{context}","name":"Sending requests to the regex detector","level":2,"index":0,"id":"sending-requests-to-the-regex-detector_{context}"},{"parentId":"configuring-regex-guardrails-gateway_{context}","name":"Querying using guardrails gateway","level":2,"index":1,"id":"querying-using-guardrails-gateway_{context}"},{"parentId":null,"name":"Configuring the OpenTelemetry exporter","level":1,"index":4,"id":"configuring-the-opentelemetry-exporter_{context}"},{"parentId":null,"name":"Using Hugging Face models with Guardrails Orchestrator","level":1,"index":5,"id":"using-hugging-face-models-with-guardrails-orchestrator_{context}"},{"parentId":null,"name":"Configuring the Guardrails Detector Hugging Face serving runtime","level":1,"index":6,"id":"configuring-the-guardrails-detector-hugging-face-serving-runtime_{context}"},{"parentId":null,"name":"Using a Hugging Face Prompt Injection detector with the Guardrails Orchestrator","level":1,"index":7,"id":"using-a-hugging-face-prompt-injection-detector-with-guardrails-orchestrator_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-trustyai/"},"sections":[{"parentId":null,"name":"Configuring monitoring for your model serving platform","level":1,"index":0,"id":"configuring-monitoring-for-your-model-serving-platform_{context}"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":1,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Configuring TrustyAI with a database","level":1,"index":2,"id":"configuring-trustyai-with-a-database_{context}"},{"parentId":null,"name":"Installing the TrustyAI service for a project","level":1,"index":3,"id":"installing-trustyai-service_{context}"},{"parentId":"installing-trustyai-service_{context}","name":"Installing the TrustyAI service by using the dashboard","level":2,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":"installing-trustyai-service_{context}","name":"Installing the TrustyAI service by using the CLI","level":2,"index":1,"id":"installing-trustyai-service-using-cli_{context}"},{"parentId":null,"name":"Enabling TrustyAI Integration with standard model deployment","level":1,"index":4,"id":"enabling-trustyai-kserve-integration_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-and-importing-jupyter-notebooks/"},"sections":[{"parentId":null,"name":"Creating a Jupyter notebook","level":1,"index":0,"id":"creating-a-jupyter-notebook_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to JupyterLab from local storage","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_{context}"},{"parentId":null,"name":"Additional resources","level":1,"index":2,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-code-server-workbenches/"},"sections":[{"parentId":null,"name":"Creating a workbench","level":1,"index":0,"id":"creating-a-project-workbench_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to code-server from local storage","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-local-storage_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-custom-workbench-images/"},"sections":[{"parentId":null,"name":"Creating a custom image from a default {productname-short} image","level":1,"index":0,"id":"creating-a-custom-image-from-default-image_custom-images"},{"parentId":null,"name":"Creating a custom image from your own image","level":1,"index":1,"id":"creating-a-custom-image-from-your-own-image_custom-images"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Basic guidelines for creating your own workbench image","level":2,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Advanced guidelines for creating your own workbench image","level":2,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Enabling custom images in {productname-short}","level":1,"index":2,"id":"enabling-custom-images_custom-images"},{"parentId":null,"name":"Importing a custom workbench image","level":1,"index":3,"id":"importing-a-custom-workbench-image_custom-images"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-component-deployment-resources/"},"sections":[{"parentId":null,"name":"Overview of component resource customization","level":1,"index":0,"id":"overview-of-component-resource-customization_managing-resources"},{"parentId":null,"name":"Customizing component resources","level":1,"index":1,"id":"customizing-component-resources_managing-resources"},{"parentId":null,"name":"Disabling component resource customization","level":1,"index":2,"id":"disabling-component-resource-customization_managing-resources"},{"parentId":null,"name":"Re-enabling component resource customization","level":1,"index":3,"id":"reenabling-component-resource-customization_managing-resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-the-dashboard/"},"sections":[{"parentId":null,"name":"Editing the dashboard configuration","level":1,"index":0,"id":"editing-the-dashboard-configuration_dashboard"},{"parentId":null,"name":"Dashboard configuration options","level":1,"index":1,"id":"ref-dashboard-configuration-options_dashboard"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-your-feature-store-configuration/"},"sections":[{"parentId":null,"name":"Specifying to use a feature project from a Git repository","level":1,"index":0,"id":"specifying-to-use-a-feature-project-from-git-repository_{context}"},{"parentId":null,"name":"Configuring an offline store","level":1,"index":1,"id":"configuring-an-offline-store_{context}"},{"parentId":null,"name":"Configuring an online store","level":1,"index":2,"id":"configuring-an-online-store_{context}"},{"parentId":null,"name":"Configuring the feature registry","level":1,"index":3,"id":"configuring-the-feature-registry_{context}"},{"parentId":null,"name":"Example PVC configuration","level":1,"index":4,"id":"ref-example-pvc-configuration_{context}"},{"parentId":null,"name":"Configuring role-based access control","level":1,"index":5,"id":"configuring-role-based-access-control_{context}"},{"parentId":"configuring-role-based-access-control_{context}","name":"Default authorization configuration","level":2,"index":0,"id":"ref-default-authorization-configuration_{context}"},{"parentId":"configuring-role-based-access-control_{context}","name":"Example OIDC Authorization configuration","level":2,"index":1,"id":"ref-example-oidc-authorization-configuration_{context}"},{"parentId":"configuring-role-based-access-control_{context}","name":"Example Kubernetes Authorization configuration","level":2,"index":2,"id":"ref-example-kubernetes-authorization-configuration_{context}"},{"parentId":null,"name":"Editing an existing feature store instance","level":1,"index":6,"id":"editing-an-existing-feature-store-instance_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/deploying-a-rag-stack-in-a-data-science-project/"},"sections":[{"parentId":null,"name":"Activating the Llama Stack Operator","level":1,"index":0,"id":"activating-the-llama-stack-operator_{context}"},{"parentId":null,"name":"Deploying a Llama model with KServe","level":1,"index":1,"id":"Deploying-a-llama-model-with-kserve_{context}"},{"parentId":null,"name":"Testing your vLLM model endpoints","level":1,"index":2,"id":"testing-your-vllm-model-endpoints_{context}"},{"parentId":null,"name":"Deploying a LlamaStackDistribution instance","level":1,"index":3,"id":"deploying-a-llamastackdistribution-instance_{context}"},{"parentId":null,"name":"Ingesting content into a Llama model","level":1,"index":4,"id":"ingesting-content-into-a-llama-model_{context}"},{"parentId":null,"name":"Querying ingested content in a Llama model","level":1,"index":5,"id":"querying-ingested-content-in-a-llama-model_{context}"},{"parentId":null,"name":"Preparing documents with Docling for Llama Stack retrieval","level":1,"index":6,"id":"preparing-documents-with-docling-for-llama-stack-retrieval_{context}"},{"parentId":null,"name":"About Llama stack search types","level":1,"index":7,"id":"about-llama-stack-search-types_{context}"},{"parentId":"about-llama-stack-search-types_{context}","name":"Supported search modes","level":2,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":3,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":3,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":3,"index":2,"id":"_hybrid_search"},{"parentId":"about-llama-stack-search-types_{context}","name":"Retrieval database support","level":2,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/enabling-lab-tuning/"},"sections":[{"parentId":null,"name":"Overview of enabling LAB-tuning","level":1,"index":0,"id":"overview-of-enabling-lab-tuning_{context}"},{"parentId":"overview-of-enabling-lab-tuning_{context}","name":"Requirements for LAB-tuning","level":2,"index":0,"id":"_requirements_for_lab_tuning"},{"parentId":null,"name":"Installing the required Operators for LAB-tuning","level":1,"index":1,"id":"installing-the-required-operators-for-lab-tuning_{context}"},{"parentId":null,"name":"Installing the required components for LAB-tuning","level":1,"index":2,"id":"installing-the-required-components-for-lab-tuning_{context}"},{"parentId":null,"name":"Configuring a storage class for LAB-tuning","level":1,"index":3,"id":"configuring-a-storage-class-for-lab-tuning_{context}"},{"parentId":null,"name":"Making LAB-tuning and hardware profile features visible","level":1,"index":4,"id":"making-lab-tuning-and-hardware-profile-features-visible_{context}"},{"parentId":null,"name":"Creating a model registry for LAB-tuning","level":1,"index":5,"id":"creating-a-model-registry-for-lab-tuning_{context}"},{"parentId":null,"name":"Creating a hardware profile for LAB-tuning","level":1,"index":6,"id":"creating-a-hardware-profile-for-lab-tuning_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/enforcing-local-queues/"},"sections":[{"parentId":null,"name":"Enforcing the local-queue labeling policy for all projects","level":1,"index":0,"id":"enforcing-lqlabel-all_{context}"},{"parentId":null,"name":"Disabling the local-queue labeling policy for all projects","level":1,"index":1,"id":"disabling-lqlabel-all_{context}"},{"parentId":null,"name":"Enforcing the local-queue labeling policy for some projects only","level":1,"index":2,"id":"enforcing-lqlabel-some_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/evaluating-large-language-models/"},"sections":[{"parentId":null,"name":"Setting up LM-Eval","level":1,"index":0,"id":"setting-up-lmeval_{context}"},{"parentId":null,"name":"LM-Eval evaluation job","level":1,"index":1,"id":"lmeval-evaluation-job_{context}"},{"parentId":null,"name":"LM-Eval evaluation job properties","level":1,"index":2,"id":"lmeval-evaluation-job-properties_{context}"},{"parentId":"lmeval-evaluation-job-properties_{context}","name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":2,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"},{"parentId":null,"name":"LM-Eval scenarios","level":1,"index":3,"id":"lmeval-scenarios_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Accessing Hugging Face models with an environment variable token","level":2,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using a custom Unitxt card","level":2,"index":1,"id":"using-a-custom-unitxt-card_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using PVCs as storage","level":2,"index":2,"id":"using-pvcs-as-storage_{context}"},{"parentId":"using-pvcs-as-storage_{context}","name":"Managed PVCs","level":3,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_{context}","name":"Existing PVCs","level":3,"index":1,"id":"_existing_pvcs"},{"parentId":"lmeval-scenarios_{context}","name":"Using a KServe Inference Service","level":2,"index":3,"id":"using-a-kserve-inference-service_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Setting up LM-Eval S3 Support","level":2,"index":4,"id":"setting-up-lmeval-s3-support_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using LLM-as-a-Judge metrics with LM-Eval","level":2,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/example-kfto-pytorch-training-scripts/"},"sections":[{"parentId":null,"name":"Example Training Operator PyTorch training script: NCCL","level":1,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training script: DDP","level":1,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training script: FSDP","level":1,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/fine-tuning-a-model-by-using-kubeflow-training/"},"sections":[{"parentId":null,"name":"Configuring the fine-tuning job","level":1,"index":0,"id":"configuring-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Running the fine-tuning job","level":1,"index":1,"id":"running-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Deleting the fine-tuning job","level":1,"index":2,"id":"deleting-the-fine-tuning-job_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v1/"},"sections":[{"parentId":null,"name":"Installing the Open Data Hub Operator version 1","level":1,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":null,"name":"Creating a new project for your Open Data Hub instance","level":1,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":null,"name":"Adding an Open Data Hub instance","level":1,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":null,"name":"Accessing the Open Data Hub dashboard","level":1,"index":3,"id":"accessing-the-odh-dashboard_installv1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v2/"},"sections":[{"parentId":null,"name":"Configuring custom namespaces","level":1,"index":0,"id":"configuring-custom-namespaces"},{"parentId":null,"name":"Installing the Open Data Hub Operator version 2","level":1,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":2,"id":"installing-odh-components_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/lmeval-scenarios/"},"sections":[{"parentId":null,"name":"Accessing Hugging Face models with an environment variable token","level":1,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_{context}"},{"parentId":null,"name":"Using a custom Unitxt card","level":1,"index":1,"id":"using-a-custom-unitxt-card_{context}"},{"parentId":null,"name":"Using PVCs as storage","level":1,"index":2,"id":"using-pvcs-as-storage_{context}"},{"parentId":"using-pvcs-as-storage_{context}","name":"Managed PVCs","level":2,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_{context}","name":"Existing PVCs","level":2,"index":1,"id":"_existing_pvcs"},{"parentId":null,"name":"Using a KServe Inference Service","level":1,"index":3,"id":"using-a-kserve-inference-service_{context}"},{"parentId":null,"name":"Setting up LM-Eval S3 Support","level":1,"index":4,"id":"setting-up-lmeval-s3-support_{context}"},{"parentId":null,"name":"Using LLM-as-a-Judge metrics with LM-Eval","level":1,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-access-to-data-science-projects/"},"sections":[{"parentId":null,"name":"Configuring access to a data science project","level":1,"index":0,"id":"configuring-access-to-a-data-science-project_{context}"},{"parentId":null,"name":"Sharing access to a data science project","level":1,"index":1,"id":"sharing-access-to-a-data-science-project_{context}"},{"parentId":null,"name":"Updating access to a data science project","level":1,"index":2,"id":"updating-access-to-a-data-science-project_{context}"},{"parentId":null,"name":"Removing access to a data science project","level":1,"index":3,"id":"removing-access-to-a-data-science-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-applications-that-show-in-the-dashboard/"},"sections":[{"parentId":null,"name":"Adding an application to the dashboard","level":1,"index":0,"id":"adding-an-application-to-the-dashboard_dashboard"},{"parentId":null,"name":"Preventing users from adding applications to the dashboard","level":1,"index":1,"id":"preventing-users-from-adding-applications-to-the-dashboard_dashboard"},{"parentId":null,"name":"Disabling applications connected to {productname-short}","level":1,"index":2,"id":"disabling-applications-connected_dashboard"},{"parentId":null,"name":"Showing or hiding information about available applications","level":1,"index":3,"id":"showing-hiding-information-about-available-applications_dashboard"},{"parentId":null,"name":"Hiding the default basic workbench application","level":1,"index":4,"id":"hiding-the-default-basic-workbench-application_dashboard"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-basic-workbenches/"},"sections":[{"parentId":null,"name":"Accessing the administration interface for basic workbenches","level":1,"index":0,"id":"accessing-the-administration-interface-for-basic-workbenches_{context}"},{"parentId":null,"name":"Starting basic workbenches owned by other users","level":1,"index":1,"id":"starting-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Accessing basic workbenches owned by other users","level":1,"index":2,"id":"accessing-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping basic workbenches owned by other users","level":1,"index":3,"id":"stopping-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping idle workbenches","level":1,"index":4,"id":"stopping-idle-workbenches_{context}"},{"parentId":null,"name":"Adding workbench pod tolerations","level":1,"index":5,"id":"adding-workbench-pod-tolerations_{context}"},{"parentId":null,"name":"Troubleshooting common problems in workbenches for administrators","level":1,"index":6,"id":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":2,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"A user&#8217;s workbench does not start","level":2,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":2,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-cluster-pvc-size/"},"sections":[{"parentId":null,"name":"Configuring the default PVC size for your cluster","level":1,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_{context}"},{"parentId":null,"name":"Restoring the default PVC size for your cluster","level":1,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-connection-types/"},"sections":[{"parentId":null,"name":"Viewing connection types","level":1,"index":0,"id":"viewing-connection-types_{context}"},{"parentId":null,"name":"Creating a connection type","level":1,"index":1,"id":"creating-a-connection-type_{context}"},{"parentId":null,"name":"Duplicating a connection type","level":1,"index":2,"id":"duplicating-a-connection-type_{context}"},{"parentId":null,"name":"Editing a connection type","level":1,"index":3,"id":"editing-a-connection-type_{context}"},{"parentId":null,"name":"Enabling a connection type","level":1,"index":4,"id":"enabling-a-connection-type_{context}"},{"parentId":null,"name":"Deleting a connection type","level":1,"index":5,"id":"deleting-a-connection-type_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-custom-training-images/"},"sections":[{"parentId":null,"name":"About base training images","level":1,"index":0,"id":"about-base-training-images_{context}"},{"parentId":null,"name":"Creating a custom training image","level":1,"index":1,"id":"creating-a-custom-training-image_{context}"},{"parentId":null,"name":"Pushing an image to the integrated OpenShift image registry","level":1,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Configuring a pipeline server","level":1,"index":0,"id":"configuring-a-pipeline-server_{context}"},{"parentId":"configuring-a-pipeline-server_{context}","name":"Configuring a pipeline server with an external Amazon RDS database","level":2,"index":0,"id":"configuring-a-pipeline-server-with-an-external-amazon-rds-db_{context}"},{"parentId":null,"name":"Defining a pipeline","level":1,"index":1,"id":"defining-a-pipeline_{context}"},{"parentId":"defining-a-pipeline_{context}","name":"Defining a pipeline by using the Kubernetes API","level":2,"index":0,"id":"defining-a-pipeline-by-using-the-kubernetes-api_{context}"},{"parentId":null,"name":"Importing a data science pipeline","level":1,"index":2,"id":"importing-a-data-science-pipeline_{context}"},{"parentId":null,"name":"Deleting a data science pipeline","level":1,"index":3,"id":"deleting-a-data-science-pipeline_{context}"},{"parentId":null,"name":"Deleting a pipeline server","level":1,"index":4,"id":"deleting-a-pipeline-server_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline server","level":1,"index":5,"id":"viewing-the-details-of-a-pipeline-server_{context}"},{"parentId":null,"name":"Viewing existing pipelines","level":1,"index":6,"id":"viewing-existing-pipelines_{context}"},{"parentId":null,"name":"Overview of pipeline versions","level":1,"index":7,"id":"overview-of-pipeline-versions_{context}"},{"parentId":null,"name":"Uploading a pipeline version","level":1,"index":8,"id":"uploading-a-pipeline-version_{context}"},{"parentId":null,"name":"Deleting a pipeline version","level":1,"index":9,"id":"deleting-a-pipeline-version_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline version","level":1,"index":10,"id":"viewing-the-details-of-a-pipeline-version_{context}"},{"parentId":null,"name":"Downloading a data science pipeline version","level":1,"index":11,"id":"downloading-a-data-science-pipeline-version_{context}"},{"parentId":null,"name":"Overview of data science pipelines caching","level":1,"index":12,"id":"overview-of-data-science-pipelines-caching_{context}"},{"parentId":"overview-of-data-science-pipelines-caching_{context}","name":"Caching criteria","level":2,"index":0,"id":"_caching_criteria"},{"parentId":"overview-of-data-science-pipelines-caching_{context}","name":"Viewing cached steps in the {productname-short} user interface","level":2,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"},{"parentId":"overview-of-data-science-pipelines-caching_{context}","name":"Controlling caching in data science pipelines","level":2,"index":2,"id":"controlling-caching-in-data-science-pipelines_{context}"},{"parentId":"controlling-caching-in-data-science-pipelines_{context}","name":"Disabling caching for individual tasks","level":3,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":"controlling-caching-in-data-science-pipelines_{context}","name":"Disabling caching for a pipeline at submit time","level":3,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":"controlling-caching-in-data-science-pipelines_{context}","name":"Disabling caching for a pipeline at compile time","level":3,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":"controlling-caching-in-data-science-pipelines_{context}","name":"Disabling caching for all pipelines (pipeline server)","level":3,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-distributed-workloads/"},"sections":[{"parentId":null,"name":"Overview of Kueue resources","level":1,"index":0,"id":"overview-of-kueue-resources_{context}"},{"parentId":"overview-of-kueue-resources_{context}","name":"Resource flavor","level":2,"index":0,"id":"_resource_flavor"},{"parentId":"overview-of-kueue-resources_{context}","name":"Cluster queue","level":2,"index":1,"id":"_cluster_queue"},{"parentId":"overview-of-kueue-resources_{context}","name":"Local queue","level":2,"index":2,"id":"_local_queue"},{"parentId":null,"name":"Example Kueue resource configurations","level":1,"index":1,"id":"ref-example-kueue-resource-configurations_{context}"},{"parentId":"ref-example-kueue-resource-configurations_{context}","name":"NVIDIA GPUs without shared cohort","level":2,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":3,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":3,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":3,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":3,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":"ref-example-kueue-resource-configurations_{context}","name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":2,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":3,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":3,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":3,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":3,"index":3,"id":"_nvidia_gpu_cluster_queue"},{"parentId":null,"name":"Configuring quota management for distributed workloads","level":1,"index":2,"id":"configuring-quota-management-for-distributed-workloads_{context}"},{"parentId":null,"name":"Enforcing the use of local queues","level":1,"index":3,"id":"enforcing-local-queues_{context}"},{"parentId":"enforcing-local-queues_{context}","name":"Enforcing the local-queue labeling policy for all projects","level":2,"index":0,"id":"enforcing-lqlabel-all_{context}"},{"parentId":"enforcing-local-queues_{context}","name":"Disabling the local-queue labeling policy for all projects","level":2,"index":1,"id":"disabling-lqlabel-all_{context}"},{"parentId":"enforcing-local-queues_{context}","name":"Enforcing the local-queue labeling policy for some projects only","level":2,"index":2,"id":"enforcing-lqlabel-some_{context}"},{"parentId":null,"name":"Configuring the CodeFlare Operator","level":1,"index":4,"id":"configuring-the-codeflare-operator_{context}"},{"parentId":null,"name":"Configuring a cluster for RDMA","level":1,"index":5,"id":"configuring-a-cluster-for-rdma_{context}"},{"parentId":null,"name":"Troubleshooting common problems with distributed workloads for administrators","level":1,"index":6,"id":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster is in a suspended state","level":2,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster is in a failed state","level":2,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user receives a \"failed to call webhook\" error message for the CodeFlare Operator","level":2,"index":2,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user receives a \"failed to call webhook\" error message for Kueue","level":2,"index":3,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster does not start","level":2,"index":4,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message","level":2,"index":5,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user receives a <strong>local_queue provided does not exist</strong> error message","level":2,"index":6,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user cannot create a Ray cluster or submit jobs","level":2,"index":7,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled","level":2,"index":8,"id":"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-pipeline-experiments/"},"sections":[{"parentId":null,"name":"Overview of pipeline experiments","level":1,"index":0,"id":"overview-of-pipeline-experiments_{context}"},{"parentId":null,"name":"Creating a pipeline experiment","level":1,"index":1,"id":"creating-a-pipeline-experiment_{context}"},{"parentId":null,"name":"Archiving a pipeline experiment","level":1,"index":2,"id":"archiving-a-pipeline-experiment_{context}"},{"parentId":null,"name":"Deleting an archived pipeline experiment","level":1,"index":3,"id":"deleting-an-archived-pipeline-experiment_{context}"},{"parentId":null,"name":"Restoring an archived pipeline experiment","level":1,"index":4,"id":"restoring-an-archived-pipeline-experiment_{context}"},{"parentId":null,"name":"Viewing pipeline task executions","level":1,"index":5,"id":"viewing-pipeline-task-executions_{context}"},{"parentId":null,"name":"Viewing pipeline artifacts","level":1,"index":6,"id":"viewing-pipeline-artifacts_{context}"},{"parentId":null,"name":"Comparing runs in an experiment","level":1,"index":7,"id":"comparing-runs-in-an-experiment_{context}"},{"parentId":null,"name":"Comparing runs in different experiments","level":1,"index":8,"id":"comparing-runs-in-different-experiments_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-pipeline-runs/"},"sections":[{"parentId":null,"name":"Overview of pipeline runs","level":1,"index":0,"id":"overview-of-pipeline-runs_{context}"},{"parentId":null,"name":"Storing data with data science pipelines","level":1,"index":1,"id":"storing-data-with-data-science-pipelines_{context}"},{"parentId":null,"name":"Viewing active pipeline runs","level":1,"index":2,"id":"viewing-active-pipeline-runs_{context}"},{"parentId":null,"name":"Executing a pipeline run","level":1,"index":3,"id":"executing-a-pipeline-run_{context}"},{"parentId":null,"name":"Stopping an active pipeline run","level":1,"index":4,"id":"stopping-an-active-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating an active pipeline run","level":1,"index":5,"id":"duplicating-an-active-pipeline-run_{context}"},{"parentId":null,"name":"Viewing scheduled pipeline runs","level":1,"index":6,"id":"viewing-scheduled-pipeline-runs_{context}"},{"parentId":null,"name":"Scheduling a pipeline run using a cron job","level":1,"index":7,"id":"scheduling-a-pipeline-run-using-a-cron-job_{context}"},{"parentId":null,"name":"Scheduling a pipeline run","level":1,"index":8,"id":"scheduling-a-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating a scheduled pipeline run","level":1,"index":9,"id":"duplicating-a-scheduled-pipeline-run_{context}"},{"parentId":null,"name":"Deleting a scheduled pipeline run","level":1,"index":10,"id":"deleting-a-scheduled-pipeline-run_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline run","level":1,"index":11,"id":"viewing-the-details-of-a-pipeline-run_{context}"},{"parentId":null,"name":"Viewing archived pipeline runs","level":1,"index":12,"id":"viewing-archived-pipeline-runs_{context}"},{"parentId":null,"name":"Archiving a pipeline run","level":1,"index":13,"id":"archiving-a-pipeline-run_{context}"},{"parentId":null,"name":"Restoring an archived pipeline run","level":1,"index":14,"id":"restoring-an-archived-pipeline-run_{context}"},{"parentId":null,"name":"Deleting an archived pipeline run","level":1,"index":15,"id":"deleting-an-archived-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating an archived pipeline run","level":1,"index":16,"id":"duplicating-an-archived-pipeline-run_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-python-packages-in-code-server/"},"sections":[{"parentId":null,"name":"Viewing Python packages installed on your code-server workbench","level":1,"index":0,"id":"viewing-python-packages-installed-on-your-code-server-workbench_{context}"},{"parentId":null,"name":"Installing Python packages on your code-server workbench","level":1,"index":1,"id":"installing-python-packages-on-your-code-server-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-python-packages/"},"sections":[{"parentId":null,"name":"Viewing Python packages installed on your workbench","level":1,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_{context}"},{"parentId":null,"name":"Installing Python packages on your workbench","level":1,"index":1,"id":"installing-python-packages-on-your-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-storage-classes/"},"sections":[{"parentId":null,"name":"About persistent storage","level":1,"index":0,"id":"about-persistent-storage_{context}"},{"parentId":"about-persistent-storage_{context}","name":"Storage classes in {productname-short}","level":2,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":"about-persistent-storage_{context}","name":"Access modes","level":2,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":3,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":null,"name":"Configuring storage class settings","level":1,"index":1,"id":"configuring-storage-class-settings_{context}"},{"parentId":null,"name":"Configuring the default storage class for your cluster","level":1,"index":2,"id":"configuring-the-default-storage-class-for-your-cluster_{context}"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":3,"id":"overview-of-object-storage-endpoints_{context}"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-users-and-groups/"},"sections":[{"parentId":null,"name":"Overview of user types and permissions","level":1,"index":0,"id":"overview-of-user-types-and-permissions_{context}"},{"parentId":null,"name":"Viewing {productname-short} users","level":1,"index":1,"id":"viewing-data-science-users_{context}"},{"parentId":null,"name":"Adding users to {productname-short} user groups","level":1,"index":2,"id":"adding-users-to-user-groups_{context}"},{"parentId":null,"name":"Selecting {productname-short} administrator and user groups","level":1,"index":3,"id":"selecting-admin-and-user-groups_{context}"},{"parentId":null,"name":"Deleting users","level":1,"index":4,"id":"_deleting_users"},{"parentId":"_deleting_users","name":"About deleting users and their resources","level":2,"index":0,"id":"about-deleting-users-and-resources_{context}"},{"parentId":"_deleting_users","name":"Stopping basic workbenches owned by other users","level":2,"index":1,"id":"stopping-basic-workbenches-owned-by-other-users_{context}"},{"parentId":"_deleting_users","name":"Revoking user access to basic workbenches","level":2,"index":2,"id":"revoking-user-access-to-basic-workbenches_{context}"},{"parentId":"_deleting_users","name":"Backing up storage data","level":2,"index":3,"id":"backing-up-storage-data_{context}"},{"parentId":"_deleting_users","name":"Cleaning up after deleting users","level":2,"index":4,"id":"cleaning-up-after-deleting-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-data-drift/"},"sections":[{"parentId":null,"name":"Creating a drift metric","level":1,"index":0,"id":"creating-a-drift-metric_drift-monitoring"},{"parentId":"creating-a-drift-metric_drift-monitoring","name":"Creating a drift metric by using the CLI","level":2,"index":0,"id":"creating-a-drift-metric-using-cli_drift-monitoring"},{"parentId":null,"name":"Deleting a drift metric by using the CLI","level":1,"index":1,"id":"deleting-a-drift-metric-using-cli_drift-monitoring"},{"parentId":null,"name":"Viewing data drift metrics for a model","level":1,"index":2,"id":"viewing-drift-metrics_drift-monitoring"},{"parentId":null,"name":"Using drift metrics","level":1,"index":3,"id":"using-drift-metrics_drift-monitoring"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-distributed-workloads/"},"sections":[{"parentId":null,"name":"Viewing project metrics for distributed workloads","level":1,"index":0,"id":"viewing-project-metrics-for-distributed-workloads_{context}"},{"parentId":null,"name":"Viewing the status of distributed workloads","level":1,"index":1,"id":"viewing-the-status-of-distributed-workloads_{context}"},{"parentId":null,"name":"Viewing Kueue alerts for distributed workloads","level":1,"index":2,"id":"viewing-kueue-alerts-for-distributed-workloads_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-model-bias/"},"sections":[{"parentId":null,"name":"Creating a bias metric","level":1,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":2,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":2,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Duplicating a bias metric","level":2,"index":2,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":null,"name":"Deleting a bias metric","level":1,"index":1,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":2,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":2,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":null,"name":"Viewing bias metrics for a model","level":1,"index":2,"id":"viewing-bias-metrics_bias-monitoring"},{"parentId":null,"name":"Using bias metrics","level":1,"index":3,"id":"using-bias-metrics_bias-monitoring"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-model-performance/"},"sections":[{"parentId":null,"name":"Viewing performance metrics for all models on a model server","level":1,"index":0,"id":"viewing-performance-metrics-for-model-server_monitoring-model-performance"},{"parentId":null,"name":"Viewing HTTP request metrics for a deployed model","level":1,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/preparing-lab-tuning-resources/"},"sections":[{"parentId":null,"name":"Creating a taxonomy","level":1,"index":0,"id":"creating-a-taxonomy_{context}"},{"parentId":null,"name":"Preparing a storage location for the LAB-tuned model","level":1,"index":1,"id":"preparing-a-storage-location-for-the-lab-tuned-model_{context}"},{"parentId":null,"name":"Creating a project for LAB-tuning","level":1,"index":2,"id":"creating-a-project-for-lab-tuning_{context}"},{"parentId":null,"name":"Deploying teacher and judge models","level":1,"index":3,"id":"deploying-teacher-and-judge-models_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/preparing-the-distributed-training-environment/"},"sections":[{"parentId":null,"name":"Creating a workbench for distributed training","level":1,"index":0,"id":"creating-a-workbench-for-distributed-training_{context}"},{"parentId":null,"name":"Using the cluster server and token to authenticate","level":1,"index":1,"id":"using-the-cluster-server-and-token-to-authenticate_{context}"},{"parentId":null,"name":"Managing custom training images","level":1,"index":2,"id":"managing-custom-training-images_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"About base training images","level":2,"index":0,"id":"about-base-training-images_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"Creating a custom training image","level":2,"index":1,"id":"creating-a-custom-training-image_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"Pushing an image to the integrated OpenShift image registry","level":2,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/running-kfto-based-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Using the Kubeflow Training Operator to run distributed training workloads","level":1,"index":0,"id":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":2,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorchJob resource","level":2,"index":1,"id":"creating-a-kfto-pytorchjob-resource_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":2,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Training Operator PyTorch training scripts","level":2,"index":3,"id":"example-kfto-pytorch-training-scripts_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: NCCL","level":3,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: DDP","level":3,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: FSDP","level":3,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Dockerfile for a Training Operator PyTorch training script","level":2,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Training Operator PyTorchJob resource for multi-node training","level":2,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_{context}"},{"parentId":null,"name":"Using the Training Operator SDK to run distributed training workloads","level":1,"index":1,"id":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"Configuring a training job by using the Training Operator SDK","level":2,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"Running a training job by using the Training Operator SDK","level":2,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"TrainingClient API: Job-related methods","level":2,"index":2,"id":"ref-trainingclient-api-job-related-methods_{context}"},{"parentId":null,"name":"Fine-tuning a model by using Kubeflow Training","level":1,"index":2,"id":"fine-tuning-a-model-by-using-kubeflow-training_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Configuring the fine-tuning job","level":2,"index":0,"id":"configuring-the-fine-tuning-job_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Running the fine-tuning job","level":2,"index":1,"id":"running-the-fine-tuning-job_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Deleting the fine-tuning job","level":2,"index":2,"id":"deleting-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Creating a multi-node PyTorch training job with RDMA","level":1,"index":3,"id":"creating-a-multi-node-pytorch-training-job-with-rdma_{context}"},{"parentId":null,"name":"Example Training Operator PyTorchJob resource configured to run with RDMA","level":1,"index":4,"id":"ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/running-ray-based-distributed-workloads/"},"sections":[{"parentId":null,"name":"Running distributed data science workloads from Jupyter notebooks","level":1,"index":0,"id":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Downloading the demo Jupyter notebooks from the CodeFlare SDK","level":2,"index":0,"id":"downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Running the demo Jupyter notebooks from the CodeFlare SDK","level":2,"index":1,"id":"running-the-demo-jupyter-notebooks-from-the-codeflare-sdk_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Managing Ray clusters from within a Jupyter notebook","level":2,"index":2,"id":"managing-ray-clusters-from-within-a-jupyter-notebook_{context}"},{"parentId":null,"name":"Running distributed data science workloads from data science pipelines","level":1,"index":1,"id":"running-distributed-data-science-workloads-from-ds-pipelines_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/serving-large-models/"},"sections":[{"parentId":null,"name":"About the single-model serving platform","level":1,"index":0,"id":"about-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Model-serving runtimes","level":1,"index":1,"id":"model-serving-runtimes_serving-large-models"},{"parentId":"model-serving-runtimes_serving-large-models","name":"ServingRuntime","level":2,"index":0,"id":"_servingruntime"},{"parentId":"model-serving-runtimes_serving-large-models","name":"InferenceService","level":2,"index":1,"id":"_inferenceservice"},{"parentId":null,"name":"About KServe deployment modes","level":1,"index":2,"id":"about-kserve-deployment-modes_serving-large-models"},{"parentId":"about-kserve-deployment-modes_serving-large-models","name":"Advanced mode","level":2,"index":0,"id":"_advanced_mode"},{"parentId":"about-kserve-deployment-modes_serving-large-models","name":"Standard mode","level":2,"index":1,"id":"_standard_mode"},{"parentId":null,"name":"Installing KServe","level":1,"index":3,"id":"installing-kserve_serving-large-models"},{"parentId":null,"name":"Deploying models by using the single-model serving platform","level":1,"index":4,"id":"deploying-models-using-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Enabling the single-model serving platform","level":2,"index":0,"id":"enabling-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a custom model-serving runtime for the single-model serving platform","level":2,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Adding a tested and verified model-serving runtime for the single-model serving platform","level":2,"index":2,"id":"adding-a-tested-and-verified-model-serving-runtime-for-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models on the single-model serving platform","level":2,"index":3,"id":"deploying-models-on-the-single-model-serving-platform_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Deploying models by using multiple GPU nodes","level":2,"index":4,"id":"deploying-models-using-multiple-gpu-nodes_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Setting a timeout for KServe","level":2,"index":5,"id":"setting-timeout-for-kserve_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Customizing the parameters of a deployed model-serving runtime","level":2,"index":6,"id":"customizing-parameters-serving-runtime_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Customizable model serving runtime parameters","level":2,"index":7,"id":"customizable-model-serving-runtime-parameters_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Using accelerators with vLLM","level":2,"index":8,"id":"using-accelerators-with-vllm_serving-large-models"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"NVIDIA GPUs","level":3,"index":0,"id":"_nvidia_gpus"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"Intel Gaudi accelerators","level":3,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":"using-accelerators-with-vllm_serving-large-models","name":"AMD GPUs","level":3,"index":2,"id":"_amd_gpus"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Using OCI containers for model storage","level":2,"index":9,"id":"using-oci-containers-for-model-storage_serving-large-models"},{"parentId":"using-oci-containers-for-model-storage_serving-large-models","name":"Storing a model in an OCI image","level":3,"index":0,"id":"storing-a-model-in-oci-image_serving-large-models"},{"parentId":"using-oci-containers-for-model-storage_serving-large-models","name":"Deploying a model stored in an OCI image by using the CLI","level":3,"index":1,"id":"deploying-model-stored-in-oci-image_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the authentication token for a deployed model","level":2,"index":10,"id":"accessing-authentication-token-for-deployed-model_serving-large-models"},{"parentId":"deploying-models-using-the-single-model-serving-platform_serving-large-models","name":"Accessing the inference endpoint for a deployed model","level":2,"index":11,"id":"accessing-inference-endpoint-for-deployed-model_serving-large-models"},{"parentId":null,"name":"Configuring monitoring for the single-model serving platform","level":1,"index":5,"id":"configuring-monitoring-for-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Viewing model-serving runtime metrics for the single-model serving platform","level":1,"index":6,"id":"viewing-metrics-for-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Monitoring model performance","level":1,"index":7,"id":"_monitoring_model_performance"},{"parentId":"_monitoring_model_performance","name":"Viewing performance metrics for a deployed model","level":2,"index":0,"id":"viewing-performance-metrics-for-deployed-model_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Deploying a Grafana metrics dashboard","level":2,"index":1,"id":"Deploying-a-grafana-metrics-dashboard_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Deploying a vLLM/GPU metrics dashboard on a Grafana instance","level":2,"index":2,"id":"deploying-vllm-gpu-metrics-dashboard-grafana_serving-large-models"},{"parentId":"_monitoring_model_performance","name":"Grafana metrics","level":2,"index":3,"id":"ref-grafana-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"Accelerator metrics","level":3,"index":0,"id":"ref-accelerator-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"CPU metrics","level":3,"index":1,"id":"ref-cpu-metrics_serving-large-models"},{"parentId":"ref-grafana-metrics_serving-large-models","name":"vLLM metrics","level":3,"index":2,"id":"ref-vllm-metrics_serving-large-models"},{"parentId":null,"name":"Optimizing model-serving runtimes","level":1,"index":8,"id":"_optimizing_model_serving_runtimes"},{"parentId":"_optimizing_model_serving_runtimes","name":"Enabling speculative decoding and multi-modal inferencing","level":2,"index":0,"id":"enabling-speculative-decoding-and-multi-modal-inferencing_serving-large-models"},{"parentId":null,"name":"Performance tuning on the single-model serving platform","level":1,"index":9,"id":"_performance_tuning_on_the_single_model_serving_platform"},{"parentId":"_performance_tuning_on_the_single_model_serving_platform","name":"Resolving CUDA out-of-memory errors","level":2,"index":0,"id":"resolving-cuda-oom-errors-for-the-single-model-serving-platform_serving-large-models"},{"parentId":null,"name":"Supported model-serving runtimes","level":1,"index":10,"id":"supported-model-serving-runtimes_serving-large-models"},{"parentId":null,"name":"Tested and verified model-serving runtimes","level":1,"index":11,"id":"tested-verified-runtimes_serving-large-models"},{"parentId":null,"name":"Inference endpoints","level":1,"index":12,"id":"inference-endpoints_serving-large-models"},{"parentId":"inference-endpoints_serving-large-models","name":"Caikit TGIS ServingRuntime for KServe","level":2,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"Caikit Standalone ServingRuntime for KServe","level":2,"index":1,"id":"_caikit_standalone_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"TGIS Standalone ServingRuntime for KServe","level":2,"index":2,"id":"_tgis_standalone_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"OpenVINO Model Server","level":2,"index":3,"id":"_openvino_model_server"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":2,"index":4,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":2,"index":5,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"vLLM AMD GPU ServingRuntime for KServe","level":2,"index":6,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_serving-large-models","name":"NVIDIA Triton Inference Server","level":2,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":"inference-endpoints_serving-large-models","name":"Seldon MLServer","level":2,"index":8,"id":"_seldon_mlserver"},{"parentId":"inference-endpoints_serving-large-models","name":"Additional resources","level":2,"index":9,"id":"_additional_resources"},{"parentId":null,"name":"About the NVIDIA NIM model serving platform","level":1,"index":13,"id":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Enabling the NVIDIA NIM model serving platform","level":2,"index":0,"id":"enabling-the-nvidia-nim-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Deploying models on the NVIDIA NIM model serving platform","level":2,"index":1,"id":"deploying-models-on-the-NVIDIA-NIM-model-serving-platform_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Customizing model selection options for the NVIDIA NIM model serving platform","level":2,"index":2,"id":"Customizing-model-selection-options_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Enabling NVIDIA NIM metrics for an existing NIM deployment","level":2,"index":3,"id":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models","name":"Enabling graph generation for an existing NIM deployment","level":3,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_serving-large-models","name":"Enabling metrics collection for an existing NIM deployment","level":3,"index":1,"id":"_enabling_metrics_collection_for_an_existing_nim_deployment"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Viewing NVIDIA NIM metrics for a NIM model","level":2,"index":4,"id":"viewing-nvidia-nim-metrics-for-a-nim-model_serving-large-models"},{"parentId":"about-the-NVIDIA-NIM-model-serving-platform_serving-large-models","name":"Viewing performance metrics for a NIM model","level":2,"index":5,"id":"viewing-performance-metrics-for-a-nim-model_serving-large-models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/serving-small-and-medium-sized-models/"},"sections":[{"parentId":null,"name":"Configuring model servers","level":1,"index":0,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the multi-model serving platform","level":2,"index":0,"id":"enabling-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime for the multi-model serving platform","level":2,"index":1,"id":"adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a tested and verified model-serving runtime for the multi-model serving platform","level":2,"index":2,"id":"adding-a-tested-and-verified-model-serving-runtime-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Adding a model server for the multi-model serving platform","level":2,"index":3,"id":"adding-a-model-server-for-the-multi-model-serving-platform_model-serving"},{"parentId":"_configuring_model_servers","name":"Deleting a model server","level":2,"index":4,"id":"deleting-a-model-server_model-serving"},{"parentId":null,"name":"Working with deployed models","level":1,"index":1,"id":"_working_with_deployed_models"},{"parentId":"_working_with_deployed_models","name":"Deploying a model by using the multi-model serving platform","level":2,"index":0,"id":"deploying-a-model-using-the-multi-model-serving-platform_model-serving"},{"parentId":"_working_with_deployed_models","name":"Viewing a deployed model","level":2,"index":1,"id":"viewing-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Updating the deployment properties of a deployed model","level":2,"index":2,"id":"updating-the-deployment-properties-of-a-deployed-model_model-serving"},{"parentId":"_working_with_deployed_models","name":"Deleting a deployed model","level":2,"index":3,"id":"deleting-a-deployed-model_model-serving"},{"parentId":null,"name":"Configuring monitoring for the multi-model serving platform","level":1,"index":2,"id":"configuring-monitoring-for-the-multi-model-serving-platform_model-serving"},{"parentId":null,"name":"Viewing model-serving runtime metrics for the multi-model serving platform","level":1,"index":3,"id":"viewing-metrics-for-the-multi-model-serving-platform_model-serving"},{"parentId":null,"name":"Monitoring model performance","level":1,"index":4,"id":"_monitoring_model_performance"},{"parentId":"_monitoring_model_performance","name":"Viewing performance metrics for all models on a model server","level":2,"index":0,"id":"viewing-performance-metrics-for-model-server_model-serving"},{"parentId":"_monitoring_model_performance","name":"Viewing HTTP request metrics for a deployed model","level":2,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_model-serving"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/setting-up-trustyai-for-your-project/"},"sections":[{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":0,"id":"authenticating-trustyai-service_{context}"},{"parentId":null,"name":"Uploading training data to TrustyAI","level":1,"index":1,"id":"uploading-training-data-to-trustyai_{context}"},{"parentId":null,"name":"Sending training data to TrustyAI","level":1,"index":2,"id":"sending-training-data-to-trustyai_{context}"},{"parentId":null,"name":"Labeling data fields","level":1,"index":3,"id":"labeling-data-fields_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v1-to-v2/"},"sections":[{"parentId":null,"name":"Requirements for upgrading {productname-short} version 1","level":1,"index":0,"id":"requirements-for-upgrading-odh-v1_upgradev1"},{"parentId":null,"name":"Upgrading the Open Data Hub Operator version 1","level":1,"index":1,"id":"upgrading-the-odh-operator-v1_upgradev1"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":2,"id":"installing-odh-components_upgradev1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v2/"},"sections":[{"parentId":null,"name":"Requirements for upgrading {productname-short} version 2","level":1,"index":0,"id":"requirements-for-upgrading-odh-v2_upgradev2"},{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":1,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Configuring custom namespaces","level":2,"index":0,"id":"configuring-custom-namespaces"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":2,"id":"installing-odh-components_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-basic-workbenches/"},"sections":[{"parentId":null,"name":"Starting a basic workbench","level":1,"index":0,"id":"starting-a-basic-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-connections/"},"sections":[{"parentId":null,"name":"Adding a connection to your data science project","level":1,"index":0,"id":"adding-a-connection-to-your-data-science-project_{context}"},{"parentId":null,"name":"Updating a connection","level":1,"index":1,"id":"updating-a-connection_{context}"},{"parentId":null,"name":"Deleting a connection","level":1,"index":2,"id":"deleting-a-connection_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-data-science-projects/"},"sections":[{"parentId":null,"name":"Creating a data science project","level":1,"index":0,"id":"creating-a-data-science-project_{context}"},{"parentId":null,"name":"Updating a data science project","level":1,"index":1,"id":"updating-a-data-science-project_{context}"},{"parentId":null,"name":"Deleting a data science project","level":1,"index":2,"id":"deleting-a-data-science-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-explainability/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation","level":1,"index":0,"id":"requesting-a-lime-explanation_explainers"},{"parentId":"requesting-a-lime-explanation_explainers","name":"Requesting a LIME explanation by using the CLI","level":2,"index":0,"id":"requesting-a-lime-explanation-using-CLI_explainers"},{"parentId":null,"name":"Requesting a SHAP explanation","level":1,"index":1,"id":"requesting-a-shap-explanation_explainers"},{"parentId":"requesting-a-shap-explanation_explainers","name":"Requesting a SHAP explanation by using the CLI","level":2,"index":0,"id":"requesting-a-shap-explanation-using-CLI_explainers"},{"parentId":null,"name":"Using explainers","level":1,"index":2,"id":"using-explainers_explainers"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-lab-tuning/"},"sections":[{"parentId":null,"name":"Registering a base model","level":1,"index":0,"id":"registering-a-base-model_{context}"},{"parentId":null,"name":"Starting a LAB-tuning run from the registered model","level":1,"index":1,"id":"starting-a-lab-tuning-run-from-the-registered-model_{context}"},{"parentId":null,"name":"Monitoring your LAB-tuning run","level":1,"index":2,"id":"monitoring-your-lab-tuning-run_{context}"},{"parentId":null,"name":"Reviewing and deploying your LAB-tuned model","level":1,"index":3,"id":"reviewing-and-deploying-your-lab-tuned-model_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-project-workbenches/"},"sections":[{"parentId":null,"name":"Creating a workbench and selecting an IDE","level":1,"index":0,"id":"creating-a-workbench-select-ide_{context}"},{"parentId":"creating-a-workbench-select-ide_{context}","name":"About workbench images","level":2,"index":0,"id":"about-workbench-images_{context}"},{"parentId":"creating-a-workbench-select-ide_{context}","name":"Creating a workbench","level":2,"index":1,"id":"creating-a-project-workbench_{context}"},{"parentId":null,"name":"Starting a workbench","level":1,"index":1,"id":"starting-a-workbench_{context}"},{"parentId":null,"name":"Updating a project workbench","level":1,"index":2,"id":"updating-a-project-workbench_{context}"},{"parentId":null,"name":"Deleting a workbench from a data science project","level":1,"index":3,"id":"deleting-a-workbench-from-a-data-science-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-the-kfto-sdk-to-run-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Configuring a training job by using the Training Operator SDK","level":1,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":null,"name":"Running a training job by using the Training Operator SDK","level":1,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":null,"name":"TrainingClient API: Job-related methods","level":1,"index":2,"id":"ref-trainingclient-api-job-related-methods_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-the-kubeflow-training-operator-to-run-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":1,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_{context}"},{"parentId":null,"name":"Creating a Training Operator PyTorchJob resource","level":1,"index":1,"id":"creating-a-kfto-pytorchjob-resource_{context}"},{"parentId":null,"name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":1,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training scripts","level":1,"index":3,"id":"example-kfto-pytorch-training-scripts_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: NCCL","level":2,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: DDP","level":2,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: FSDP","level":2,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"},{"parentId":null,"name":"Example Dockerfile for a Training Operator PyTorch training script","level":1,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_{context}"},{"parentId":null,"name":"Example Training Operator PyTorchJob resource for multi-node training","level":1,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/viewing-logs-and-audit-records/"},"sections":[{"parentId":null,"name":"Configuring the {productname-short} Operator logger","level":1,"index":0,"id":"configuring-the-operator-logger_{context}"},{"parentId":"configuring-the-operator-logger_{context}","name":"Viewing the {productname-short} Operator logs","level":2,"index":0,"id":"_viewing_the_productname_short_operator_logs"},{"parentId":null,"name":"Viewing audit records","level":1,"index":1,"id":"viewing-audit-records_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-certificates/"},"sections":[{"parentId":null,"name":"Understanding how {productname-short} handles certificates","level":1,"index":0,"id":"understanding-certificates_certs"},{"parentId":null,"name":"Adding certificates","level":1,"index":1,"id":"_adding_certificates"},{"parentId":null,"name":"Adding certificates to a cluster-wide CA bundle","level":1,"index":2,"id":"adding-certificates-to-a-cluster-ca-bundle_certs"},{"parentId":null,"name":"Adding certificates to a custom CA bundle","level":1,"index":3,"id":"adding-certificates-to-a-custom-ca-bundle_certs"},{"parentId":null,"name":"Using self-signed certificates with {productname-short} components","level":1,"index":4,"id":"_using_self_signed_certificates_with_productname_short_components"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Accessing S3-compatible object storage with self-signed certificates","level":2,"index":0,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Configuring a certificate for data science pipelines","level":2,"index":1,"id":"configuring-a-certificate-for-pipelines_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Configuring a certificate for workbenches","level":2,"index":2,"id":"configuring-a-certificate-for-workbenches_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Using the cluster-wide CA bundle for the single-model serving platform","level":2,"index":3,"id":"using-the-cluster-CA-bundle-for-single-model-serving_certs"},{"parentId":null,"name":"Managing certificates without the {productname-long} Operator","level":1,"index":5,"id":"managing-certificates-without-the-operator_certs"},{"parentId":null,"name":"Removing the CA bundle","level":1,"index":6,"id":"_removing_the_ca_bundle"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from all namespaces","level":2,"index":0,"id":"removing-the-ca-bundle-from-all-namespaces_certs"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from a single namespace","level":2,"index":1,"id":"removing-the-ca-bundle-from-a-single-namespace_certs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-data-in-s3-compatible-object-store/"},"sections":[{"parentId":null,"name":"Prerequisites","level":1,"index":0,"id":"s3-prerequisites_s3"},{"parentId":null,"name":"Creating an S3 client","level":1,"index":1,"id":"creating-an-s3-client_s3"},{"parentId":null,"name":"Listing available buckets in your object store","level":1,"index":2,"id":"listing-available-amazon-buckets_s3"},{"parentId":null,"name":"Creating a bucket in your object store","level":1,"index":3,"id":"creating-an-s3-bucket_s3"},{"parentId":null,"name":"Listing files in your bucket","level":1,"index":4,"id":"listing-files-in-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Downloading files from your bucket","level":1,"index":5,"id":"downloading-files-from-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Uploading files to your bucket","level":1,"index":6,"id":"uploading-files-to-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Copying files between buckets","level":1,"index":7,"id":"copying-files-to-between-buckets_s3"},{"parentId":null,"name":"Deleting files from your bucket","level":1,"index":8,"id":"Deleting-files-on-your-object-store_s3"},{"parentId":null,"name":"Deleting a bucket from your object store","level":1,"index":9,"id":"deleting-a-s3-bucket_s3"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":10,"id":"overview-of-object-storage-endpoints_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Accessing S3-compatible object storage with self-signed certificates","level":1,"index":11,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_s3"},{"parentId":null,"name":"Additional resources","level":0,"index":12,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-model-registries/"},"sections":[{"parentId":null,"name":"Registering a model","level":1,"index":0,"id":"registering-a-model_model-registry"},{"parentId":null,"name":"Registering a model from the model catalog","level":1,"index":1,"id":"registering-a-model-from-the-model-catalog_model-registry"},{"parentId":null,"name":"Registering a model version","level":1,"index":2,"id":"registering-a-model-version_model-registry"},{"parentId":null,"name":"Viewing registered models","level":1,"index":3,"id":"viewing-registered-models_model-registry"},{"parentId":null,"name":"Viewing registered model versions","level":1,"index":4,"id":"viewing-registered-model-versions_model-registry"},{"parentId":null,"name":"Editing model metadata in a model registry","level":1,"index":5,"id":"editing-model-metadata-in-a-model-registry_model-registry"},{"parentId":null,"name":"Editing model version metadata in a model registry","level":1,"index":6,"id":"editing-model-version-metadata-in-a-model-registry_model-registry"},{"parentId":null,"name":"Deploying a model version from a model registry","level":1,"index":7,"id":"deploying-a-model-version-from-a-model-registry_model-registry"},{"parentId":null,"name":"Deploying a model from the model catalog","level":1,"index":8,"id":"deploying-a-model-from-the-model-catalog_model-registry"},{"parentId":null,"name":"Editing the deployment properties of a deployed model version from a model registry","level":1,"index":9,"id":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the multi-model serving platform","level":2,"index":0,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-multi-model-serving-platform_model-registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the single-model serving platform","level":2,"index":1,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-single-model-serving-platform_model-registry"},{"parentId":null,"name":"Deleting a deployed model version from a model registry","level":1,"index":10,"id":"deleting-a-deployed-model-version-from-a-model-registry_model-registry"},{"parentId":null,"name":"Archiving a model","level":1,"index":11,"id":"archiving-a-model_model-registry"},{"parentId":null,"name":"Archiving a model version","level":1,"index":12,"id":"archiving-a-model-version_model-registry"},{"parentId":null,"name":"Restoring a model","level":1,"index":13,"id":"restoring-a-model_model-registry"},{"parentId":null,"name":"Restoring a model version","level":1,"index":14,"id":"restoring-a-model-version_model-registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-pipeline-logs/"},"sections":[{"parentId":null,"name":"About pipeline logs","level":1,"index":0,"id":"about-pipeline-logs_{context}"},{"parentId":null,"name":"Viewing pipeline step logs","level":1,"index":1,"id":"viewing-pipeline-step-logs_{context}"},{"parentId":null,"name":"Downloading pipeline step logs","level":1,"index":2,"id":"downloading-pipeline-step-logs_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-pipelines-in-jupyterlab/"},"sections":[{"parentId":null,"name":"Overview of pipelines in JupyterLab","level":1,"index":0,"id":"overview-of-pipelines-in-jupyterlab_{context}"},{"parentId":null,"name":"Accessing the pipeline editor","level":1,"index":1,"id":"accessing-the-pipeline-editor_{context}"},{"parentId":null,"name":"Creating a runtime configuration","level":1,"index":2,"id":"creating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Updating a runtime configuration","level":1,"index":3,"id":"updating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Deleting a runtime configuration","level":1,"index":4,"id":"deleting-a-runtime-configuration_{context}"},{"parentId":null,"name":"Duplicating a runtime configuration","level":1,"index":5,"id":"duplicating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Running a pipeline in JupyterLab","level":1,"index":6,"id":"running-a-pipeline-in-jupyterlab_{context}"},{"parentId":null,"name":"Exporting a pipeline in JupyterLab","level":1,"index":7,"id":"exporting-a-pipeline-in-jupyterlab_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-base-training-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-kserve-deployment-modes/"},"sections":[{"parentId":null,"name":"Advanced mode","level":1,"index":0,"id":"_advanced_mode"},{"parentId":null,"name":"Standard mode","level":1,"index":1,"id":"_standard_mode"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-llama-stack-search-types/"},"sections":[{"parentId":null,"name":"Supported search modes","level":1,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":2,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":2,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":2,"index":2,"id":"_hybrid_search"},{"parentId":null,"name":"Retrieval database support","level":1,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-model-serving/"},"sections":[{"parentId":null,"name":"Single-model serving platform","level":1,"index":0,"id":"_single_model_serving_platform"},{"parentId":null,"name":"Multi-model serving platform","level":1,"index":1,"id":"_multi_model_serving_platform"},{"parentId":null,"name":"NVIDIA NIM model serving platform","level":1,"index":2,"id":"_nvidia_nim_model_serving_platform"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-persistent-storage/"},"sections":[{"parentId":null,"name":"Storage classes in {productname-short}","level":1,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":null,"name":"Access modes","level":1,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":2,"index":0,"id":"_using_shared_storage_rwx"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-pipeline-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-authentication-token-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-hugging-face-models-with-an-environment-variable-token/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-inference-endpoint-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-s3-compatible-object-storage-with-self-signed-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-administration-interface-for-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-odh-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-your-workbench-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/activating-the-llama-stack-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-connection-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-model-server-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-tested-and-verified-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-tested-and-verified-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-application-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-certificates-to-a-cluster-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-certificates-to-a-custom-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-cluster-storage-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-users-to-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-workbench-pod-tolerations/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/allocating-additional-resources-to-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/amd-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-custom-image-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-workbench-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-workbench-overview/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/backing-up-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/before-you-begin/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/changing-the-storage-class-for-an-existing-cluster-storage-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/comparing-runs-in-an-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/comparing-runs-in-different-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-certificate-for-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-certificate-for-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-cluster-for-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-pipeline-server-with-an-external-amazon-rds-db/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-storage-class-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-an-offline-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-an-online-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-custom-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-your-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-quota-management-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-role-based-access-control/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-storage-class-settings/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-codeflare-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-default-storage-class-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-feature-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-guardrails-detector-hugging-face-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-opentelemetry-exporter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-operator-logger/"},"sections":[{"parentId":null,"name":"Viewing the {productname-short} Operator logs","level":1,"index":0,"id":"_viewing_the_productname_short_operator_logs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-trustyai-with-a-database/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/controlling-caching-in-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Disabling caching for individual tasks","level":1,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":null,"name":"Disabling caching for a pipeline at submit time","level":1,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":null,"name":"Disabling caching for a pipeline at compile time","level":1,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":null,"name":"Disabling caching for all pipelines (pipeline server)","level":1,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/copying-files-between-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-image-from-default-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-image-from-your-own-image/"},"sections":[{"parentId":null,"name":"Basic guidelines for creating your own workbench image","level":1,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Advanced guidelines for creating your own workbench image","level":1,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-training-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-drift-metric/"},"sections":[{"parentId":null,"name":"Creating a drift metric by using the CLI","level":1,"index":0,"id":"creating-a-drift-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-hardware-profile-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorch-training-script-configmap-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorchjob-resource-by-using-the-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorchjob-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-project-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-taxonomy/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-workbench-for-distributed-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-workbench-select-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-an-s3-client/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-project-scoped-resources-for-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-project-scoped-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizable-model-serving-runtime-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-component-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-model-selection-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-parameters-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-a-pipeline-by-using-the-kubernetes-api/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-deployed-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-workbench-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-cluster-storage-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-feature-store-instance-in-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-grafana-metrics-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-llama-model-with-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-llamastackdistribution-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-model-stored-in-oci-image-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-single-node-openshift-using-kserve-raw-deployment-mode/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-multiple-gpu-nodes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-teacher-and-judge-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-the-guardrails-orchestrator-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-vllm-gpu-metrics-dashboard-grafana/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-a-data-science-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-files-from-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-an-existing-feature-store-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-model-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-model-version-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-dashboard-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-amd-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-custom-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-intel-gaudi-ai-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-metrics-for-existing-nim-deployment/"},"sections":[{"parentId":null,"name":"Enabling graph generation for an existing NIM deployment","level":1,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"},{"parentId":null,"name":"Enabling metrics collection for an existing NIM deployment","level":1,"index":1,"id":"_enabling_metrics_collection_for_an_existing_nim_deployment"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-nvidia-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-feature-store-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-model-registry-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-nvidia-nim-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-kserve-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enforcing-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enforcing-lqlabel-some/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/executing-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/glossary-of-common-terms/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-configuring-regex-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-hap-scenario/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-querying-using-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/hiding-the-default-basic-workbench-application/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-regex-using/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/importing-a-custom-workbench-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/importing-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ingesting-content-into-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-extensions-with-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-model-registry-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-python-packages-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-multi-node-pytorch-training-job-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-python-packages-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-distributed-workloads-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-required-components-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-required-operators-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service/"},"sections":[{"parentId":null,"name":"Installing the TrustyAI service by using the dashboard","level":1,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Installing the TrustyAI service by using the CLI","level":1,"index":1,"id":"installing-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/intel-gaudi-ai-accelerator-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/listing-available-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/listing-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/lmeval-evaluation-job-properties/"},"sections":[{"parentId":null,"name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":1,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/lmeval-evaluation-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/logging-in/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/making-inference-requests-to-models-deployed-on-single-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-certificates-without-the-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/making-lab-tuning-and-hardware-profiles-features-visible/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-model-registry-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-ray-clusters-from-within-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/migrating-to-data-science-pipelines-2/"},"sections":[{"parentId":null,"name":"Upgrading to data science pipelines 2.0","level":1,"index":0,"id":"_upgrading_to_data_science_pipelines_2_0"},{"parentId":null,"name":"Removing data science pipelines 1.0 resources","level":1,"index":1,"id":"_removing_data_science_pipelines_1_0_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/model-serving-runtimes/"},"sections":[{"parentId":null,"name":"ServingRuntime","level":1,"index":0,"id":"_servingruntime"},{"parentId":null,"name":"InferenceService","level":1,"index":1,"id":"_inferenceservice"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/monitoring-your-lab-tuning-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/next-steps-getting-started/"},"sections":[{"parentId":null,"name":"Additional resources","level":1,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/nvidia-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/optimizing-the-vllm-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-for-getting-started/"},"sections":[{"parentId":null,"name":"Data science workflow","level":1,"index":0,"id":"_data_science_workflow"},{"parentId":null,"name":"About this guide","level":1,"index":1,"id":"_about_this_guide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-data-science-pipelines-caching/"},"sections":[{"parentId":null,"name":"Caching criteria","level":1,"index":0,"id":"_caching_criteria"},{"parentId":null,"name":"Viewing cached steps in the {productname-short} user interface","level":1,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-distributed-workloads/"},"sections":[{"parentId":null,"name":"Distributed workloads infrastructure","level":1,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":null,"name":"Types of distributed workloads","level":1,"index":1,"id":"_types_of_distributed_workloads"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-enabling-lab-tuning/"},"sections":[{"parentId":null,"name":"Requirements for LAB-tuning","level":1,"index":0,"id":"_requirements_for_lab_tuning"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-features-and-feature-store/"},"sections":[{"parentId":null,"name":"Overview of machine learning features","level":1,"index":0,"id":"_overview_of_machine_learning_features"},{"parentId":null,"name":"Overview of Feature Store","level":1,"index":1,"id":"_overview_of_feature_store"},{"parentId":null,"name":"Audience for Feature Store","level":1,"index":2,"id":"_audience_for_feature_store"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-kueue-resources/"},"sections":[{"parentId":null,"name":"Resource flavor","level":1,"index":0,"id":"_resource_flavor"},{"parentId":null,"name":"Cluster queue","level":1,"index":1,"id":"_cluster_queue"},{"parentId":null,"name":"Local queue","level":1,"index":2,"id":"_local_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-lab-tuning/"},"sections":[{"parentId":null,"name":"LAB-tuning workflow","level":1,"index":0,"id":"_lab_tuning_workflow"},{"parentId":null,"name":"Model customization page","level":1,"index":1,"id":"_model_customization_page"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-model-monitoring/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-model-registries/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-object-storage-endpoints/"},"sections":[{"parentId":null,"name":"MinIO (On-Cluster)","level":1,"index":0,"id":"_minio_on_cluster"},{"parentId":null,"name":"Amazon S3","level":1,"index":1,"id":"_amazon_s3"},{"parentId":null,"name":"Other S3-Compatible Object Stores","level":1,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":null,"name":"Verification and Troubleshooting","level":1,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-rag/"},"sections":[{"parentId":null,"name":"Audience for RAG","level":1,"index":0,"id":"_audience_for_rag"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preparing-a-storage-location-for-the-lab-tuned-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preparing-documents-with-docling-for-llama-stack-retrieval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preventing-users-from-adding-applications-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-an-image-to-the-integrated-openshift-image-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-project-changes-in-code-server-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/querying-ingested-content-in-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/reenabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-accelerator-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-cpu-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-dashboard-configuration-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-default-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-dockerfile-for-a-kfto-pytorch-training-script/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-ddp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-fsdp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-nccl/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorchjob-resource-for-multi-node-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kubernetes-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kueue-resource-configurations/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs without shared cohort","level":1,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":2,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":2,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":2,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":2,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":null,"name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":1,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":2,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":2,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":2,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":2,"index":3,"id":"_nvidia_gpu_cluster_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-oidc-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-pvc-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-grafana-metrics/"},"sections":[{"parentId":null,"name":"Accelerator metrics","level":1,"index":0,"id":"ref-accelerator-metrics_{context}"},{"parentId":null,"name":"CPU metrics","level":1,"index":1,"id":"ref-cpu-metrics_{context}"},{"parentId":null,"name":"vLLM metrics","level":1,"index":2,"id":"ref-vllm-metrics_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-inference-endpoints/"},"sections":[{"parentId":null,"name":"Caikit TGIS ServingRuntime for KServe","level":1,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":null,"name":"Caikit Standalone ServingRuntime for KServe","level":1,"index":1,"id":"_caikit_standalone_servingruntime_for_kserve"},{"parentId":null,"name":"TGIS Standalone ServingRuntime for KServe","level":1,"index":2,"id":"_tgis_standalone_servingruntime_for_kserve"},{"parentId":null,"name":"OpenVINO Model Server","level":1,"index":3,"id":"_openvino_model_server"},{"parentId":null,"name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":1,"index":4,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":1,"index":5,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM AMD GPU ServingRuntime for KServe","level":1,"index":6,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"NVIDIA Triton Inference Server","level":1,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":null,"name":"Seldon MLServer","level":1,"index":8,"id":"_seldon_mlserver"},{"parentId":null,"name":"Additional resources","level":1,"index":9,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-supported-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-tested-verified-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-trainingclient-api-job-related-methods/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-vllm-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-base-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-disabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-the-ca-bundle-from-a-single-namespace/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-the-ca-bundle-from-all-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-lime-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-lime-explanation/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation by using the CLI","level":1,"index":0,"id":"requesting-a-lime-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-shap-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-shap-explanation/"},"sections":[{"parentId":null,"name":"Requesting a SHAP explanation by using the CLI","level":1,"index":0,"id":"requesting-a-shap-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requirements-for-upgrading-odh-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requirements-for-upgrading-odh-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/resolving-cuda-oom-errors/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/reviewing-and-deploying-your-lab-tuned-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/revoking-user-access-to-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-ds-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-jupyter-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/s3-prerequisites/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run-using-a-cron-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/selecting-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sending-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-lmeval-s3-support/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-timeout-for-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sharing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/showing-hiding-information-about-available-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/specifying-to-use-a-feature-project-from-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-basic-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-lab-tuning-run-from-the-registered-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-idle-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/storing-a-model-in-oci-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/storing-data-with-data-science-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-checking-model-fairness/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-deploying-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-introduction/"},"sections":[{"parentId":null,"name":"About the example models","level":1,"index":0,"id":"_about_the_example_models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-reviewing-the-results/"},"sections":[{"parentId":null,"name":"Are the models biased?","level":1,"index":0,"id":"_are_the_models_biased"},{"parentId":null,"name":"How does the production data compare to the training data?","level":1,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-scheduling-a-fairness-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-scheduling-an-identity-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-sending-training-data-to-the-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-setting-up-your-environment/"},"sections":[{"parentId":null,"name":"Downloading the tutorial files","level":1,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":null,"name":"Logging in to the OpenShift cluster from the command line","level":1,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":null,"name":"Configuring monitoring for the model serving platform","level":1,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":3,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Setting up a project","level":1,"index":4,"id":"_setting_up_a_project"},{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":5,"id":"_authenticating_the_trustyai_service"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-simulating-real-world-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/testing-your-vllm-model-endpoints/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-workbenches-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s workbench does not start","level":1,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-workbenches-for-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-with-distributed-workloads-for-administrators/"},"sections":[{"parentId":null,"name":"A user&#8217;s Ray cluster is in a suspended state","level":1,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"A user&#8217;s Ray cluster is in a failed state","level":1,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for the CodeFlare Operator","level":1,"index":2,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for Kueue","level":1,"index":3,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"A user&#8217;s Ray cluster does not start","level":1,"index":4,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":null,"name":"A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message","level":1,"index":5,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"A user receives a <strong>local_queue provided does not exist</strong> error message","level":1,"index":6,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"A user cannot create a Ray cluster or submit jobs","level":1,"index":7,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled","level":1,"index":8,"id":"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-with-distributed-workloads-for-users/"},"sections":[{"parentId":null,"name":"My Ray cluster is in a suspended state","level":1,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"My Ray cluster is in a failed state","level":1,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for the CodeFlare Operator","level":1,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for Kueue","level":1,"index":3,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"My Ray cluster does not start","level":1,"index":4,"id":"_my_ray_cluster_does_not_start"},{"parentId":null,"name":"I see a \"Default Local Queue not found\" error message","level":1,"index":5,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"I see a \"local_queue provided does not exist\" error message","level":1,"index":6,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"I cannot create a Ray cluster or submit jobs","level":1,"index":7,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"My pod provisioned by Kueue is terminated before my image is pulled","level":1,"index":8,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-workbench-settings-by-restarting-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-project-in-code-server-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/upgrading-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-code-server-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-files-to-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-custom-unitxt-card/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-hugging-face-prompt-injection-detector-with-the-guardrails-orchestrator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-kserve-inference-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-accelerators-with-vllm/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs","level":1,"index":0,"id":"_nvidia_gpus"},{"parentId":null,"name":"Intel Gaudi accelerators","level":1,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":null,"name":"AMD GPUs","level":1,"index":2,"id":"_amd_gpus"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-explainers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-hugging-face-models-with-guardrails-orchestrator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-oci-containers-for-model-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-llm-as-a-judge-metrics-with-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-pvcs-as-storage/"},"sections":[{"parentId":null,"name":"Managed PVCs","level":1,"index":0,"id":"_managed_pvcs"},{"parentId":null,"name":"Existing PVCs","level":1,"index":1,"id":"_existing_pvcs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-the-cluster-CA-bundle-for-single-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/verifying-amd-gpu-availability-on-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-the-cluster-server-and-token-to-authenticate/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-active-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-archived-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-audit-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-connected-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-connection-types/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-feature-store-objects-in-the-web-based-ui/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-installed-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-kueue-alerts-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-metrics-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-metrics-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-nvidia-nim-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-artifacts/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-task-executions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-project-metrics-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-python-packages-installed-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-registered-model-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-python-packages-installed-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-registered-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-status-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/working-with-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/working-with-hardware-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-base-training-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-kserve-deployment-modes/"},"sections":[{"parentId":null,"name":"Advanced mode","level":1,"index":0,"id":"_advanced_mode"},{"parentId":null,"name":"Standard mode","level":1,"index":1,"id":"_standard_mode"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-model-serving/"},"sections":[{"parentId":null,"name":"Single-model serving platform","level":1,"index":0,"id":"_single_model_serving_platform"},{"parentId":null,"name":"Multi-model serving platform","level":1,"index":1,"id":"_multi_model_serving_platform"},{"parentId":null,"name":"NVIDIA NIM model serving platform","level":1,"index":2,"id":"_nvidia_nim_model_serving_platform"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-llama-stack-search-types/"},"sections":[{"parentId":null,"name":"Supported search modes","level":1,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":2,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":2,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":2,"index":2,"id":"_hybrid_search"},{"parentId":null,"name":"Retrieval database support","level":1,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-persistent-storage/"},"sections":[{"parentId":null,"name":"Storage classes in {productname-short}","level":1,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":null,"name":"Access modes","level":1,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":2,"index":0,"id":"_using_shared_storage_rwx"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-pipeline-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-authentication-token-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-hugging-face-models-with-an-environment-variable-token/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-inference-endpoint-for-model-deployed-on-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-s3-compatible-object-storage-with-self-signed-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-administration-interface-for-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-odh-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-your-workbench-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/activating-the-llama-stack-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-connection-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-tested-and-verified-runtime-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-model-server-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-application-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-tested-and-verified-runtime-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-certificates-to-a-cluster-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-cluster-storage-to-your-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-certificates-to-a-custom-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-users-to-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/allocating-additional-resources-to-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-workbench-pod-tolerations/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/amd-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-workbench-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-custom-image-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-workbench-overview/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/backing-up-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/before-you-begin/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/changing-the-storage-class-for-an-existing-cluster-storage-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/comparing-runs-in-an-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/comparing-runs-in-different-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-certificate-for-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-certificate-for-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-cluster-for-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-pipeline-server-with-an-external-amazon-rds-db/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-storage-class-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-an-offline-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-an-online-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-custom-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-quota-management-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-your-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-role-based-access-control/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-storage-class-settings/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-codeflare-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-default-storage-class-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/understanding-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-dspa-component-errors/"},"sections":[{"parentId":null,"name":"Common errors across DSP components","level":1,"index":0,"id":"_common_errors_across_dsp_components"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-feature-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-guardrails-detector-hugging-face-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-opentelemetry-exporter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-operator-logger/"},"sections":[{"parentId":null,"name":"Viewing the {productname-short} Operator logs","level":1,"index":0,"id":"_viewing_the_productname_short_operator_logs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-trustyai-with-a-database/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/controlling-caching-in-data-science-pipelines/"},"sections":[{"parentId":null,"name":"Disabling caching for individual tasks","level":1,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":null,"name":"Disabling caching for a pipeline at submit time","level":1,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":null,"name":"Disabling caching for a pipeline at compile time","level":1,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":null,"name":"Disabling caching for all pipelines (pipeline server)","level":1,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/copying-files-between-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-image-from-default-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-image-from-your-own-image/"},"sections":[{"parentId":null,"name":"Basic guidelines for creating your own workbench image","level":1,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Advanced guidelines for creating your own workbench image","level":1,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-training-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-drift-metric/"},"sections":[{"parentId":null,"name":"Creating a drift metric by using the CLI","level":1,"index":0,"id":"creating-a-drift-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-hardware-profile-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorch-training-script-configmap-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorchjob-resource-by-using-the-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorchjob-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-model-registry-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-multi-node-pytorch-training-job-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-project-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-taxonomy/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-workbench-for-distributed-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-workbench-select-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-an-s3-client/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-project-scoped-resources-for-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-project-scoped-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizable-model-serving-runtime-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-component-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-model-selection-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-parameters-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-a-pipeline-by-using-the-kubernetes-api/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-deployed-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-workbench-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-cluster-storage-from-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-feature-store-instance-in-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-grafana-metrics-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-llama-model-with-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-llamastackdistribution-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-model-stored-in-oci-image-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-single-node-openshift-using-kserve-raw-deployment-mode/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-multiple-gpu-nodes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-teacher-and-judge-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-vllm-gpu-metrics-dashboard-grafana/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-the-guardrails-orchestrator-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-a-data-science-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-files-from-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-an-existing-feature-store-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-model-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-model-version-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-dashboard-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-amd-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-custom-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-intel-gaudi-ai-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-metrics-for-existing-nim-deployment/"},"sections":[{"parentId":null,"name":"Enabling graph generation for an existing NIM deployment","level":1,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"},{"parentId":null,"name":"Enabling metrics collection for an existing NIM deployment","level":1,"index":1,"id":"_enabling_metrics_collection_for_an_existing_nim_deployment"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-nvidia-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-feature-store-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-model-registry-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-nvidia-nim-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-kserve-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enforcing-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enforcing-lqlabel-some/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/executing-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/glossary-of-common-terms/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-configuring-regex-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-hap-scenario/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-querying-using-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/hiding-the-default-basic-workbench-application/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-regex-using/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/importing-a-custom-workbench-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ingesting-content-into-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/importing-a-data-science-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-extensions-with-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-python-packages-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-required-components-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-required-operators-for-lab-tuning/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service/"},"sections":[{"parentId":null,"name":"Installing the TrustyAI service by using the dashboard","level":1,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Installing the TrustyAI service by using the CLI","level":1,"index":1,"id":"installing-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/intel-gaudi-ai-accelerator-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/listing-available-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/listing-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/lmeval-evaluation-job-properties/"},"sections":[{"parentId":null,"name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":1,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/lmeval-evaluation-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/logging-in/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/making-inference-requests-to-models-deployed-on-single-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-certificates-without-the-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/making-lab-tuning-and-hardware-profiles-features-visible/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-model-registry-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/migrating-to-data-science-pipelines-2/"},"sections":[{"parentId":null,"name":"Upgrading to data science pipelines 2.0","level":1,"index":0,"id":"_upgrading_to_data_science_pipelines_2_0"},{"parentId":null,"name":"Removing data science pipelines 1.0 resources","level":1,"index":1,"id":"_removing_data_science_pipelines_1_0_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/model-serving-runtimes/"},"sections":[{"parentId":null,"name":"ServingRuntime","level":1,"index":0,"id":"_servingruntime"},{"parentId":null,"name":"InferenceService","level":1,"index":1,"id":"_inferenceservice"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/monitoring-your-lab-tuning-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-ray-clusters-from-within-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/next-steps-getting-started/"},"sections":[{"parentId":null,"name":"Additional resources","level":1,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-distributed-workloads-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-python-packages-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/nvidia-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/optimizing-the-vllm-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-for-getting-started/"},"sections":[{"parentId":null,"name":"Data science workflow","level":1,"index":0,"id":"_data_science_workflow"},{"parentId":null,"name":"About this guide","level":1,"index":1,"id":"_about_this_guide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-data-science-pipelines-caching/"},"sections":[{"parentId":null,"name":"Caching criteria","level":1,"index":0,"id":"_caching_criteria"},{"parentId":null,"name":"Viewing cached steps in the {productname-short} user interface","level":1,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-distributed-workloads/"},"sections":[{"parentId":null,"name":"Distributed workloads infrastructure","level":1,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":null,"name":"Types of distributed workloads","level":1,"index":1,"id":"_types_of_distributed_workloads"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-enabling-lab-tuning/"},"sections":[{"parentId":null,"name":"Requirements for LAB-tuning","level":1,"index":0,"id":"_requirements_for_lab_tuning"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-features-and-feature-store/"},"sections":[{"parentId":null,"name":"Overview of machine learning features","level":1,"index":0,"id":"_overview_of_machine_learning_features"},{"parentId":null,"name":"Overview of Feature Store","level":1,"index":1,"id":"_overview_of_feature_store"},{"parentId":null,"name":"Audience for Feature Store","level":1,"index":2,"id":"_audience_for_feature_store"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-kueue-resources/"},"sections":[{"parentId":null,"name":"Resource flavor","level":1,"index":0,"id":"_resource_flavor"},{"parentId":null,"name":"Cluster queue","level":1,"index":1,"id":"_cluster_queue"},{"parentId":null,"name":"Local queue","level":1,"index":2,"id":"_local_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-lab-tuning/"},"sections":[{"parentId":null,"name":"LAB-tuning workflow","level":1,"index":0,"id":"_lab_tuning_workflow"},{"parentId":null,"name":"Model customization page","level":1,"index":1,"id":"_model_customization_page"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-model-monitoring/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-model-registries/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-object-storage-endpoints/"},"sections":[{"parentId":null,"name":"MinIO (On-Cluster)","level":1,"index":0,"id":"_minio_on_cluster"},{"parentId":null,"name":"Amazon S3","level":1,"index":1,"id":"_amazon_s3"},{"parentId":null,"name":"Other S3-Compatible Object Stores","level":1,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":null,"name":"Verification and Troubleshooting","level":1,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-rag/"},"sections":[{"parentId":null,"name":"Audience for RAG","level":1,"index":0,"id":"_audience_for_rag"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preparing-a-storage-location-for-the-lab-tuned-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preparing-documents-with-docling-for-llama-stack-retrieval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preventing-users-from-adding-applications-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-an-image-to-the-integrated-openshift-image-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-project-changes-in-code-server-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/querying-ingested-content-in-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/reenabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-accelerator-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-cpu-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-dashboard-configuration-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-default-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-dockerfile-for-a-kfto-pytorch-training-script/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-fsdp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-nccl/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-ddp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorchjob-resource-for-multi-node-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kueue-resource-configurations/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs without shared cohort","level":1,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":2,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":2,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":2,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":2,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":null,"name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":1,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":2,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":2,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":2,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":2,"index":3,"id":"_nvidia_gpu_cluster_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-oidc-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kubernetes-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-pvc-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-grafana-metrics/"},"sections":[{"parentId":null,"name":"Accelerator metrics","level":1,"index":0,"id":"ref-accelerator-metrics_{context}"},{"parentId":null,"name":"CPU metrics","level":1,"index":1,"id":"ref-cpu-metrics_{context}"},{"parentId":null,"name":"vLLM metrics","level":1,"index":2,"id":"ref-vllm-metrics_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-inference-endpoints/"},"sections":[{"parentId":null,"name":"Caikit TGIS ServingRuntime for KServe","level":1,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":null,"name":"Caikit Standalone ServingRuntime for KServe","level":1,"index":1,"id":"_caikit_standalone_servingruntime_for_kserve"},{"parentId":null,"name":"TGIS Standalone ServingRuntime for KServe","level":1,"index":2,"id":"_tgis_standalone_servingruntime_for_kserve"},{"parentId":null,"name":"OpenVINO Model Server","level":1,"index":3,"id":"_openvino_model_server"},{"parentId":null,"name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":1,"index":4,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":1,"index":5,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM AMD GPU ServingRuntime for KServe","level":1,"index":6,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"NVIDIA Triton Inference Server","level":1,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":null,"name":"Seldon MLServer","level":1,"index":8,"id":"_seldon_mlserver"},{"parentId":null,"name":"Additional resources","level":1,"index":9,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-supported-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-tested-verified-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-vllm-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-base-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-trainingclient-api-job-related-methods/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-disabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-the-ca-bundle-from-a-single-namespace/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-the-ca-bundle-from-all-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-lime-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-lime-explanation/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation by using the CLI","level":1,"index":0,"id":"requesting-a-lime-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-shap-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-shap-explanation/"},"sections":[{"parentId":null,"name":"Requesting a SHAP explanation by using the CLI","level":1,"index":0,"id":"requesting-a-shap-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requirements-for-upgrading-odh-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requirements-for-upgrading-odh-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/resolving-cuda-oom-errors/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/reviewing-and-deploying-your-lab-tuned-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/revoking-user-access-to-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-ds-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-jupyter-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/s3-prerequisites/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run-using-a-cron-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/selecting-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sending-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-timeout-for-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-lmeval-s3-support/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sharing-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/showing-hiding-information-about-available-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/specifying-to-use-a-feature-project-from-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-lab-tuning-run-from-the-registered-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-basic-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-idle-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/storing-a-model-in-oci-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/storing-data-with-data-science-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-checking-model-fairness/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-deploying-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-introduction/"},"sections":[{"parentId":null,"name":"About the example models","level":1,"index":0,"id":"_about_the_example_models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-reviewing-the-results/"},"sections":[{"parentId":null,"name":"Are the models biased?","level":1,"index":0,"id":"_are_the_models_biased"},{"parentId":null,"name":"How does the production data compare to the training data?","level":1,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-scheduling-a-fairness-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-scheduling-an-identity-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-sending-training-data-to-the-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-setting-up-your-environment/"},"sections":[{"parentId":null,"name":"Downloading the tutorial files","level":1,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":null,"name":"Logging in to the OpenShift cluster from the command line","level":1,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":null,"name":"Configuring monitoring for the model serving platform","level":1,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":3,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Setting up a project","level":1,"index":4,"id":"_setting_up_a_project"},{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":5,"id":"_authenticating_the_trustyai_service"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-simulating-real-world-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/testing-your-vllm-model-endpoints/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-workbenches-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s workbench does not start","level":1,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-workbenches-for-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-with-distributed-workloads-for-administrators/"},"sections":[{"parentId":null,"name":"A user&#8217;s Ray cluster is in a suspended state","level":1,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"A user&#8217;s Ray cluster is in a failed state","level":1,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for the CodeFlare Operator","level":1,"index":2,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for Kueue","level":1,"index":3,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"A user&#8217;s Ray cluster does not start","level":1,"index":4,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":null,"name":"A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message","level":1,"index":5,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"A user receives a <strong>local_queue provided does not exist</strong> error message","level":1,"index":6,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"A user cannot create a Ray cluster or submit jobs","level":1,"index":7,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled","level":1,"index":8,"id":"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-with-distributed-workloads-for-users/"},"sections":[{"parentId":null,"name":"My Ray cluster is in a suspended state","level":1,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"My Ray cluster is in a failed state","level":1,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for the CodeFlare Operator","level":1,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_the_codeflare_operator"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for Kueue","level":1,"index":3,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"My Ray cluster does not start","level":1,"index":4,"id":"_my_ray_cluster_does_not_start"},{"parentId":null,"name":"I see a \"Default Local Queue not found\" error message","level":1,"index":5,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"I see a \"local_queue provided does not exist\" error message","level":1,"index":6,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"I cannot create a Ray cluster or submit jobs","level":1,"index":7,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"My pod provisioned by Kueue is terminated before my image is pulled","level":1,"index":8,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-dspa-component-errors/"},"sections":[{"parentId":null,"name":"Common errors across DSP components","level":1,"index":0,"id":"_common_errors_across_dsp_components"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/understanding-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-access-to-a-data-science-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-an-accelerator-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-workbench-settings-by-restarting-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-project-in-code-server-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/upgrading-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-code-server-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-files-to-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-custom-unitxt-card/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-kserve-inference-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-hugging-face-prompt-injection-detector-with-the-guardrails-orchestrator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-accelerators-with-vllm/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs","level":1,"index":0,"id":"_nvidia_gpus"},{"parentId":null,"name":"Intel Gaudi accelerators","level":1,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":null,"name":"AMD GPUs","level":1,"index":2,"id":"_amd_gpus"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-explainers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-hugging-face-models-with-guardrails-orchestrator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-llm-as-a-judge-metrics-with-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-oci-containers-for-model-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-pvcs-as-storage/"},"sections":[{"parentId":null,"name":"Managed PVCs","level":1,"index":0,"id":"_managed_pvcs"},{"parentId":null,"name":"Existing PVCs","level":1,"index":1,"id":"_existing_pvcs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-the-cluster-CA-bundle-for-single-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-the-cluster-server-and-token-to-authenticate/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/verifying-amd-gpu-availability-on-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-active-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-audit-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-archived-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-connected-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-connection-types/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-feature-store-objects-in-the-web-based-ui/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-kueue-alerts-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-installed-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-metrics-for-the-multi-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-metrics-for-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-nvidia-nim-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-artifacts/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-task-executions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-project-metrics-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-python-packages-installed-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-python-packages-installed-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-registered-model-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-registered-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/working-with-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-status-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/working-with-hardware-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-accelerator-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-a-deployed-model/"},"sections":null}}}]},"asciidoc":{"html":"<div id=\"toc\" class=\"toc\">\n<div id=\"toctitle\">Table of Contents</div>\n<ul class=\"sectlevel1\">\n<li><a href=\"#managing-users-and-groups\">Managing users and groups</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#overview-of-user-types-and-permissions_managing-odh\">Overview of user types and permissions</a></li>\n<li><a href=\"#viewing-data-science-users_managing-odh\">Viewing Open Data Hub users</a></li>\n<li><a href=\"#adding-users-to-user-groups_managing-odh\">Adding users to Open Data Hub user groups</a></li>\n<li><a href=\"#selecting-admin-and-user-groups_managing-odh\">Selecting Open Data Hub administrator and user groups</a></li>\n<li><a href=\"#_deleting_users\">Deleting users</a></li>\n</ul>\n</li>\n<li><a href=\"#creating-custom-workbench-images\">Creating custom workbench images</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#creating-a-custom-image-from-default-image_custom-images\">Creating a custom image from a default Open Data Hub image</a></li>\n<li><a href=\"#creating-a-custom-image-from-your-own-image_custom-images\">Creating a custom image from your own image</a></li>\n<li><a href=\"#enabling-custom-images_custom-images\">Enabling custom images in Open Data Hub</a></li>\n<li><a href=\"#importing-a-custom-workbench-image_custom-images\">Importing a custom workbench image</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-applications-that-show-in-the-dashboard\">Managing applications that show in the dashboard</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#adding-an-application-to-the-dashboard_dashboard\">Adding an application to the dashboard</a></li>\n<li><a href=\"#preventing-users-from-adding-applications-to-the-dashboard_dashboard\">Preventing users from adding applications to the dashboard</a></li>\n<li><a href=\"#disabling-applications-connected_dashboard\">Disabling applications connected to Open Data Hub</a></li>\n<li><a href=\"#showing-hiding-information-about-available-applications_dashboard\">Showing or hiding information about available applications</a></li>\n<li><a href=\"#hiding-the-default-basic-workbench-application_dashboard\">Hiding the default basic workbench application</a></li>\n</ul>\n</li>\n<li><a href=\"#creating-project-scoped-resources_managing-odh\">Creating project-scoped resources</a></li>\n<li><a href=\"#allocating-additional-resources-to-data-science-users_managing-odh\">Allocating additional resources to Open Data Hub users</a></li>\n<li><a href=\"#customizing-component-deployment-resources_managing-resources\">Customizing component deployment resources</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#overview-of-component-resource-customization_managing-resources\">Overview of component resource customization</a></li>\n<li><a href=\"#customizing-component-resources_managing-resources\">Customizing component resources</a></li>\n<li><a href=\"#disabling-component-resource-customization_managing-resources\">Disabling component resource customization</a></li>\n<li><a href=\"#reenabling-component-resource-customization_managing-resources\">Re-enabling component resource customization</a></li>\n</ul>\n</li>\n<li><a href=\"#_enabling_accelerators\">Enabling accelerators</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#enabling-nvidia-gpus_managing-odh\">Enabling NVIDIA GPUs</a></li>\n<li><a href=\"#intel-gaudi-ai-accelerator-integration_managing-odh\">Intel Gaudi AI Accelerator integration</a></li>\n<li><a href=\"#amd-gpu-integration_managing-odh\">AMD GPU Integration</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-distributed-workloads_managing-odh\">Managing distributed workloads</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#overview-of-kueue-resources_managing-odh\">Overview of Kueue resources</a></li>\n<li><a href=\"#ref-example-kueue-resource-configurations_managing-odh\">Example Kueue resource configurations</a></li>\n<li><a href=\"#configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</a></li>\n<li><a href=\"#enforcing-local-queues_managing-odh\">Enforcing the use of local queues</a></li>\n<li><a href=\"#configuring-the-codeflare-operator_managing-odh\">Configuring the CodeFlare Operator</a></li>\n<li><a href=\"#configuring-a-cluster-for-rdma_managing-odh\">Configuring a cluster for RDMA</a></li>\n<li><a href=\"#troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh\">Troubleshooting common problems with distributed workloads for administrators</a></li>\n</ul>\n</li>\n<li><a href=\"#_backing_up_data\">Backing up data</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#backing-up-storage-data_managing-odh\">Backing up storage data</a></li>\n<li><a href=\"#backing-up-your-cluster_managing-odh\">Backing up your cluster</a></li>\n</ul>\n</li>\n<li><a href=\"#viewing-logs-and-audit-records_managing-odh\">Viewing logs and audit records</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#configuring-the-operator-logger_managing-odh\">Configuring the Open Data Hub Operator logger</a></li>\n<li><a href=\"#viewing-audit-records_managing-odh\">Viewing audit records</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"preamble\">\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>As an OpenShift cluster administrator, you can manage the following Open Data Hub resources:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Users and groups</p>\n</li>\n<li>\n<p>Custom workbench images</p>\n</li>\n<li>\n<p>Applications that show in the dashboard</p>\n</li>\n<li>\n<p>Custom deployment resources that are related to the Open Data Hub Operator, for example, CPU and memory limits and requests</p>\n</li>\n<li>\n<p>Accelerators</p>\n</li>\n<li>\n<p>Distributed workloads</p>\n</li>\n<li>\n<p>Data backup</p>\n</li>\n<li>\n<p>Logs and audit records</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-users-and-groups\">Managing users and groups</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Users with administrator access to OpenShift Container Platform can add, modify, and remove user permissions for Open Data Hub.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"overview-of-user-types-and-permissions_managing-odh\">Overview of user types and permissions</h3>\n<div class=\"paragraph\">\n<p>Table 1 describes the Open Data Hub user types.</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<caption class=\"title\">Table 1. User types</caption>\n<colgroup>\n<col style=\"width: 16.6666%;\">\n<col style=\"width: 83.3334%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">User Type</th>\n<th class=\"tableblock halign-left valign-top\">Permissions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Users</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Machine learning operations (MLOps) engineers and data scientists can access and use individual components of Open Data Hub, such as workbenches and data science pipelines.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Administrators</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"paragraph\">\n<p>In addition to the actions permitted to users, administrators can perform these actions:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Configure Open Data Hub settings.</p>\n</li>\n<li>\n<p>Access and manage workbenches.</p>\n</li>\n<li>\n<p>Access and manage data science pipeline applications for any data science project.</p>\n</li>\n</ul>\n</div></div></td>\n</tr>\n</tbody>\n</table>\n<div class=\"paragraph\">\n<p>By default, all OpenShift users have access to Open Data Hub. In addition, users in the OpenShift administrator group (<code>cluster admins</code>), automatically have administrator access in Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Optionally, if you want to restrict access to your Open Data Hub deployment to specific users or groups, you can create user groups for users and administrators.</p>\n</div>\n<div class=\"paragraph\">\n<p>If you decide to restrict access, and you already have groups defined in your configured identity provider, you can add these groups to your Open Data Hub deployment. If you decide to use groups without adding these groups from an identity provider, you must create the groups in OpenShift Container Platform and then add users to them.</p>\n</div>\n<div class=\"paragraph\">\n<p>There are some operations relevant to Open Data Hub that require the <code>cluster-admin</code> role. Those operations include:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Adding users to the Open Data Hub user and administrator groups, if you are using groups.</p>\n</li>\n<li>\n<p>Removing users from the Open Data Hub user and administrator groups, if you are using groups.</p>\n</li>\n<li>\n<p>Managing custom environment and storage configuration for users in OpenShift Container Platform, such as Jupyter notebook resources, ConfigMaps, and persistent volume claims (PVCs).</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Although users of Open Data Hub and its components are authenticated through OpenShift, session management is separate from authentication.\nThis means that logging out of OpenShift Container Platform or Open Data Hub does not affect a logged in Jupyter session running on those platforms.\nThis means that when a user&#8217;s permissions change, that user must log out of all current sessions in order for the changes to take effect.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"viewing-data-science-users_managing-odh\">Viewing Open Data Hub users</h3>\n<div class=\"paragraph\">\n<div class=\"title\">Additional resources</div>\n<p>If you have defined Open Data Hub user groups, you can view the users that belong to these groups.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>The Open Data Hub user group, administrator group, or both exist.</p>\n</li>\n<li>\n<p>You have the <code>cluster-admin</code> role in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have configured a supported identity provider for OpenShift Container Platform.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, click <strong>User Management</strong> &#8594; <strong>Groups</strong>.</p>\n</li>\n<li>\n<p>Click the name of the group containing the users that you want to view.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For administrative users, click the name of your administrator group. for example, <code>odh-admins</code>.</p>\n</li>\n<li>\n<p>For normal users, click the name of your user group, for example, <code>odh-users</code>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Group details</strong> page for the group appears.</p>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>In the <strong>Users</strong> section for the relevant group, you can view the users who have permission to access Open Data Hub.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"adding-users-to-user-groups_managing-odh\">Adding users to Open Data Hub user groups</h3>\n<div class=\"paragraph\">\n<p>By default, all OpenShift users have access to Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Optionally, you can restrict user access to your Open Data Hub instance by defining user groups. You must grant users permission to access Open Data Hub by adding user accounts to the Open Data Hub user group, administrator group, or both. You can either use the default group name, or specify a group name that already exists in your identity provider.</p>\n</div>\n<div class=\"paragraph\">\n<p>The <strong>user group</strong> provides the user with access to product components in the Open Data Hub dashboard, such as data science pipelines, and associated services, such as Jupyter. By default, users in the <strong>user group</strong> have access to data science pipeline applications within data science projects that they created.</p>\n</div>\n<div class=\"paragraph\">\n<p>The <strong>administrator group</strong> provides the user with access to developer and administrator functions in the Open Data Hub dashboard, such as data science pipelines, and associated services, such as Jupyter. Users in the <strong>administrator group</strong> can configure data science pipeline applications in the Open Data Hub dashboard for any data science project.</p>\n</div>\n<div class=\"paragraph\">\n<p>If you restrict access by using user groups, users that are not in the Open Data Hub user group or administrator group cannot view the dashboard and use associated services, such as Jupyter. They are also unable to access the <strong>Cluster settings</strong> page.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you are using LDAP as your identity provider, you need to configure LDAP syncing to OpenShift Container Platform. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/authentication_and_authorization/ldap-syncing\">Syncing LDAP groups</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>Follow the steps in this section to add users to your Open Data Hub administrator and user groups.</p>\n</div>\n<div class=\"paragraph\">\n<p>Note: You can add users in Open Data Hub but you must manage the user lists in the OpenShift Container Platform web console.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have configured a supported identity provider for OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You are assigned the <code>cluster-admin</code> role in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have defined an administrator group and user group for Open Data Hub.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, click <strong>User Management</strong> &#8594; <strong>Groups</strong>.</p>\n</li>\n<li>\n<p>Click the name of the group you want to add users to.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For administrative users, click the administrator group, for example, {oai-admin-group}.</p>\n</li>\n<li>\n<p>For normal users, click the user group, for example, {oai-user-group}.</p>\n<div class=\"paragraph\">\n<p>The <strong>Group details</strong> page for that group appears.</p>\n</div>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Actions</strong> &#8594; <strong>Add Users</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Add Users</strong> dialog appears.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Users</strong> field, enter the relevant user name to add to the group.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Click the <strong>Details</strong> tab for each group and confirm that the <strong>Users</strong> section contains the user names that you added.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"selecting-admin-and-user-groups_managing-odh\">Selecting Open Data Hub administrator and user groups</h3>\n<div class=\"paragraph\">\n<p>By default, all users authenticated in OpenShift can access Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Also by default, users with <code>cluster-admin</code> permissions are Open Data Hub administrators. A <code>cluster admin</code> is a superuser that can perform any action in any project in the OpenShift cluster. When bound to a user with a local binding, they have full control over quota and every action on every resource in the project.</p>\n</div>\n<div class=\"paragraph\">\n<p>After a <code>cluster admin</code> user defines additional administrator and user groups in OpenShift, you can add those groups to Open Data Hub by selecting them in the Open Data Hub dashboard.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The groups that you want to select as administrator and user groups for Open Data Hub already exist in OpenShift Container Platform. For more information, see\n<a href=\"https://opendatahub.io/docs/managing-odh/#managing-users-and-groups\">Managing users and groups</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>User management</strong>.</p>\n</li>\n<li>\n<p>Select your Open Data Hub administrator groups: Under <strong>Data science administrator groups</strong>, click the text box and select an OpenShift group. Repeat this process to define multiple administrator groups.</p>\n</li>\n<li>\n<p>Select your Open Data Hub user groups: Under <strong>Data science user groups</strong>, click the text box and select an OpenShift group. Repeat this process to define multiple user groups.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\nThe <code>system:authenticated</code> setting allows all users authenticated in OpenShift to access Open Data Hub.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Administrator users can successfully log in to Open Data Hub and have access to the <strong>Settings</strong> navigation menu.</p>\n</li>\n<li>\n<p>Non-administrator users can successfully log in to Open Data Hub. They can also access and use individual components, such as projects and workbenches.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_deleting_users\">Deleting users</h3>\n<div class=\"sect3\">\n<h4 id=\"about-deleting-users-and-resources_managing-odh\">About deleting users and their resources</h4>\n<div class=\"paragraph\">\n<p>If you have administrator access to OpenShift Container Platform, you can revoke a user&#8217;s access to Jupyter and delete the user&#8217;s resources from Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Deleting a user and the user&#8217;s resources involves the following tasks:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Before you delete a user from Open Data Hub, it is good practice to back up the data on your persistent volume claims (PVCs).</p>\n</li>\n<li>\n<p>Stop workbenches owned by the user.</p>\n</li>\n<li>\n<p>Revoke user access to Jupyter.</p>\n</li>\n<li>\n<p>Remove the user from the allowed group in your OpenShift identity provider.</p>\n</li>\n<li>\n<p>After you delete a user, delete their associated configuration files from OpenShift Container Platform.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"stopping-basic-workbenches-owned-by-other-users_managing-odh\">Stopping basic workbenches owned by other users</h4>\n<div class=\"paragraph _abstract\">\n<p>Open Data Hub administrators can stop basic workbenches that are owned by other users to reduce resource consumption on the cluster, or as part of removing a user and their resources from the cluster.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>You have launched the <strong>Start basic workbench</strong> application, as described in <a href=\"https://opendatahub.io/docs/working-with-connected-applications/#starting-a-basic-workbench_connected-apps\">Starting a basic workbench</a>.</p>\n</li>\n<li>\n<p>The workbench that you want to stop is running.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>On the page that opens when you launch a basic workbench, click the <strong>Administration</strong> tab.</p>\n</li>\n<li>\n<p>Stop one or more servers.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you want to stop one or more specific servers, perform the following actions:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>In the <strong>Users</strong> section, locate the user that the workbench belongs to.</p>\n</li>\n<li>\n<p>To stop the workbench, perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the relevant user and select <strong>Stop server</strong>.</p>\n</li>\n<li>\n<p>Click <strong>View server</strong> beside the relevant user and then click <strong>Stop workbench</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Stop server</strong> dialog box appears.</p>\n</div>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Stop server</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>If you want to stop all workbenches, perform the following actions:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>Click the <strong>Stop all workbenches</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>OK</strong> to confirm stopping all servers.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <strong>Stop server</strong> link beside each server changes to a <strong>Start workbench</strong> link when the workbench has stopped.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"revoking-user-access-to-basic-workbenches_managing-odh\">Revoking user access to basic workbenches</h4>\n<div class=\"paragraph _abstract\">\n<p>You can revoke a user&#8217;s access to basic workbenches by removing the user from the Open Data Hub user groups that define access to Open Data Hub. When you remove a user from the user groups, the user is prevented from accessing the Open Data Hub dashboard and from using associated services that consume resources in your cluster.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\nFollow these steps only if you have implemented Open Data Hub user groups to restrict access to Open Data Hub. To completely remove a user from Open Data Hub, you must remove them from the allowed group in your OpenShift identity provider.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have stopped any workbenches owned by the user you want to delete.</p>\n</li>\n<li>\n<p>You are using Open Data Hub user groups, and the user is part of the user group, administrator group, or both.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, click <strong>User Management</strong> &#8594; <strong>Groups</strong>.</p>\n</li>\n<li>\n<p>Click the name of the group that you want to remove the user from.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For administrative users, click the name of your administrator group, for example, {oai-admin-group}.</p>\n</li>\n<li>\n<p>For non-administrator users, click the name of your user group, for example, {oai-user-group}.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>The <strong>Group details</strong> page for the group appears.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Users</strong> section on the <strong>Details</strong> tab, locate the user that you want to remove.</p>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the user that you want to remove and click <strong>Remove user</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Check the <strong>Users</strong> section on the <strong>Details</strong> tab and confirm that the user that you removed is not visible.</p>\n</li>\n<li>\n<p>In the <code>rhods-notebooks</code> project, check under <strong>Workloads</strong> &#8594; <strong>Pods</strong> and ensure that there is no workbench pod for this user. If you see a pod named <code>jupyter-nb-&lt;username&gt;-*</code> for the user that you have removed, delete that pod to ensure that the deleted user is not consuming resources on the cluster.</p>\n</li>\n<li>\n<p>In the Open Data Hub dashboard, check the list of data science projects. Delete any projects that belong to the user.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"backing-up-storage-data_managing-odh\">Backing up storage data</h4>\n<div class=\"paragraph _abstract\">\n<p>It is a best practice to back up the data on your persistent volume claims (PVCs) regularly.</p>\n</div>\n<div class=\"paragraph\">\n<p>Backing up your data is particularly important before you delete a user and before you uninstall Open Data Hub, as all PVCs are deleted when Open Data Hub is uninstalled.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about backing up PVCs for your cluster platform, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/backup_and_restore/oadp-application-backup-and-restore.html\">OADP Application backup and restore</a> in the OpenShift Container Platform documentation.</p>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/storage/understanding-persistent-storage\">Understanding persistent storage</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"cleaning-up-after-deleting-users_managing-odh\">Cleaning up after deleting users</h4>\n<div class=\"paragraph _abstract\">\n<p>After you remove a user&#8217;s access to Open Data Hub or Jupyter, you must also delete the configuration files for the user from OpenShift Container Platform.\nRed&#160;Hat recommends that you back up the user&#8217;s data before removing their configuration files.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>(Optional) If you want to completely remove the user&#8217;s access to Open Data Hub, you have removed their credentials from your identity provider.</p>\n</li>\n<li>\n<p>You have revoked the user&#8217;s access to Jupyter.</p>\n</li>\n<li>\n<p>You have logged in to the OpenShift Container Platform web console as a user with the <code>cluster-admin</code> role.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Delete the user&#8217;s persistent volume claim (PVC).</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Storage</strong> &#8594; <strong>PersistentVolumeClaims</strong>.</p>\n</li>\n<li>\n<p>If it is not already selected, select the <code>rhods-notebooks</code> project from the project list.</p>\n</li>\n<li>\n<p>Locate the  <code>jupyter-nb-&lt;username&gt;</code> PVC.</p>\n<div class=\"paragraph\">\n<p>Replace <code>&lt;username&gt;</code> with the relevant user name.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (&#8942;) and select <strong>Delete PersistentVolumeClaim</strong> from the list.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete PersistentVolumeClaim</strong> dialog appears.</p>\n</div>\n</li>\n<li>\n<p>Inspect the dialog and confirm that you are deleting the correct PVC.</p>\n</li>\n<li>\n<p>Click <strong>Delete</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Delete the user&#8217;s ConfigMap.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Workloads</strong> &#8594; <strong>ConfigMaps</strong>.</p>\n</li>\n<li>\n<p>If it is not already selected, select the <code>rhods-notebooks</code> project from the project list.</p>\n</li>\n<li>\n<p>Locate the <code>jupyterhub-singleuser-profile-&lt;username&gt;</code> ConfigMap.</p>\n<div class=\"paragraph\">\n<p>Replace <code>&lt;username&gt;</code> with the relevant user name.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (&#8942;) and select <strong>Delete ConfigMap</strong> from the list.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete ConfigMap</strong> dialog appears.</p>\n</div>\n</li>\n<li>\n<p>Inspect the dialog and confirm that you are deleting the correct ConfigMap.</p>\n</li>\n<li>\n<p>Click <strong>Delete</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The user cannot access Jupyter any more, and sees an \"Access permission needed\" message if they try.</p>\n</li>\n<li>\n<p>The user&#8217;s single-user profile, persistent volume claim (PVC), and ConfigMap are not visible in OpenShift Container Platform.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"creating-custom-workbench-images\">Creating custom workbench images</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Open Data Hub includes a selection of default workbench images that a data scientist can select when they create or edit a workbench.</p>\n</div>\n<div class=\"paragraph\">\n<p>In addition, you can import a custom workbench image, for example, if you want to add libraries that data scientists often use, or if your data scientists require a specific version of a library that is different from the version provided in a default image. Custom workbench images are also useful if your data scientists require operating system packages or applications because they cannot install them directly in their running environment (data scientist users do not have root access, which is needed for those operations).</p>\n</div>\n<div class=\"paragraph\">\n<p>A custom workbench image is simply a container image. You build one as you would build any standard container image, by using a Containerfile (or Dockerfile). You start from an existing image (the <code>FROM</code> instruction), and then add your required elements.</p>\n</div>\n<div class=\"paragraph\">\n<p>You have the following options for creating a custom workbench image:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Start from one of the default images, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#creating-a-custom-image-from-default-image_custom-images\">Creating a custom image from a default Open Data Hub image</a>.</p>\n</li>\n<li>\n<p>Create your own image by following the guidelines for making it compatible with Open Data Hub, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#creating-a-custom-image-from-your-own-image_custom-images\">Creating a custom image from your own image</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Additional resources</div>\n<p>For more information about creating images, see the following resources:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/images/creating-images\">Red Hat OpenShift Container Platform - Creating Images</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/images/creating-images#creating-images\">Red Hat OpenShift Service on AWS - Creating images</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.docker.com/engine/reference/builder/\">Red Hat OpenShift Dedicated - Dockerfile reference documentation</a></p>\n</li>\n</ul>\n</div>\n<div class=\"sect2\">\n<h3 id=\"creating-a-custom-image-from-default-image_custom-images\">Creating a custom image from a default Open Data Hub image</h3>\n<div class=\"paragraph\">\n<p>After Open Data Hub is installed on a cluster, you can find the default workbench images in the OpenShift console, under <strong>Builds</strong> &#8594; <strong>ImageStreams</strong> for the <code>redhat-ods-applications</code> project.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can create a custom image by adding OS packages or applications to a default Open Data Hub image.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You know which default image you want to use as the base for your custom image.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you want to create a custom Elyra-compatible image, the base image must be an Open Data Hub image that contains the Elyra extension.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>You have <code>cluster-admin</code> access to the OpenShift console for the cluster where Open Data Hub is installed.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Obtain the location of the default image that you want to use as the base for your custom image.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift console, select <strong>Builds</strong> &#8594; <strong>ImageStreams</strong>.</p>\n</li>\n<li>\n<p>Select the <strong>redhat-ods-applications</strong> project.</p>\n</li>\n<li>\n<p>From the list of installed imagestreams, click the name of the image that you want to use as the base for your custom image. For example, click <strong>pytorch</strong>.</p>\n</li>\n<li>\n<p>On the ImageStream details page, click <strong>YAML</strong>.</p>\n</li>\n<li>\n<p>In the <code>spec:tags</code> section, find the tag for the version of the image that you want to use.</p>\n<div class=\"paragraph\">\n<p>The location of the original image is shown in the tag&#8217;s <code>from:name</code> section, for example:</p>\n</div>\n<div class=\"paragraph\">\n<p><code>name: 'quay.io/modh/odh-pytorch-notebook@sha256:b68e0192abf7d…'</code></p>\n</div>\n</li>\n<li>\n<p>Copy this location for use in your custom image.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Create a standard Containerfile or Dockerfile.</p>\n</li>\n<li>\n<p>For the <code>FROM</code> instruction, specify the base image location that you copied in Step 1, for example:</p>\n<div class=\"paragraph\">\n<p><code>FROM quay.io/modh/odh-pytorch-notebook@sha256:b68e0…</code></p>\n</div>\n</li>\n<li>\n<p>Optional: Install OS images:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Switch to <code>USER 0</code> (USER 0 is required to install OS packages).</p>\n</li>\n<li>\n<p>Install the packages.</p>\n</li>\n<li>\n<p>Switch back to <code>USER 1001</code>.</p>\n<div class=\"paragraph\">\n<p>The following example creates a custom workbench image that adds Java to the default PyTorch image:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code> FROM quay.io/modh/odh-pytorch-notebook@sha256:b68e0…\n\n USER 0\n\n RUN INSTALL_PKGS=\"java-11-openjdk java-11-openjdk-devel\" &amp;&amp; \\\n    dnf install -y --setopt=tsflags=nodocs $INSTALL_PKGS &amp;&amp; \\\n    dnf -y clean all --enablerepo=<em>*</em>\n\n USER 1001</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: Add Python packages:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Specify <code>USER 1001</code>.</p>\n</li>\n<li>\n<p>Copy the <code>requirements.txt</code> file.</p>\n</li>\n<li>\n<p>Install the packages.</p>\n<div class=\"paragraph\">\n<p>The following example installs packages from the <code>requirements.txt</code> file in the default PyTorch image:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code> FROM quay.io/modh/odh-pytorch-notebook@sha256:b68e0…\n\n USER 1001\n\n COPY requirements.txt ./requirements.txt\n\n RUN pip install -r requirements.txt</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Build the image file. For example, you can use <code>podman build</code> locally where the image file is located and then push the image to a registry that is accessible to Open Data Hub:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>$ podman build -t my-registry/my-custom-image:0.0.1 .\n$ podman push my-registry/my-custom-image:0.0.1</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Alternatively, you can leverage OpenShift&#8217;s image build capabilities by using <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/builds_using_buildconfig/understanding-buildconfigs\">BuildConfig</a>.</p>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"creating-a-custom-image-from-your-own-image_custom-images\">Creating a custom image from your own image</h3>\n<div class=\"paragraph\">\n<p>You can build your own custom image. However, you must make sure that your image is compatible with OpenShift and Open Data Hub.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/images/creating-images#images-create-guide-general_create-images\">General Container image guidelines section</a> in the OpenShift Container Platform Images documentation.</p>\n</li>\n<li>\n<p>Red Hat Universal Base Image: <a href=\"https://catalog.redhat.com/software/base-images\" class=\"bare\">https://catalog.redhat.com/software/base-images</a></p>\n</li>\n<li>\n<p>Red Hat Ecosystem Catalog: <a href=\"https://catalog.redhat.com/\" class=\"bare\">https://catalog.redhat.com/</a></p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_basic_guidelines_for_creating_your_own_workbench_image\">Basic guidelines for creating your own workbench image</h4>\n<div class=\"paragraph\">\n<p>The following basic guidelines provide information to consider when you build your own custom workbench image.</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Designing your image to run with USER 1001</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>In OpenShift, your container will run with a random UID and a GID of <code>0</code>. Make sure that your image is compatible with these user and group requirements, especially if you need write access to directories. Best practice is to design your image to run with <code>USER 1001</code>.</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Avoid placing artifacts in $HOME</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>The persistent volume attached to the workbench will be mounted on <code>/opt/app-root/src</code>. This location is also the location of <code>$HOME</code>. Therefore, do not put any files or other resources directly in <code>$HOME</code> because they are not visible after the workbench is deployed (and the persistent volume is mounted).</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Specifying the API endpoint</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>OpenShift readiness and liveness probes will query the <code>/api</code> endpoint. For a Jupyter IDE, this is the default endpoint. For other IDEs, you must implement the <code>/api</code> endpoint.</p>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_advanced_guidelines_for_creating_your_own_workbench_image\">Advanced guidelines for creating your own workbench image</h4>\n<div class=\"paragraph\">\n<p>The following guidelines provide information to consider when you build your own custom workbench image.</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Minimizing image size</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>A workbench image uses a \"layered\" file system. Every time you use a COPY or a RUN command in your workbench image file, a new layer is created. Artifacts are not deleted. When you remove an artifact, for example, a file, it is \"masked\" in the next layer. Therefore, consider the following guidelines when you create your workbench image file.</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Avoid using the <code>dnf update</code> command.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you start from an image that is constantly updated, such as <code>ubi9/python-39</code> from the Red Hat Catalog, you might not need to use the <code>dnf update</code> command. This command fetches new metadata, updates files that might not have impact, and increases the workbench image size.</p>\n</li>\n<li>\n<p>Point to a newer version of your base image rather than performing a <code>dnf update</code> on an older version.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Group <code>RUN</code> commands. Chain your commands by adding <code>&amp;&amp; \\</code> at the end of each line.</p>\n</li>\n<li>\n<p>If you must compile code (such as a library or an application) to include in your custom image, implement multi-stage builds so that you avoid including the build artifacts in your final image. That is, compile the library or application in an intermediate image and then copy the result to your final image, leaving behind build artifacts that you do not want included.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><strong>Setting access to files and directories</strong></p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Set the ownership of files and folders to <code>1001:0</code> (user \"default\", group \"0\"), for example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>COPY --chown=1001:0 os-packages.txt ./</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>On OpenShift, every container is in a standard namespace (unless you modify security). The container runs with a user that has a random user ID (uid) and with a group ID (gid) of <code>0</code>. Therefore, all folders that you want to write to - and all the files you want to (temporarily) modify - in your image must be accessible by the user that has the random user ID (uid).\nAlternatively, you can set access to any user, as shown in the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>COPY --chmod=775 os-packages.txt ./</pre>\n</div>\n</div>\n</li>\n<li>\n<p>Build your image with <code>/opt/app-root/src</code> as the default location for the data that you want persisted, for example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>WORKDIR /opt/app-root/src</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>When a user launches a workbench from the Open Data Hub <strong>Applications</strong> → <strong>Enabled</strong> page, the \"personal\" volume of the user is mounted at <code>/opt/app-root/src</code>. Because this location is not configurable, when you build your custom image, you must specify this default location for persisted data.</p>\n</div>\n</li>\n<li>\n<p>Fix permissions to support PIP (the package manager for Python packages) in OpenShift environments. Add the following command to your custom image (if needed, change <code>python3.9</code> to the Python version that you are using):</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>chmod -R g+w /opt/app-root/lib/python3.9/site-packages &amp;&amp; \\\n   fix-permissions /opt/app-root -P</pre>\n</div>\n</div>\n</li>\n<li>\n<p>A service within your workbench image must answer at <code>${NB_PREFIX}/api</code>, otherwise the OpenShift liveness/readiness probes fail and delete the pod for the workbench image.</p>\n<div class=\"paragraph\">\n<p>The <code>NB_PREFIX</code> environment variable specifies the URL path where the container is expected to be listening.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following is an example of an Nginx configuration:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>location = ${NB_PREFIX}/api {\n\treturn 302  /healthz;\n\taccess_log  off;\n}</pre>\n</div>\n</div>\n</li>\n<li>\n<p>For idle culling to work, the <code>${NB_PREFIX}/api/kernels</code> URL must return a specifically-formatted JSON payload, as shown in the following example:</p>\n<div class=\"paragraph\">\n<p>The following is an example of an Nginx configuration:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>location = ${NB_PREFIX}/api/kernels {\n\treturn 302 $custom_scheme://$http_host/api/kernels/;\n\taccess_log  off;\n}\n\nlocation ${NB_PREFIX}/api/kernels/ {\n\treturn 302 $custom_scheme://$http_host/api/kernels/;\n\taccess_log  off;\n}\n\nlocation /api/kernels/ {\n  index access.cgi;\n  fastcgi_index access.cgi;\n  gzip  off;\n  access_log\toff;\n }</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The returned JSON payload should be:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>{\"id\":\"rstudio\",\"name\":\"rstudio\",\"last_activity\":(time in ISO8601 format),\"execution_state\":\"busy\",\"connections\": 1}</pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><strong>Enabling CodeReady Builder (CRB) and Extra Packages for Enterprise Linux (EPEL)</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>CRB and EPEL are repositories that provide packages which are absent from a standard Red Hat Enterprise Linux (RHEL) or Universal Base Image (UBI) installation. They are useful and required for installing some software, for example, RStudio.</p>\n</div>\n<div class=\"paragraph\">\n<p>On UBI9 images, CRB is enabled by default. To enable EPEL on UBI9-based images, run the following command:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre> RUN yum install -y https://download.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>To enable CRB and EPEL on Centos Stream 9-based images, run the following command:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre> RUN yum install -y yum-utils &amp;&amp; \\\n    yum-config-manager --enable crb &amp;&amp; \\\n    yum install -y https://download.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p><strong>Adding Elyra compatibility</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>Support for data science pipelines V2 (provided with the <code>odh-elyra</code> package) is available in Open Data Hub version 2.9 and later. Previous versions of Open Data Hub support data science pipelines V1 (provided with the <code>elyra</code> package).</p>\n</div>\n<div class=\"paragraph\">\n<p>If you want your custom image to support data science pipelines V2, you must address the following requirements:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Include the <code>odh-elyra</code> package for having support with Data Science pipeline V2 (not the <code>elyra</code> package), for example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre> USER 1001\n\n RUN pip install odh-elyra</pre>\n</div>\n</div>\n</li>\n<li>\n<p>If you want to include the data science pipeline configuration automatically, as a runtime configuration, add an annotation when you import a custom workbench image.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"enabling-custom-images_custom-images\">Enabling custom images in Open Data Hub</h3>\n<div class=\"paragraph\">\n<p>All Open Data Hub administrators can import custom workbench images, by default, by selecting the <strong>Settings</strong> &#8594; <strong>Workbench images</strong> navigation option in the Open Data Hub dashboard.</p>\n</div>\n<div class=\"paragraph\">\n<p>If the <strong>Settings</strong> &#8594; <strong>Workbench images</strong> option is not available, check the following settings, depending on which navigation element does not appear in the dashboard:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>The <strong>Settings</strong> menu does not appear in the Open Data Hub navigation bar.</p>\n<div class=\"paragraph\">\n<p>The visibility of the Open Data Hub dashboard <strong>Settings</strong> menu is determined by your user permissions. By default, the <strong>Settings</strong> menu is available to Open Data Hub administration users (users that are members of the <code>rhoai-admins</code> group). Users with the OpenShift <code>cluster-admin</code> role are automatically added to the <code>rhoai-admins</code> group and are granted administrator access in Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about user permissions, see <a href=\"https://opendatahub.io/docs/managing-odh/#managing-groups-and-users\">Managing users and groups</a>.</p>\n</div>\n</li>\n<li>\n<p>The <strong>Workbench images</strong> menu item does not appear under the <strong>Settings</strong> menu.</p>\n<div class=\"paragraph\">\n<p>The visibility of the <strong>Workbench images</strong> menu item is controlled in the dashboard configuration, by the value of the <code>dashboardConfig: disableBYONImageStream</code> option. It is set to <strong>false</strong> (the <strong>Workbench images</strong> menu item is visible) by default.</p>\n</div>\n<div class=\"paragraph\">\n<p>You need Open Data Hub administrator permissions to edit the dashboard configuration.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</div>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"importing-a-custom-workbench-image_custom-images\">Importing a custom workbench image</h3>\n<div class=\"paragraph _abstract\">\n<p>You can import custom workbench images that cater to your Open Data Hub project&#8217;s specific requirements. From the <strong>Workbench images</strong> page, you can enable or disable a previously imported workbench image and create an accelerator profile or a hardware profile as a recommended accelerator for existing workbench images.</p>\n</div>\n<div class=\"paragraph\">\n<p>You must import it so that your Open Data Hub users (data scientists) can access it when they create a project workbench.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>Your custom image exists in an image registry that is accessible to Open Data Hub.</p>\n</li>\n<li>\n<p>The <strong>Settings</strong> &#8594; <strong>Workbench images</strong> dashboard navigation menu item is enabled, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#enabling-custom-images_custom-images\">Creating a custom image from a default Open Data Hub image</a>.</p>\n</li>\n<li>\n<p>If you want to associate an accelerator with the custom image that you want to import, you know the accelerator&#8217;s identifier - the unique string that identifies the hardware accelerator. You must also have enabled GPU support. This includes installing the Node Feature Discovery and NVIDIA GPU Operators. For more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Workbench images</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Workbench images</strong> page appears. Previously imported images are displayed. To enable or disable a previously imported image, on the row containing the relevant image, click the toggle in the <strong>Enable</strong> column.</p>\n</div>\n</li>\n<li>\n<p>Optional: If you want to associate an accelerator and you have not already created an accelerator profile or a hardware profile, click  <strong>Create profile</strong> on the row containing the image and complete the relevant fields. If the image does not contain an accelerator identifier, you must manually configure one before creating an associated accelerator profile or a hardware profile.</p>\n</li>\n<li>\n<p>Click <strong>Import new image</strong>. Alternatively, if no previously imported images were found, click <strong>Import image</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Import workbench image</strong> dialog appears.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Image location</strong> field, enter the URL of the repository containing the image. For example: <code>quay.io/my-repo/my-image:tag</code>, <code>quay.io/my-repo/my-image@sha256:xxxxxxxxxxxxx</code>, or\n<code>docker.io/my-repo/my-image:tag</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> field, enter an appropriate name for the image.</p>\n</li>\n<li>\n<p>Optional: In the <strong>Description</strong> field, enter a description for the image.</p>\n</li>\n<li>\n<p>Optional: From the <strong>Accelerator identifier</strong> list, select an identifier to set its accelerator as recommended with the image. If the image contains only one accelerator identifier, the identifier name displays by default.</p>\n</li>\n<li>\n<p>Optional: Add software to the image. After the import has completed, the software is added to the image&#8217;s meta-data and displayed on the workbench creation page.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click the <strong>Software</strong> tab.</p>\n</li>\n<li>\n<p>Click the <strong>Add software</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>Edit</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-edit-icon.png\" alt=\"The Edit icon\"></span>).</p>\n</li>\n<li>\n<p>Enter the <strong>Software</strong> name.</p>\n</li>\n<li>\n<p>Enter the software <strong>Version</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>) to confirm your entry.</p>\n</li>\n<li>\n<p>To add additional software, click <strong>Add software</strong>, complete the relevant fields, and confirm your entry.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: Add packages to the workbench images. After the import has completed, the packages are added to the image&#8217;s meta-data and displayed on the workbench creation page.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click the <strong>Packages</strong> tab.</p>\n</li>\n<li>\n<p>Click the  <strong>Add package</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>Edit</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-edit-icon.png\" alt=\"The Edit icon\"></span>).</p>\n</li>\n<li>\n<p>Enter the <strong>Package</strong> name. For example, if you want to include data science pipeline V2 automatically, as a runtime configuration, type <code>odh-elyra</code>.</p>\n</li>\n<li>\n<p>Enter the package <strong>Version</strong>. For example, type <code>3.16.7</code>.</p>\n</li>\n<li>\n<p>Click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>) to confirm your entry.</p>\n</li>\n<li>\n<p>To add an additional package, click <strong>Add package</strong>, complete the relevant fields, and confirm your entry.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Click <strong>Import</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The image that you imported is displayed in the table on the <strong>Workbench images</strong> page.</p>\n</li>\n<li>\n<p>Your custom image is available for selection when a user creates a workbench.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/images/managing-image-streams\">Managing image streams</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/builds_using_buildconfig/understanding-buildconfigs\">Understanding build configurations</a></p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-applications-that-show-in-the-dashboard\">Managing applications that show in the dashboard</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"adding-an-application-to-the-dashboard_dashboard\">Adding an application to the dashboard</h3>\n<div class=\"paragraph _abstract\">\n<p>If you have installed an application in your OpenShift Container Platform cluster, an Open Data Hub administrator can add a tile for that application to the Open Data Hub dashboard (the <strong>Applications</strong> → <strong>Enabled</strong> page) to make it accessible for Open Data Hub users.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The <code>spec.dashboardConfig.enablement</code> dashboard configuration option is set to <code>true</code> (the default).</p>\n<div class=\"paragraph\">\n<p>For more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as an Open Data Hub administrator.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhApplication</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhApplication</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click <strong>Create OdhApplication</strong>.</p>\n</li>\n<li>\n<p>On the <strong>Create OdhApplication</strong> page, copy the following code and paste it into the YAML editor.</p>\n<div class=\"listingblock lines_space console-input\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">apiVersion: dashboard.opendatahub.io/v1\nkind: OdhApplication\nmetadata:\n  name: examplename\n  namespace: opendatahub\n  labels:\n    app: odh-dashboard\n    app.kubernetes.io/part-of: odh-dashboard\nspec:\n  enable:\n    validationConfigMap: examplename-enable\n  img: &gt;-\n    &lt;svg width=\"24\" height=\"25\" viewBox=\"0 0 24 25\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"&gt;\n    &lt;path d=\"path data\" fill=\"#ee0000\"/&gt;\n    &lt;/svg&gt;\n  getStartedLink: 'https://example.org/docs/quickstart.html'\n  route: exampleroutename\n  routeNamespace: examplenamespace\n  displayName: Example Name\n  kfdefApplications: []\n  support: third party support\n  csvName: ''\n  provider: example\n  docsLink: 'https://example.org/docs/index.html'\n  quickStart: ''\n  getStartedMarkDown: &gt;-\n    # Example\n\n    Enter text for the information panel.\n\n  description: &gt;-\n    Enter summary text for the tile.\n  category: Self-managed | Partner managed | Red Hat managed</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Modify the parameters in the code for your application.</p>\n<div class=\"admonitionblock tip\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Tip</div>\n</td>\n<td class=\"content\">\nTo see example YAML files, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>, select <code>OdhApplication</code>, click the <strong>Instances</strong> tab, select an instance, and then click the <strong>YAML</strong> tab.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Click <strong>Create</strong>. The application details page appears.</p>\n</li>\n<li>\n<p>Log in to Open Data Hub.</p>\n</li>\n<li>\n<p>In the left menu, click <strong>Applications</strong> &#8594; <strong>Explore</strong>.</p>\n</li>\n<li>\n<p>Locate the new tile for your application and click it.</p>\n</li>\n<li>\n<p>In the information pane for the application, click <strong>Enable</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>In the left menu of the Open Data Hub dashboard, click <strong>Applications</strong> → <strong>Enabled</strong> and verify that your application is available.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"preventing-users-from-adding-applications-to-the-dashboard_dashboard\">Preventing users from adding applications to the dashboard</h3>\n<div class=\"paragraph _abstract\">\n<p>By default, Open Data Hub administrators can add applications to the Open Data Hub dashboard <strong>Application → Enabled</strong> page.</p>\n</div>\n<div class=\"paragraph\">\n<p>As an Open Data Hub administrator, you can disable the ability for Open Data Hub administrators to add applications to the dashboard.</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Note:</strong> The <strong>Start basic workbench</strong> tile is enabled by default. To disable it, see <a href=\"https://opendatahub.io/docs/managing-odh/#hiding-the-default-basic-workbench-application_dashboard\">Hiding the default basic workbench application</a>.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisite</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as an Open Data Hub administrator.</p>\n</li>\n<li>\n<p>Open the dashboard configuration file:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhDashboardConfig</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhDashboardConfig</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click the <code>odh-dashboard-config</code> instance to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>In the <code>spec.dashboardConfig</code> section, set the value of <code>enablement</code> to <code>false</code> to disable the ability for dashboard users to add applications to the dashboard.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong> to apply your changes and then click <strong>Reload</strong> to make sure that your changes are synced to the cluster.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Open the Open Data Hub dashboard <strong>Application → Enabled</strong> page.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"disabling-applications-connected_dashboard\">Disabling applications connected to Open Data Hub</h3>\n<div class=\"paragraph _abstract\">\n<p>You can disable applications and components so that they do not appear on the Open Data Hub dashboard when you no longer want to use them, for example, when data scientists no longer use an application or when the application license expires.</p>\n</div>\n<div class=\"paragraph\">\n<p>Disabling unused applications allows your data scientists to manually remove these application tiles from their Open Data Hub dashboard so that they can focus on the applications that they are most likely to use.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to the OpenShift Container Platform web console.</p>\n</li>\n<li>\n<p>You are part of the <code>cluster-admins</code> user group in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have installed or configured the service on your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>The application or component that you want to disable is enabled and appears on the <strong>Enabled</strong> page.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, switch to the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>Switch to the <code>odh</code> project.</p>\n</li>\n<li>\n<p>Click <strong>Operators</strong> &#8594; <strong>Installed Operators</strong>.</p>\n</li>\n<li>\n<p>Click on the Operator that you want to uninstall. You can enter a keyword into the <strong>Filter by name</strong> field to help you find the Operator faster.</p>\n</li>\n<li>\n<p>Delete any Operator resources or instances by using the tabs in the Operator interface.</p>\n<div class=\"paragraph\">\n<p>During installation, some Operators require the administrator to create resources or start process instances using tabs in the Operator interface. These must be deleted before the Operator can uninstall correctly.</p>\n</div>\n</li>\n<li>\n<p>On the <strong>Operator Details</strong> page, click the <strong>Actions</strong> drop-down menu and select <strong>Uninstall Operator</strong>.</p>\n<div class=\"paragraph\">\n<p>An <strong>Uninstall Operator?</strong> dialog box is displayed.</p>\n</div>\n</li>\n<li>\n<p>Select <strong>Uninstall</strong> to uninstall the Operator, Operator deployments, and pods. After this is complete, the Operator stops running and no longer receives updates.</p>\n</li>\n</ol>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Removing an Operator does not remove any custom resource definitions or managed resources for the Operator. Custom resource definitions and managed resources still exist and must be cleaned up manually. Any applications deployed by your Operator and any configured off-cluster resources continue to run and must be cleaned up manually.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The Operator is uninstalled from its target clusters.</p>\n</li>\n<li>\n<p>The Operator no longer appears on the <strong>Installed Operators</strong> page.</p>\n</li>\n<li>\n<p>The disabled application is no longer available for your data scientists to use, and is marked as <code>Disabled</code> on the <strong>Enabled</strong> page of the Open Data Hub dashboard. This action may take a few minutes to occur following the removal of the Operator.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"showing-hiding-information-about-available-applications_dashboard\">Showing or hiding information about available applications</h3>\n<div class=\"paragraph _abstract\">\n<p>You can view a list of available applications in the <strong>Exploring applications</strong> page of the Open Data Hub dashboard. By default, the following information is provided for each application:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Any independent software vendor (ISV) application is indicated with a label on the tile indicating <code>Red&#160;Hat-managed</code>, <code>Partner managed</code>, or <code>Self-managed</code>. As an Open Data Hub administrator, you can hide or show the labels. For example, if you are running a self-managed environment, you might want to show all available applications regardless of the support level.</p>\n</li>\n<li>\n<p>When a user clicks on an application, an information panel appears and provides more information about the application, including links to quick starts or detailed documentation. You can disable or enable the appearance of application information panels.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as an Open Data Hub administrator.</p>\n</li>\n<li>\n<p>Open the dashboard configuration file:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhDashboardConfig</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhDashboardConfig</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click the <code>odh-dashboard-config</code> instance to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>In the <code>spec.dashboardConfig</code> section, set either or both of the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>disableInfo</code>: Set to <code>true</code> to hide the appearance of application information panel. Set to <code>False</code> (the default) to show the application information panel.</p>\n</li>\n<li>\n<p><code>disableISVBadges</code>: Set to <code>true</code> to hide the appearance of the support-level label. Set to <code>False</code> (the default) to show the support-level label.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong> to apply your changes and then click <strong>Reload</strong> to make sure that your changes are synced to the cluster.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>Log in to Open Data Hub and verify that your dashboard configurations apply.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"hiding-the-default-basic-workbench-application_dashboard\">Hiding the default basic workbench application</h3>\n<div class=\"paragraph _abstract\">\n<p>The Open Data Hub dashboard includes <strong>Start basic workbench</strong> as an enabled application by default.</p>\n</div>\n<div class=\"paragraph\">\n<p>To hide the <strong>Start basic workbench</strong> tile so that it is no longer included in the list of applications on the <strong>Applications</strong> → <strong>Enabled</strong> page, edit the dashboard configuration file.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisite</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as an Open Data Hub administrator.</p>\n</li>\n<li>\n<p>Open the dashboard configuration file:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhDashboardConfig</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhDashboardConfig</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click the <code>odh-dashboard-config</code> instance to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>In the <code>spec:notebookController</code> section, set the value of <code>enabled</code> to <code>false</code> to remove the <strong>Start basic workbench</strong> tile from the list of applications on the <strong>Applications</strong> → <strong>Enabled</strong> page.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong> to apply your changes and then click <strong>Reload</strong> to make sure that your changes are synced to the cluster.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>In the Open Data Hub dashboard, click <strong>Applications</strong> → <strong>Enabled</strong>.\nThe list of applications no longer includes the <strong>Start basic workbench</strong> tile.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"creating-project-scoped-resources_managing-odh\">Creating project-scoped resources</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>Users can access <em>global resources</em> in all Open Data Hub projects, but can access <em>project-scoped resources</em> within the specified project only.</p>\n</div>\n<div class=\"paragraph\">\n<p>Cluster administrators can create the following types of project-scoped resources in any Open Data Hub project:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Workbench images</p>\n</li>\n<li>\n<p>Hardware profiles</p>\n</li>\n<li>\n<p>Accelerator profiles</p>\n</li>\n<li>\n<p>Model-serving runtimes for KServe</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>All resource names must be unique within a project.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>A project member who is not a cluster administrator can create project-scoped resources for their project, as described in <a href=\"https://opendatahub.io/docs/working-on-data-science-projects/#creating-project-scoped-resources-for-your-project_projects\">Creating project-scoped resources for your project</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You can access the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>You have set the <code>disableProjectScoped</code> dashboard configuration option to <code>false</code>, as described in <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>Copy the YAML code to create the resource.</p>\n<div class=\"paragraph\">\n<p>You can get the YAML code from a trusted source, such as an existing resource, a Git repository, or documentation.</p>\n</div>\n<div class=\"paragraph\">\n<p>For example, you can copy the YAML code from an existing resource, as follows:</p>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>Search</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the appropriate value.</p>\n<div class=\"paragraph\">\n<p>To limit the search to global Open Data Hub resources only, select the <code>opendatahub</code> project.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Resources</strong> list, search for the relevant resource type, as follows:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For workbench images, search for <code>ImageStream</code>.</p>\n</li>\n<li>\n<p>For hardware profiles, search for <code>HardwareProfile</code>.</p>\n</li>\n<li>\n<p>For accelerator profiles, search for <code>AcceleratorProfile</code>.</p>\n</li>\n<li>\n<p>For serving runtimes, search for <code>Template</code>.\nFrom the resulting list, find the templates that have the <code>objects.kind</code> specification set to <code>ServingRuntime</code>.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Select a resource, and click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Copy the YAML content, and click <strong>Cancel</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the target project name. Note the spelling.</p>\n</li>\n<li>\n<p>From the toolbar, click the <strong>+</strong> icon to open the <strong>Import YAML</strong> page.</p>\n</li>\n<li>\n<p>Paste the relevant YAML content into the code area.</p>\n</li>\n<li>\n<p>Edit the <code>metadata.namespace</code> value to specify the name of the target project.</p>\n</li>\n<li>\n<p>If necessary, edit the <code>metadata.name</code> value to ensure that the resource name is unique within the specified project.</p>\n</li>\n<li>\n<p>Optional: Edit the resource name that is displayed in the Open Data Hub console, as follows:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For workbench images, edit the <code>metadata.annotations.opendatahub.io/notebook-image-name</code> value.</p>\n</li>\n<li>\n<p>For hardware profiles and accelerator profiles, edit the <code>spec.displayName</code> value.</p>\n</li>\n<li>\n<p>For serving runtimes, edit the <code>objects.metadata.annotations.openshift.io/display-name</code> value.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Create</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the Open Data Hub console as a regular user.</p>\n</li>\n<li>\n<p>Verify that the project-scoped resource is shown in the specified project only:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For workbench images, hardware profiles, and accelerator profiles, see <a href=\"https://opendatahub.io/docs/working-on-data-science-projects/#creating-a-project-workbench_projects\">Creating a workbench</a>.</p>\n</li>\n<li>\n<p>For serving runtimes, see <a href=\"https://opendatahub.io/docs/serving-models/#deploying-models-on-the-single-model-serving-platform_serving-large-models\">Deploying models on the single-model serving platform</a>.</p>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"allocating-additional-resources-to-data-science-users_managing-odh\">Allocating additional resources to Open Data Hub users</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>As a cluster administrator, you can allocate additional resources to a cluster to support compute-intensive data science work. This support includes increasing the number of nodes in the cluster and changing the cluster&#8217;s allocated machine pool.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about allocating additional resources to an OpenShift Container Platform cluster, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/machine_management/manually-scaling-machineset\">Manually scaling a compute machine set</a>.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"customizing-component-deployment-resources_managing-resources\">Customizing component deployment resources</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"overview-of-component-resource-customization_managing-resources\">Overview of component resource customization</h3>\n<div class=\"paragraph _abstract\">\n<p>You can customize deployment resources that are related to the Open Data Hub Operator, for example, CPU and memory limits and requests. For resource customizations to persist without being overwritten by the Operator, the <code>opendatahub.io/managed: true</code> annotation must not be present in the YAML file for the component deployment. This annotation is absent by default.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following table shows the deployment names for each component in the <code>opendatahub</code> namespace:</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<colgroup>\n<col style=\"width: 50%;\">\n<col style=\"width: 50%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">Component</th>\n<th class=\"tableblock halign-left valign-top\">Deployment names</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">CodeFlare</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">codeflare-operator-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">KServe</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"ulist\">\n<ul>\n<li>\n<p>kserve-controller-manager</p>\n</li>\n<li>\n<p>odh-model-controller</p>\n</li>\n</ul>\n</div></div></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">TrustyAI</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">trustyai-service-operator-controller-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Ray</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">kuberay-operator</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Kueue</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">kueue-controller-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Workbenches</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"ulist\">\n<ul>\n<li>\n<p>notebook-controller-deployment</p>\n</li>\n<li>\n<p>odh-notebook-controller-manager</p>\n</li>\n</ul>\n</div></div></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Dashboard</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">odh-dashboard</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Model serving</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"ulist\">\n<ul>\n<li>\n<p>modelmesh-controller</p>\n</li>\n<li>\n<p>odh-model-controller</p>\n</li>\n</ul>\n</div></div></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Model registry</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">model-registry-operator-controller-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Data science pipelines</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">data-science-pipelines-operator-controller-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Training Operator</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">kubeflow-training-operator</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div class=\"sect2\">\n<h3 id=\"customizing-component-resources_managing-resources\">Customizing component resources</h3>\n<div class=\"paragraph _abstract\">\n<p>You can customize component deployment resources by updating the <code>.spec.template.spec.containers.resources</code> section of the YAML file for the component deployment.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> drop-down list, select <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> column, click the name of the deployment for the component that you want to customize resources for.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>For more information about the deployment names for each component, see <a href=\"https://opendatahub.io/docs/managing-resources/#overview-of-component-resource-customization_managing-resources\">Overview of component resource customization</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>On the <strong>Deployment details</strong> page that appears, click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Find the <code>.spec.template.spec.containers.resources</code> section.</p>\n</li>\n<li>\n<p>Update the value of the resource that you want to customize. For example, to update the memory limit to 500Mi, make the following change:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>containers:\n        - resources:\n            limits:\n                cpu: '2'\n                memory: 500Mi\n            requests:\n                cpu: '1'\n                memory: 1Gi</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Reload</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Log in to Open Data Hub and verify that your resource changes apply.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"disabling-component-resource-customization_managing-resources\">Disabling component resource customization</h3>\n<div class=\"paragraph _abstract\">\n<p>You can disable customization of component deployment resources, and restore default  values, by adding the <code>opendatahub.io/managed: true</code> annotation to the YAML file for the component deployment.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Manually removing or setting the <code>opendatahub.io/managed: true</code> annotation to <code>false</code> after manually adding it to the YAML file for a component deployment might cause unexpected cluster issues.</p>\n</div>\n<div class=\"paragraph\">\n<p>To remove the annotation from a deployment, use the steps described in <a href=\"https://opendatahub.io/docs/managing-resources/#reenabling-component-resource-customization_managing-resources\">Re-enabling component resource customization</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> drop-down list, select <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> column, click the name of the deployment for the component to which you want to add the annotation.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>For more information about the deployment names for each component, see <a href=\"https://opendatahub.io/docs/managing-resources/#overview-of-component-resource-customization_managing-resources\">Overview of component resource customization</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>On the <strong>Deployment details</strong> page that appears, click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Find the <code>metadata.annotations:</code> section.</p>\n</li>\n<li>\n<p>Add the <code>opendatahub.io/managed: true</code> annotation.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>metadata:\n  annotations:\n     opendatahub.io/managed: true</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Reload</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <code>opendatahub.io/managed: true</code> annotation appears in the YAML file for the component deployment.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"reenabling-component-resource-customization_managing-resources\">Re-enabling component resource customization</h3>\n<div class=\"paragraph _abstract\">\n<p>You can re-enable customization of component deployment resources after manually disabling it.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Manually removing or setting the <code>opendatahub.io/managed:</code> annotation to <code>false</code> after adding it to the YAML file for a component deployment might cause unexpected cluster issues.</p>\n</div>\n<div class=\"paragraph\">\n<p>To remove the annotation from a deployment, use the following steps to delete the deployment. The controller pod for the deployment will automatically redeploy with the default settings.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> drop-down list, select <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> column, click the name of the deployment for the component for which you want to remove the annotation.</p>\n</li>\n<li>\n<p>Click the Options menu <span class=\"image\"><img src=\"/static/docs/images/osd-ellipsis.png\" alt=\"Options menu\"></span>.</p>\n</li>\n<li>\n<p>Click <strong>Delete Deployment</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The controller pod for the deployment automatically redeploys with the default settings.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_enabling_accelerators\">Enabling accelerators</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"enabling-nvidia-gpus_managing-odh\">Enabling NVIDIA GPUs</h3>\n<div class=\"paragraph _abstract\">\n<p>Before you can use NVIDIA GPUs in Open Data Hub, you must install the NVIDIA GPU Operator.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have the <code>cluster-admin</code> role in your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have installed an NVIDIA GPU and confirmed that it is detected in your environment.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>To enable GPU support on an OpenShift cluster, follow the instructions here: <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>After you install the Node Feature Discovery (NFD) Operator, you must create an instance of NodeFeatureDiscovery. In addition, after you install the NVIDIA GPU Operator, you must create a ClusterPolicy and populate it with default values.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Delete the <strong>migration-gpu-status</strong> ConfigMap.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform web console, switch to the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>Set the <strong>Project</strong> to <strong>All Projects</strong> or <strong>redhat-ods-applications</strong> to ensure you can see the appropriate ConfigMap.</p>\n</li>\n<li>\n<p>Search for the <strong>migration-gpu-status</strong> ConfigMap.</p>\n</li>\n<li>\n<p>Click the action menu (&#8942;) and select <strong>Delete ConfigMap</strong> from the list.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete ConfigMap</strong> dialog appears.</p>\n</div>\n</li>\n<li>\n<p>Inspect the dialog and confirm that you are deleting the correct ConfigMap.</p>\n</li>\n<li>\n<p>Click <strong>Delete</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Restart the dashboard replicaset.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform web console, switch to the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>Click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>Set the <strong>Project</strong> to <strong>All Projects</strong> or <strong>redhat-ods-applications</strong> to ensure you can see the appropriate deployment.</p>\n</li>\n<li>\n<p>Search for the <strong>rhods-dashboard</strong> deployment.</p>\n</li>\n<li>\n<p>Click the action menu (&#8942;)  and select <strong>Restart Rollout</strong> from the list.</p>\n</li>\n<li>\n<p>Wait until the <strong>Status</strong> column indicates that all pods in the rollout have fully restarted.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The reset <strong>migration-gpu-status</strong> instance is present on the <strong>Instances</strong> tab on the <code>AcceleratorProfile</code> custom resource definition (CRD) details page.</p>\n</li>\n<li>\n<p>From the <strong>Administrator</strong> perspective, go to the <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> page. Confirm that the following Operators appear:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>NVIDIA GPU</p>\n</li>\n<li>\n<p>Node Feature Discovery (NFD)</p>\n</li>\n<li>\n<p>Kernel Module Management (KMM)</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>The GPU is correctly detected a few minutes after full installation of the Node Feature Discovery (NFD) and NVIDIA GPU Operators. The OpenShift Container Platform command line interface (CLI) displays the appropriate output for the GPU worker node. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code># Expected output when the GPU is detected properly\noc describe node &lt;node name&gt;\n...\nCapacity:\n  cpu:                4\n  ephemeral-storage:  313981932Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16076568Ki\n  nvidia.com/gpu:     1\n  pods:               250\nAllocatable:\n  cpu:                3920m\n  ephemeral-storage:  288292006229\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             12828440Ki\n  nvidia.com/gpu:     1\n  pods:               250</code></pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>After installing the NVIDIA GPU Operator, create a hardware profile as described in <a href=\"https://opendatahub.io/docs/working-with-accelerators/\">Working with accelerators</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>+</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>By default, hardware profiles are hidden in the dashboard navigation menu and user interface, while accelerator profiles remain visible. In addition, user interface components associated with the deprecated accelerator profiles functionality are still displayed. To show the <strong>Settings &#8594; Hardware profiles</strong> option in the dashboard navigation menu, and the user interface components associated with hardware profiles, set the <code>disableHardwareProfiles</code> value to <code>false</code> in the <code>OdhDashboardConfig</code> custom resource (CR) in OpenShift Container Platform.\nFor more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"intel-gaudi-ai-accelerator-integration_managing-odh\">Intel Gaudi AI Accelerator integration</h3>\n<div class=\"paragraph _abstract\">\n<p>To accelerate your high-performance deep learning models, you can integrate Intel Gaudi AI accelerators into Open Data Hub. This integration enables your data scientists to use Gaudi libraries and software associated with Intel Gaudi AI accelerators through custom-configured workbench instances.</p>\n</div>\n<div class=\"paragraph\">\n<p>Intel Gaudi AI accelerators offer optimized performance for deep learning workloads, with the latest Gaudi 3 devices providing significant improvements in training speed and energy efficiency. These accelerators are suitable for enterprises running machine learning and AI applications on Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Before you can enable Intel Gaudi AI accelerators in Open Data Hub, you must complete the following steps:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Install the latest version of the Intel Gaudi AI Accelerator Operator from OperatorHub.</p>\n</li>\n<li>\n<p>Create and configure a custom workbench image for Intel Gaudi AI accelerators. A prebuilt workbench image for Gaudi accelerators is not included in Open Data Hub.</p>\n</li>\n<li>\n<p>Manually define and configure an accelerator profile or a hardware profile for each Intel Gaudi AI device in your environment.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>By default, hardware profiles are hidden in the dashboard navigation menu and user interface, while accelerator profiles remain visible. In addition, user interface components associated with the deprecated accelerator profiles functionality are still displayed. To show the <strong>Settings &#8594; Hardware profiles</strong> option in the dashboard navigation menu, and the user interface components associated with hardware profiles, set the <code>disableHardwareProfiles</code> value to <code>false</code> in the <code>OdhDashboardConfig</code> custom resource (CR) in OpenShift Container Platform.\nFor more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>Red&#160;Hat supports Intel Gaudi devices up to Intel Gaudi 3. The Intel Gaudi 3 accelerators, in particular, offer the following benefits:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Improved training throughput: Reduce the time required to train large models by using advanced tensor processing cores and increased memory bandwidth.</p>\n</li>\n<li>\n<p>Energy efficiency: Lower power consumption while maintaining high performance, reducing operational costs for large-scale deployments.</p>\n</li>\n<li>\n<p>Scalable architecture: Scale across multiple nodes for distributed training configurations.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>Your OpenShift platform must support EC2 DL1 instances to use Intel Gaudi AI accelerators in an Amazon EC2 DL1 instance. You can use Intel Gaudi AI accelerators in workbench instances or model serving after you enable the accelerators, create a custom workbench image, and configure the accelerator profile or the hardware profile.</p>\n</div>\n<div class=\"paragraph\">\n<p>To identify the Intel Gaudi AI accelerators present in your deployment, use the <code>lspci</code> utility. For more information, see <a href=\"https://linux.die.net/man/8/lspci\">lspci(8) - Linux man page</a>.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>The presence of Intel Gaudi AI accelerators in your deployment, as indicated by the <code>lspci</code> utility, does not guarantee that the devices are ready to use. You must ensure that all installation and configuration steps are completed successfully.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://linux.die.net/man/8/lspci\">lspci(8) - Linux man page</a></p>\n</li>\n<li>\n<p><a href=\"https://aws.amazon.com/ec2/instance-types/dl1/\">Amazon EC2 DL1 Instances</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.habana.ai/en/latest/Installation_Guide/Additional_Installation/OpenShift_Installation/index.html\">Intel Gaudi AI Operator OpenShift installation</a></p>\n</li>\n<li>\n<p><a href=\"https://access.redhat.com/solutions/4870701\">What version of the Kubernetes API is included with each OpenShift 4.x release?</a></p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"enabling-intel-gaudi-ai-accelerators_managing-odh\">Enabling Intel Gaudi AI accelerators</h4>\n<div class=\"paragraph _abstract\">\n<p>Before you can use Intel Gaudi AI accelerators in Open Data Hub, you must install the required dependencies, deploy the Intel Gaudi AI Accelerator Operator, and configure the environment.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have the <code>cluster-admin</code> role in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have installed your Intel Gaudi accelerator and confirmed that it is detected in your environment.</p>\n</li>\n<li>\n<p>Your OpenShift environment supports EC2 DL1 instances if you are running on Amazon Web Services (AWS).</p>\n</li>\n<li>\n<p>You have installed the OpenShift command-line interface (CLI).</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Install the latest version of the Intel Gaudi AI Accelerator Operator, as described in <a href=\"https://docs.habana.ai/en/latest/Installation_Guide/Additional_Installation/OpenShift_Installation/index.html\">Intel Gaudi AI Operator OpenShift installation</a>.</p>\n</li>\n<li>\n<p>By default, OpenShift Container Platform sets a per-pod PID limit of 4096. If your workload requires more processing power, such as when you use multiple Gaudi accelerators or when using vLLM with Ray, you must manually increase the per-pod PID limit to avoid <code>Resource temporarily unavailable</code> errors. These errors occur due to PID exhaustion. Red&#160;Hat recommends setting this limit to 32768, although values over 20000 are sufficient.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Run the following command to label the node:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc label node &lt;node_name&gt; custom-kubelet=set-pod-pid-limit-kubelet</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Optional: To prevent workload distribution on the affected node, you can mark the node as unschedulable and then drain it in preparation for maintenance. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/nodes/working-with-nodes#nodes-nodes-working-evacuating_nodes-nodes-working\">Understanding how to evacuate pods on nodes</a>.</p>\n</li>\n<li>\n<p>Create a <code>custom-kubelet-pidslimit.yaml</code> KubeletConfig resource file:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc create -f custom-kubelet-pidslimit.yaml</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Populate the file with the following YAML code. Set the <code>PodPidsLimit</code> value to 32768:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-YAML\" data-lang=\"YAML\">apiVersion: machineconfiguration.openshift.io/v1\nkind: KubeletConfig\nmetadata:\n  name: custom-kubelet-pidslimit\nspec:\n  kubeletConfig:\n    PodPidsLimit: 32768\n  machineConfigPoolSelector:\n    matchLabels:\n      custom-kubelet: set-pod-pid-limit-kubelet</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Apply the configuration:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc apply -f custom-kubelet-pidslimit.yaml</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>This operation causes the node to reboot. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/nodes/working-with-nodes#nodes-nodes-rebooting\">Understanding node rebooting</a>.</p>\n</div>\n</li>\n<li>\n<p>Optional: If you previously marked the node as unschedulable, you can allow scheduling again after the node reboots.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Create a custom workbench image for Intel Gaudi AI accelerators, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#creating-custom-workbench-images\">Creating custom workbench images</a>.</p>\n</li>\n<li>\n<p>After installing the Intel Gaudi AI Accelerator Operator, create an accelerator profile, as described in <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-accelerator-profiles_accelerators\">Working with accelerator profiles</a>.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>By default, hardware profiles are hidden in the dashboard navigation menu and user interface, while accelerator profiles remain visible. In addition, user interface components associated with the deprecated accelerator profiles functionality are still displayed. To show the <strong>Settings &#8594; Hardware profiles</strong> option in the dashboard navigation menu, and the user interface components associated with hardware profiles, set the <code>disableHardwareProfiles</code> value to <code>false</code> in the <code>OdhDashboardConfig</code> custom resource (CR) in OpenShift Container Platform.\nFor more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>From the <strong>Administrator</strong> perspective, go to the <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> page. Confirm that the following Operators appear:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Intel Gaudi AI Accelerator</p>\n</li>\n<li>\n<p>Node Feature Discovery (NFD)</p>\n</li>\n<li>\n<p>Kernel Module Management (KMM)</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"amd-gpu-integration_managing-odh\">AMD GPU Integration</h3>\n<div class=\"paragraph\">\n<p>You can use AMD GPUs with Open Data Hub to accelerate AI and machine learning (ML) workloads. AMD GPUs provide high-performance compute capabilities, allowing users to process large data sets, train deep neural networks, and perform complex inference tasks more efficiently.</p>\n</div>\n<div class=\"paragraph\">\n<p>Integrating AMD GPUs with Open Data Hub involves the following components:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>ROCm workbench images</strong>:\nUse the ROCm workbench images to streamline AI/ML workflows on AMD GPUs. These images include libraries and frameworks optimized with the AMD ROCm platform, enabling high-performance workloads for PyTorch and TensorFlow. The pre-configured images reduce setup time and provide an optimized environment for GPU-accelerated development and experimentation.</p>\n</li>\n<li>\n<p><strong>AMD GPU Operator</strong>:\nThe AMD GPU Operator simplifies GPU integration by automating driver installation, device plugin setup, and node labeling for GPU resource management. It ensures compatibility between OpenShift and AMD hardware while enabling scaling of GPU-enabled workloads.</p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"verifying-amd-gpu-availability-on-your-cluster_managing-odh\">Verifying AMD GPU availability on your cluster</h4>\n<div class=\"paragraph _abstract\">\n<p>Before you proceed with the AMD GPU Operator installation process, you can verify the presence of an AMD GPU device on a node within your OpenShift Container Platform cluster. You can use commands such as <code>lspci</code> or <code>oc</code> to confirm hardware and resource availability.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have administrative access to the OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have a running OpenShift Container Platform cluster with a node equipped with an AMD GPU.</p>\n</li>\n<li>\n<p>You have access to the OpenShift CLI (<code>oc</code>) and terminal access to the node.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Use the OpenShift CLI to verify if GPU resources are allocatable:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>List all nodes in the cluster to identify the node with an AMD GPU:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>oc get nodes</pre>\n</div>\n</div>\n</li>\n<li>\n<p>Note the name of the node where you expect the AMD GPU to be present.</p>\n</li>\n<li>\n<p>Describe the node to check its resource allocation:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>oc describe node &lt;node_name&gt;</pre>\n</div>\n</div>\n</li>\n<li>\n<p>In the output, locate the <strong>Capacity</strong> and <strong>Allocatable</strong> sections and confirm that <code>amd.com/gpu</code> is listed. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>Capacity:\n  amd.com/gpu:  1\nAllocatable:\n  amd.com/gpu:  1</pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Check for the AMD GPU device using the <code>lspci</code> command:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Log in to the node:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>oc debug node/&lt;node_name&gt;\nchroot /host</pre>\n</div>\n</div>\n</li>\n<li>\n<p>Run the <code>lspci</code> command and search for the supported AMD device in your deployment. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>lspci | grep -E \"MI210|MI250|MI300\"</pre>\n</div>\n</div>\n</li>\n<li>\n<p>Verify that the output includes one of the AMD GPU models. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>03:00.0 Display controller: Advanced Micro Devices, Inc. [AMD] Instinct MI210</pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: Use the <code>rocminfo</code> command if the ROCm stack is installed on the node:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>rocminfo</pre>\n</div>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Confirm that the ROCm tool outputs details about the AMD GPU, such as compute units, memory, and driver status.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <code>oc describe node &lt;node_name&gt;</code> command lists <code>amd.com/gpu</code> under <strong>Capacity</strong> and <strong>Allocatable</strong>.</p>\n</li>\n<li>\n<p>The <code>lspci</code> command output identifies an AMD GPU as a PCI device matching one of the specified models (for example, MI210, MI250, MI300).</p>\n</li>\n<li>\n<p>Optional: The <code>rocminfo</code> tool provides detailed GPU information, confirming driver and hardware configuration.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://github.com/ROCm/gpu-operator\">AMD GPU Operator GitHub Repository</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"enabling-amd-gpus_managing-odh\">Enabling AMD GPUs</h4>\n<div class=\"paragraph _abstract\">\n<p>Before you can use AMD GPUs in Open Data Hub, you must install the required dependencies, deploy the AMD GPU Operator, and configure the environment.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have the <code>cluster-admin</code> role in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have installed your AMD GPU and confirmed that it is detected in your environment.</p>\n</li>\n<li>\n<p>Your OpenShift Container Platform environment supports EC2 DL1 instances if you are running on Amazon Web Services (AWS).</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Install the latest version of the AMD GPU Operator, as described in <a href=\"https://instinct.docs.amd.com/projects/gpu-operator/en/latest/installation/openshift-olm.html\">Install AMD GPU Operator on OpenShift</a>.</p>\n</li>\n<li>\n<p>After installing the AMD GPU Operator, configure the AMD drivers required by the Operator as described in the documentation: <a href=\"https://instinct.docs.amd.com/projects/gpu-operator/en/latest/drivers/installation.html\">Configure AMD drivers for the GPU Operator</a>.</p>\n</li>\n</ol>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Alternatively, you can install the AMD GPU Operator from the Red&#160;Hat Catalog. For more information, see <a href=\"https://catalog.redhat.com/software/container-stacks/detail/6722781e65e61b6d4caccef8?rh-tabs-2b5yslu8z=rh-tab-v8le4ijlp\">Install AMD GPU Operator from Red Hat Catalog</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>After installing the AMD GPU Operator, create an accelerator profile, as described in <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-accelerator-profiles_accelerators\">Working with accelerator profiles</a>.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>By default, hardware profiles are hidden in the dashboard navigation menu and user interface, while accelerator profiles remain visible. In addition, user interface components associated with the deprecated accelerator profiles functionality are still displayed. To show the <strong>Settings &#8594; Hardware profiles</strong> option in the dashboard navigation menu, and the user interface components associated with hardware profiles, set the <code>disableHardwareProfiles</code> value to <code>false</code> in the <code>OdhDashboardConfig</code> custom resource (CR) in OpenShift Container Platform.\nFor more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>From the <strong>Administrator</strong> perspective, go to the <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> page. Confirm that the following Operators appear:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>AMD GPU Operator</p>\n</li>\n<li>\n<p>Node Feature Discovery (NFD)</p>\n</li>\n<li>\n<p>Kernel Module Management (KMM)</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Ensure that you follow all the steps for proper driver installation and configuration. Incorrect installation or configuration may prevent the AMD GPUs from being recognized or functioning properly.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-distributed-workloads_managing-odh\">Managing distributed workloads</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>In Open Data Hub, cluster administrators create Kueue resources to configure quota management for distributed workloads.\nCluster administrators can optionally configure the CodeFlare Operator if they want to change its default behavior.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"overview-of-kueue-resources_managing-odh\">Overview of Kueue resources</h3>\n<div class=\"paragraph _abstract\">\n<p>Cluster administrators can configure Kueue objects (such as resource flavors, cluster queues, and local queues) to manage distributed workload resources across multiple nodes in an OpenShift cluster.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_resource_flavor\">Resource flavor</h4>\n<div class=\"paragraph\">\n<p>The Kueue <code>ResourceFlavor</code> object describes the resource variations that are available in a cluster.</p>\n</div>\n<div class=\"paragraph\">\n<p>Resources in a cluster can be <em>homogenous</em> or <em>heterogeneous</em>:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Homogeneous resources are identical across the cluster: same node type, CPUs, memory, accelerators, and so on.</p>\n</li>\n<li>\n<p>Heterogeneous resources have variations across the cluster.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>If a cluster has homogeneous resources, or if it is not necessary to manage separate quotas for different flavors of a resource, a cluster administrator can create an empty <code>ResourceFlavor</code> object named <code>default-flavor</code>, without any labels or taints, as follows:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Empty Kueue resource flavor for homegeneous resources</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: default-flavor</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>If a cluster has heterogeneous resources, cluster administrators can define a different resource flavor for each variation in the resources available.\nExample variations include different CPUs, different memory, or different accelerators.\nIf a cluster has multiple types of accelerator, cluster administrators can set up a resource flavor for each accelerator type.\nCluster administrators can then associate the resource flavors with cluster nodes by using labels, taints, and tolerations, as shown in the following example.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Example Kueue resource flavor for heterogeneous resources</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"spot\"\nspec:\n  nodeLabels:\n    instance-type: spot\n  nodeTaints:\n  - effect: NoSchedule\n    key: spot\n    value: \"true\"\n  tolerations:\n  - key: \"spot-taint\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Make sure that each resource flavor has the correct label selectors and taint tolerations so that workloads run on the expected nodes.</p>\n</div>\n<div class=\"paragraph\">\n<p>See the example configurations provided in <a href=\"https://opendatahub.io/docs/managing-odh/#ref-example-kueue-resource-configurations_managing-odh\">Example Kueue resource configurations</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about configuring resource flavors, see <a href=\"https://kueue.sigs.k8s.io/docs/concepts/resource_flavor/\">Resource Flavor</a> in the Kueue documentation.</p>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_cluster_queue\">Cluster queue</h4>\n<div class=\"paragraph\">\n<p>The Kueue <code>ClusterQueue</code> object manages a pool of cluster resources such as pods, CPUs, memory, and accelerators.\nA cluster can have multiple cluster queues, and each cluster queue can reference multiple resource flavors.</p>\n</div>\n<div class=\"paragraph\">\n<p>Cluster administrators can configure a cluster queue to define the resource flavors that the queue manages, and assign a quota for each resource in each resource flavor.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following example configures a cluster queue to assign a quota of 9 CPUs, 36 GiB memory, 5 pods, and 5 NVIDIA GPUs.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Example cluster queue</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"cluster-queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"pods\", \"nvidia.com/gpu\"]\n    flavors:\n    - name: \"default-flavor\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 9\n      - name: \"memory\"\n        nominalQuota: 36Gi\n      - name: \"pods\"\n        nominalQuota: 5\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: '5'</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>A cluster administrator should notify the consumers of a cluster queue about the quota limits for that cluster queue.\nThe cluster queue starts a distributed workload only if the total required resources are within these quota limits.\nIf the sum of the requests for a resource in a distributed workload is greater than the specified quota for that resource in the cluster queue, the cluster queue does not admit the distributed workload.</p>\n</div>\n<div class=\"paragraph\">\n<p>See the example configurations provided in <a href=\"https://opendatahub.io/docs/managing-odh/#ref-example-kueue-resource-configurations_managing-odh\">Example Kueue resource configurations</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about configuring cluster queues, see <a href=\"https://kueue.sigs.k8s.io/docs/concepts/cluster_queue/\">Cluster Queue</a> in the Kueue documentation.</p>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_local_queue\">Local queue</h4>\n<div class=\"paragraph\">\n<p>The Kueue <code>LocalQueue</code> object groups closely related distributed workloads in a project.\nCluster administrators can configure local queues to specify the project name and the associated cluster queue.\nEach local queue then grants access to the resources that its specified cluster queue manages.\nA cluster administrator can optionally define one local queue in a project as the default local queue for that project.</p>\n</div>\n<div class=\"paragraph\">\n<p>When configuring a distributed workload, the user specifies the local queue name.\nIf a cluster administrator configured a default local queue, the user can omit the local queue specification from the distributed workload code.</p>\n</div>\n<div class=\"paragraph\">\n<p>Kueue allocates the resources for a distributed workload from the cluster queue that is associated with the local queue, if the total requested resources are within the quota limits specified in that cluster queue.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following example configures a local queue called <code>team-a-queue</code> for the <code>team-a</code> project, and specifies <code>cluster-queue</code> as the associated cluster queue.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Example local queue</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: LocalQueue\nmetadata:\n  namespace: team-a\n  name: team-a-queue\n  annotations:\n    kueue.x-k8s.io/default-queue: \"true\"\nspec:\n  clusterQueue: cluster-queue</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>In this example, the <code>kueue.x-k8s.io/default-queue: \"true\"</code> annotation defines this local queue as the default local queue for the <code>team-a</code> project.\nIf a user submits a distributed workload in the <code>team-a</code> project and that distributed workload does not specify a local queue in the cluster configuration, Kueue automatically routes the distributed workload to the <code>team-a-queue</code> local queue.\nThe distributed workload can then access the resources that the <code>cluster-queue</code> cluster queue manages.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about configuring local queues, see <a href=\"https://kueue.sigs.k8s.io/docs/concepts/local_queue/\">Local Queue</a> in the Kueue documentation.</p>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"ref-example-kueue-resource-configurations_managing-odh\">Example Kueue resource configurations</h3>\n<div class=\"paragraph _abstract\">\n<p>These examples show how to configure Kueue resource flavors and cluster queues.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_nvidia_gpus_without_shared_cohort\">NVIDIA GPUs without shared cohort</h4>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_rtx_a400_gpu_resource_flavor\">NVIDIA RTX A400 GPU resource flavor</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"A400-node\"\nspec:\n  nodeLabels:\n    instance-type: nvidia-a400-node\n  tolerations:\n  - key: \"HasGPU\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_rtx_a1000_gpu_resource_flavor\">NVIDIA RTX A1000 GPU resource flavor</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"A1000-node\"\nspec:\n  nodeLabels:\n    instance-type: nvidia-a1000-node\n  tolerations:\n  - key: \"HasGPU\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_rtx_a400_gpu_cluster_queue\">NVIDIA RTX A400 GPU cluster queue</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"A400-queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]\n    - name: \"A400-node\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 16\n      - name: \"memory\"\n        nominalQuota: 64Gi\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: 2</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_rtx_a1000_gpu_cluster_queue\">NVIDIA RTX A1000 GPU cluster queue</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"A1000-queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]\n    flavors:\n    - name: \"A1000-node\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 16\n      - name: \"memory\"\n        nominalQuota: 64Gi\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: 2</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_nvidia_gpus_and_amd_gpus_without_shared_cohort\">NVIDIA GPUs and AMD GPUs without shared cohort</h4>\n<div class=\"sect4\">\n<h5 id=\"_amd_gpu_resource_flavor\">AMD GPU resource flavor</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"amd-node\"\nspec:\n  nodeLabels:\n    instance-type: amd-node\n  tolerations:\n  - key: \"HasGPU\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_gpu_resource_flavor\">NVIDIA GPU resource flavor</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"nvidia-node\"\nspec:\n  nodeLabels:\n    instance-type: nvidia-node\n  tolerations:\n  - key: \"HasGPU\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_amd_gpu_cluster_queue\">AMD GPU cluster queue</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"team-a-amd-queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"amd.com/gpu\"]\n    - name: \"amd-node\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 16\n      - name: \"memory\"\n        nominalQuota: 64Gi\n      - name: \"amd.com/gpu\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_gpu_cluster_queue\">NVIDIA GPU cluster queue</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"team-a-nvidia-queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]\n    flavors:\n    - name: \"nvidia-node\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 16\n      - name: \"memory\"\n        nominalQuota: 64Gi\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: 2</code></pre>\n</div>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://kueue.sigs.k8s.io/docs/concepts/resource_flavor/\">Resource Flavor</a> in the Kueue documentation</p>\n</li>\n<li>\n<p><a href=\"https://kueue.sigs.k8s.io/docs/concepts/cluster_queue/\">Cluster Queue</a> in the Kueue documentation</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</h3>\n<div class=\"paragraph _abstract\">\n<p>Configure quotas for distributed workloads on a cluster, so that you can share resources between several data science projects.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform with the <code>cluster-admin</code> role.</p>\n</li>\n<li>\n<p>You have installed the required distributed workloads components as described in <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-distributed-workloads-components_install\">Installing the distributed workloads components</a>.</p>\n</li>\n<li>\n<p>You have created a data science project that contains a workbench, and the workbench is running a default workbench image that contains the CodeFlare SDK, for example, the <strong>Standard Data Science</strong> workbench. For information about how to create a project, see <a href=\"https://opendatahub.io/docs/working-on-data-science-projects/#creating-a-data-science-project_projects\">Creating a data science project</a>.</p>\n</li>\n<li>\n<p>You have sufficient resources. In addition to the base Open Data Hub resources, you need 1.6 vCPU and 2 GiB memory to deploy the distributed workloads infrastructure.</p>\n</li>\n<li>\n<p>The resources are physically available in the cluster.\nFor more information about Kueue resources, see <a href=\"https://opendatahub.io/docs/managing-odh/#overview-of-kueue-resources_managing-odh\">Overview of Kueue resources</a>.</p>\n</li>\n<li>\n<p>If you want to use graphics processing units (GPUs), you have enabled GPU support.\nThis process includes installing the Node Feature Discovery Operator and the relevant GPU Operator.\nFor more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation for NVIDIA GPUs and <a href=\"https://instinct.docs.amd.com/projects/gpu-operator/en/latest/installation/openshift-olm.html\" target=\"_blank\" rel=\"noopener\">AMD GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the AMD documentation for AMD GPUs.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In a terminal window, if you are not already logged in to your OpenShift cluster as a cluster administrator, log in to the OpenShift CLI as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ oc login <em>&lt;openshift_cluster_url&gt;</em> -u <em>&lt;admin_username&gt;</em> -p <em>&lt;password&gt;</em></code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Create an empty Kueue resource flavor, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Create a file called <code>default_flavor.yaml</code> and populate it with the following content:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Empty Kueue resource flavor</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: default-flavor</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Apply the configuration to create the <code>default-flavor</code> object:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc apply -f default_flavor.yaml</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Create a cluster queue to manage the empty Kueue resource flavor, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Create a file called <code>cluster_queue.yaml</code> and populate it with the following content:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example cluster queue</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"cluster-queue\"\nspec:\n  namespaceSelector: {}  # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]\n    flavors:\n    - name: \"default-flavor\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 9\n      - name: \"memory\"\n        nominalQuota: 36Gi\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: 5</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Replace the example quota values (9 CPUs, 36 GiB memory, and 5 NVIDIA GPUs) with the appropriate values for your cluster queue.\nIf you use AMD GPUs, replace <code>nvidia.com/gpu</code> with <code>amd.com/gpu</code> in the example code.\nThe cluster queue will start a distributed workload only if the total required resources are within these quota limits.</p>\n<div class=\"paragraph\">\n<p>You must specify a quota for each resource that the user can request, even if the requested value is 0, by updating the <code>spec.resourceGroups</code> section as follows:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Include the resource name in the <code>coveredResources</code> list.</p>\n</li>\n<li>\n<p>Specify the resource <code>name</code> and <code>nominalQuota</code> in the <code>flavors.resources</code> section, even if the <code>nominalQuota</code> value is 0.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Apply the configuration to create the <code>cluster-queue</code> object:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc apply -f cluster_queue.yaml</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Create a local queue that points to your cluster queue, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Create a file called <code>local_queue.yaml</code> and populate it with the following content:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example local queue</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: LocalQueue\nmetadata:\n  namespace: test\n  name: local-queue-test\n  annotations:\n    kueue.x-k8s.io/default-queue: 'true'\nspec:\n  clusterQueue: cluster-queue</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The <code>kueue.x-k8s.io/default-queue: 'true'</code> annotation defines this queue as the default queue.\nDistributed workloads are submitted to this queue if no <code>local_queue</code> value is specified in the <code>ClusterConfiguration</code> section of the data science pipeline or Jupyter notebook or Microsoft Visual Studio Code file.</p>\n</div>\n</li>\n<li>\n<p>Update the <code>namespace</code> value to specify the same namespace as in the <code>ClusterConfiguration</code> section that creates the Ray cluster.</p>\n</li>\n<li>\n<p>Optional: Update the <code>name</code> value accordingly.</p>\n</li>\n<li>\n<p>Apply the configuration to create the local-queue object:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc apply -f local_queue.yaml</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The cluster queue allocates the resources to run distributed workloads in the local queue.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>Check the status of the local queue in a project, as follows:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ oc get -n <em>&lt;project-name&gt;</em> localqueues</code></pre>\n</div>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://kueue.sigs.k8s.io/docs/concepts/\">Kueue documentation</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"enforcing-local-queues_managing-odh\">Enforcing the use of local queues</h3>\n<div class=\"paragraph _abstract\">\n<p>Efficient workload orchestration in OpenShift Container Platform clusters relies on strict management of resources and queues.\nCluster administrators can use the Validating Admission Policy feature to enforce the mandatory labeling of RayCluster and PyTorchJob resources with Local Queue identifiers.\nThis labeling ensures that workloads are properly categorized and routed based on queue management policies, which prevents resource contention and enhances operational efficiency.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>The Validating Admission Policy feature is available in OpenShift Container Platform v4.17 or later.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"sect3\">\n<h4 id=\"enforcing-lqlabel-all_managing-odh\">Enforcing the local-queue labeling policy for all projects</h4>\n<div class=\"paragraph _abstract\">\n<p>When the local-queue labeling policy is enforced, Ray clusters and PyTorchJobs are created <em>only if</em> they are configured to use a local queue, and the Ray cluster and PyTorchJob resources are then managed by Kueue.</p>\n</div>\n<div class=\"paragraph\">\n<p>The local-queue labeling policy is enforced for all projects by default. The Validating Admission Policy is enforced on both RayCluster and PyTorchJob resources.</p>\n</div>\n<div class=\"paragraph\">\n<p>If the original <code>ValidatingAdmissionPolicyBinding</code> resource is edited, you can use either of the following methods to undo the edits and enforce the policy for all projects:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Delete the <code>kueue-validating-admission-policy-binding</code> resource.\nThe resource is automatically re-created with the default values.\nNo other action is required.</p>\n</li>\n<li>\n<p>Edit the existing resource as described in this procedure.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform with the <code>cluster-admin</code> role.</p>\n</li>\n<li>\n<p>You have installed the required distributed workloads components as described in <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-distributed-workloads-components_install\">Installing the distributed workloads components</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, open the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select <strong>All Projects</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Home</strong> &#8594; <strong>Search</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Resources</strong> list, search for <strong>ValidatingAdmissionPolicyBinding</strong>.</p>\n</li>\n<li>\n<p>Click the <code>kueue-validating-admission-policy-binding</code> entry to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab to show the binding specifications.</p>\n</li>\n<li>\n<p>Ensure that the following fields are set to the specified values:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example to enforce local-queue labeling for all projects</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">kind: ValidatingAdmissionPolicyBinding\napiVersion: admissionregistration.k8s.io/v1\nmetadata:\n  name: kueue-validating-admission-policy-binding\n  uid: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  resourceVersion: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  generation: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  creationTimestamp: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: kueue\n  managedFields:\nspec:\n  policyName: kueue-validating-admission-policy\n  matchResources:\n    namespaceSelector: {}\n    objectSelector: {}\n    matchPolicy: Equivalent\n  validationActions:\n    - Deny</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>If you made any changes, click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>To verify that the local-queue labeling policy is enforced for Ray clusters:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Create a project.</p>\n</li>\n<li>\n<p>Complete the following steps in the new project:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Before you configure a local queue, try to create a Ray cluster.</p>\n<div class=\"paragraph\">\n<p>The Validating Admission Policy rejects the request, and the Ray cluster is not created, because no local queue is configured.</p>\n</div>\n</li>\n<li>\n<p>Create a local queue without the <code>default-queue</code> annotation.</p>\n</li>\n<li>\n<p>Try to create a Ray cluster, and specify the local-queue name in the <code>local_queue</code> field.</p>\n<div class=\"paragraph\">\n<p>The Validating Admission Policy approves the request, and the Ray cluster is created.</p>\n</div>\n</li>\n<li>\n<p>Try to create a Ray cluster without specifying a value in the <code>local_queue</code> field.</p>\n<div class=\"paragraph\">\n<p>The Validating Admission Policy rejects the request, and the Ray cluster is not created, because a local queue is not specified and a default local queue is not configured.</p>\n</div>\n</li>\n<li>\n<p>Edit the local queue to add the <code>kueue.x-k8s.io/default-queue: \"true\"</code> annotation, which configures that queue as the default local queue.</p>\n</li>\n<li>\n<p>Try to create a Ray cluster without specifying a value in the <code>local_queue</code> field.</p>\n<div class=\"paragraph\">\n<p>The Validating Admission Policy approves the request, and the Ray cluster is created even though a local queue is not specified, because the default local queue is used.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>To verify that the local-queue labeling policy is enforced for PyTorchJobs:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Complete the following steps in the new project:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Before you configure a local queue, try to create a PyTorchJob.</p>\n<div class=\"paragraph\">\n<p>The Validating Admission Policy rejects the request, and the PyTorchJob is not created, because no local queue is configured.</p>\n</div>\n</li>\n<li>\n<p>Create a local queue.</p>\n</li>\n<li>\n<p>Try to create a PyTorchJob and add the <code>kueue.x-k8s.io/queue-name: &lt;local-queue-name&gt;</code> label in the <code>labels</code> field.</p>\n<div class=\"paragraph\">\n<p>The Validating Admission Policy approves the request, and the PyTorchJob is created.</p>\n</div>\n</li>\n<li>\n<p>Try to create a PyTorchJob without specifying the <code>kueue.x-k8s.io/queue-name</code> label in the <code>labels</code> field.</p>\n<div class=\"paragraph\">\n<p>The Validating Admission Policy rejects the request, and the PyTorchJob is not created, because a local queue is not specified.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"disabling-lqlabel-all_managing-odh\">Disabling the local-queue labeling policy for all projects</h4>\n<div class=\"paragraph _abstract\">\n<p>The local-queue labeling policy is enforced for all projects by default.\nIf the local-queue labeling policy is disabled, it is possible to create Ray clusters that do not use a local queue.\nHowever, the resources of such Ray clusters are not managed by Kueue.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can disable the local-queue labeling policy for all projects by editing the <code>ValidatingAdmissionPolicyBinding</code> resource as described in this procedure.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform with the <code>cluster-admin</code> role.</p>\n</li>\n<li>\n<p>You have installed the required distributed workloads components as described in <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-distributed-workloads-components_install\">Installing the distributed workloads components</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, open the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select <strong>All Projects</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Home</strong> &#8594; <strong>Search</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Resources</strong> list, search for <strong>ValidatingAdmissionPolicyBinding</strong>.</p>\n</li>\n<li>\n<p>Click the <code>kueue-validating-admission-policy-binding</code> entry to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab to show the binding specifications.</p>\n</li>\n<li>\n<p>Edit the <code>policyName</code> field to change the value to <code>disabled</code>, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example to disable local-queue labeling for all projects</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">kind: ValidatingAdmissionPolicyBinding\napiVersion: admissionregistration.k8s.io/v1\nmetadata:\n  name: kueue-validating-admission-policy-binding\n  uid: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  resourceVersion: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  generation: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  creationTimestamp: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: kueue\n  managedFields:\nspec:\n  policyName: disabled\n  matchResources:\n    namespaceSelector: {}\n    objectSelector: {}\n    matchPolicy: Equivalent\n  validationActions:\n    - Deny</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>To verify that the local-queue labeling policy is disabled for Ray clusters:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Create a project.</p>\n</li>\n<li>\n<p>Complete the following steps in the new project:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Before you configure a local queue, try to create a Ray cluster.</p>\n<div class=\"paragraph\">\n<p>The Ray cluster is created, even though no local queue is configured, because the Validating Admission Policy is not enforced.\nHowever, the Ray cluster resources are not managed by Kueue.</p>\n</div>\n</li>\n<li>\n<p>Create a local queue without the <code>default-queue</code> annotation.</p>\n</li>\n<li>\n<p>Try to create a Ray cluster, and specify the local-queue name in the <code>local_queue</code> field.</p>\n<div class=\"paragraph\">\n<p>The Ray cluster is created, and the Ray cluster resources are managed by Kueue.</p>\n</div>\n</li>\n<li>\n<p>Try to create a Ray cluster without specifying a value in the <code>local_queue</code> field.</p>\n<div class=\"paragraph\">\n<p>The Ray cluster is created, but the Ray cluster resources are not managed by Kueue.</p>\n</div>\n</li>\n<li>\n<p>Edit the local queue to add the <code>kueue.x-k8s.io/default-queue: \"true\"</code> annotation, which configures that queue as the default local queue.</p>\n</li>\n<li>\n<p>Try to create a Ray cluster without specifying a value in the <code>local_queue</code> field.</p>\n<div class=\"paragraph\">\n<p>The Ray cluster is created, and the Ray cluster resources are managed by Kueue.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>To verify that the local-queue labeling policy is disabled for PyTorchJobs:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Create a project.</p>\n</li>\n<li>\n<p>Complete the following steps in the new project:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Before you configure a local queue, try to create a PyTorchJob.</p>\n<div class=\"paragraph\">\n<p>The PyTorchJob is created, even though no local queue is configured, because the Validating Admission Policy is not enforced. The PyTorchJob resources are not managed by Kueue.</p>\n</div>\n</li>\n<li>\n<p>Create a local queue.</p>\n</li>\n<li>\n<p>Try to create a PyTorchJob and add the <code>kueue.x-k8s.io/queue-name: &lt;local-queue-name&gt;</code> label in the <code>labels</code> field.</p>\n<div class=\"paragraph\">\n<p>The PyTorchJob is created, and the PyTorchJob resources are managed by Kueue.</p>\n</div>\n</li>\n<li>\n<p>Try to create a PyTorchJob without adding the <code>kueue.x-k8s.io/queue-name: &lt;local-queue-name&gt;</code> label in the <code>labels</code> field.</p>\n<div class=\"paragraph\">\n<p>The PyTorchJob is created, but the PyTorchJob resources are not managed by Kueue.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"enforcing-lqlabel-some_managing-odh\">Enforcing the local-queue labeling policy for some projects only</h4>\n<div class=\"paragraph _abstract\">\n<p>When the local-queue labeling policy is enforced, Ray clusters and PyTorchJobs are created <em>only if</em> they are configured to use a local queue, and the Ray cluster and PyTorchJob resources are then managed by Kueue.\nDisabling the policy means that it is possible to create Ray clusters or PyTorchJobs that do not use a local queue, but the resources of such Ray clusters or PyTorchJobs are not managed by Kueue.</p>\n</div>\n<div class=\"paragraph\">\n<p>The local-queue labeling policy is enforced for all projects by default. The Validating Admission Policy is enforced on both RayCluster and PyTorchJob resources. To enforce the local-queue labeling policy for <em>some</em> projects only, follow these steps.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform with the <code>cluster-admin</code> role.</p>\n</li>\n<li>\n<p>You have installed the required distributed workloads components as described in <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-distributed-workloads-components_install\">Installing the distributed workloads components</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, open the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select <strong>All Projects</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Home</strong> &#8594; <strong>Search</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Resources</strong> list, search for <strong>ValidatingAdmissionPolicyBinding</strong>.</p>\n</li>\n<li>\n<p>Click the <code>kueue-validating-admission-policy-binding</code> entry to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab to show the binding specifications.</p>\n</li>\n<li>\n<p>Edit the <code>namespaceSelector</code> field to delete the <code>{}</code> value, and add the <code>matchLabels</code> and <code>kueue.openshift.io/managed</code> values as shown in the following example:</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>The <code>kueue.openshift.io/managed=true</code> label is supported for Open Data Hub projects only.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Example to enforce local-queue labeling for some projects only</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">kind: ValidatingAdmissionPolicyBinding\napiVersion: admissionregistration.k8s.io/v1\nmetadata:\n  name: kueue-validating-admission-policy-binding\n  uid: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  resourceVersion: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  generation: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  creationTimestamp: <em>&lt;Populated by the system. Read-only.&gt;</em>\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: kueue\n  managedFields:\nspec:\n  policyName: kueue-validating-admission-policy\n  matchResources:\n    namespaceSelector:\n      matchLabels:\n      kueue.openshift.io/managed: \"true\"\n    objectSelector: {}\n    matchPolicy: Equivalent\n  validationActions:\n    - Deny</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n<li>\n<p>Add the <code>kueue.openshift.io/managed</code> label to each project for which you want to enforce this policy, by running the following command:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example command to add the <code>kueue.openshift.io/managed</code> label to a project</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">oc label namespace <em>&lt;project-name&gt;</em> kueue.openshift.io/managed=true</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>Create two projects: Project A and Project B.</p>\n</li>\n<li>\n<p>Add the <code>kueue.openshift.io/managed</code> label to Project A only.</p>\n</li>\n<li>\n<p>In each project, try to create a Ray cluster or PyTorchJob.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>In Project A and all projects with the <code>kueue.openshift.io/managed</code> label, the behavior is as described in <a href=\"https://opendatahub.io/docs/managing-odh/#enforcing-lqlabel-all_managing-odh\">Enforcing the local-queue labeling policy for all projects</a>.</p>\n</li>\n<li>\n<p>In Project B and all projects without the <code>kueue.openshift.io/managed</code> label, the behavior is as described in <a href=\"https://opendatahub.io/docs/managing-odh/#disabling-lqlabel-all_managing-odh\">Disabling the local-queue labeling policy for all projects</a>.</p>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-the-codeflare-operator_managing-odh\">Configuring the CodeFlare Operator</h3>\n<div class=\"paragraph _abstract\">\n<p>If you want to change the default configuration of the CodeFlare Operator for distributed workloads in Open Data Hub, you can edit the associated config map.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform with the <code>cluster-admin</code> role.</p>\n</li>\n<li>\n<p>You have installed the required distributed workloads components as described in <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-distributed-workloads-components_install\">Installing the distributed workloads components</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, click <strong>Workloads</strong> &#8594; <strong>ConfigMaps</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select <strong>odh</strong>.</p>\n</li>\n<li>\n<p>Search for the <strong>codeflare-operator-config</strong> config map, and click the config map name to open the <strong>ConfigMap details</strong> page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab to show the config map specifications.</p>\n</li>\n<li>\n<p>In the <code>data:config.yaml:kuberay</code> section, you can edit the following entries:</p>\n<div class=\"dlist\">\n<dl>\n<dt class=\"hdlist1\">ingressDomain</dt>\n<dd>\n<p>This configuration option is null (<code>ingressDomain: \"\"</code>) by default.\nDo not change this option unless the Ingress Controller is not running on OpenShift.\nOpen Data Hub uses this value to generate the dashboard and client routes for every Ray Cluster, as shown in the following examples:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example dashboard and client routes</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">ray-dashboard-<em>&lt;clustername&gt;</em>-<em>&lt;namespace&gt;</em>.<em>&lt;your.ingress.domain&gt;</em>\nray-client-<em>&lt;clustername&gt;</em>-<em>&lt;namespace&gt;</em>.<em>&lt;your.ingress.domain&gt;</em></code></pre>\n</div>\n</div>\n</dd>\n<dt class=\"hdlist1\">mTLSEnabled</dt>\n<dd>\n<p>This configuration option is enabled (<code>mTLSEnabled: true</code>) by default.\nWhen this option is enabled, the Ray Cluster pods create certificates that are used for mutual Transport Layer Security (mTLS), a form of mutual authentication, between Ray Cluster nodes.\nWhen this option is enabled, Ray clients cannot connect to the Ray head node unless they download the generated certificates from the <code>ca-secret-_&lt;cluster_name&gt;_</code> secret, generate the necessary certificates for mTLS communication, and then set the required Ray environment variables.\nUsers must then re-initialize the Ray clients to apply the changes.\nThe CodeFlare SDK provides the following functions to simplify the authentication process for Ray clients:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example Ray client authentication code</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">from codeflare_sdk import generate_cert\n\ngenerate_cert.generate_tls_cert(cluster.config.name, cluster.config.namespace)\ngenerate_cert.export_env(cluster.config.name, cluster.config.namespace)\n\nray.init(cluster.cluster_uri())</code></pre>\n</div>\n</div>\n</dd>\n<dt class=\"hdlist1\">rayDashboardOauthEnabled</dt>\n<dd>\n<p>This configuration option is enabled (<code>rayDashboardOAuthEnabled: true</code>) by default.\nWhen this option is enabled, Open Data Hub places an OpenShift OAuth proxy in front of the Ray Cluster head node.\nUsers must then authenticate by using their OpenShift cluster login credentials when accessing the Ray Dashboard through the browser.\nIf users want to access the Ray Dashboard in another way (for example, by using the Ray <code>JobSubmissionClient</code> class), they must set an authorization header as part of their request, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example authorization header</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">{Authorization: \"Bearer <em>&lt;your-openshift-token&gt;</em>\"}</code></pre>\n</div>\n</div>\n</dd>\n</dl>\n</div>\n</li>\n<li>\n<p>To save your changes, click <strong>Save</strong>.</p>\n</li>\n<li>\n<p>To apply your changes, delete the pod:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Workloads</strong> &#8594; <strong>Pods</strong>.</p>\n</li>\n<li>\n<p>Find the <strong>codeflare-operator-manager-<em>&lt;pod-id&gt;</em></strong> pod.</p>\n</li>\n<li>\n<p>Click the options menu (&#8942;) for that pod, and then click <strong>Delete Pod</strong>.\nThe pod restarts with your changes applied.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>Check the status of the <strong>codeflare-operator-manager</strong> pod, as follows:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>Search for the <strong>codeflare-operator-manager</strong> deployment, and then click the deployment name to open the deployment details page.</p>\n</li>\n<li>\n<p>Click the <strong>Pods</strong> tab.\nWhen the status of the <strong>codeflare-operator-manager-<em>&lt;pod-id&gt;</em></strong> pod is <strong>Running</strong>, the pod is ready to use.\nTo see more information about the pod, click the pod name to open the pod details page, and then click the <strong>Logs</strong> tab.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-a-cluster-for-rdma_managing-odh\">Configuring a cluster for RDMA</h3>\n<div class=\"paragraph _abstract\">\n<p>NVIDIA GPUDirect RDMA uses Remote Direct Memory Access (RDMA) to provide direct GPU interconnect.\nTo configure a cluster for RDMA, a cluster administrator must install and configure several Operators.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You can access an OpenShift cluster as a cluster administrator.</p>\n</li>\n<li>\n<p>Your cluster has multiple worker nodes with supported NVIDIA GPUs, and can access a compatible NVIDIA accelerated networking platform.</p>\n</li>\n<li>\n<p>You have installed Open Data Hub with the required distributed training components as described in <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-distributed-workloads-components_install\">Installing the distributed workloads components</a>.</p>\n</li>\n<li>\n<p>You have configured the distributed training resources as described in <a href=\"https://opendatahub.io/docs/managing-odh/#managing-distributed-workloads_managing-odh\">Managing distributed workloads</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Console as a cluster administrator.</p>\n</li>\n<li>\n<p>Enable NVIDIA GPU support in Open Data Hub.</p>\n<div class=\"paragraph\">\n<p>This process includes installing the Node Feature Discovery Operator and the NVIDIA GPU Operator.\nFor more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>After the NVIDIA GPU Operator is installed, ensure that <code>rdma</code> is set to <code>enabled</code> in your <code>ClusterPolicy</code> custom resource instance.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>To simplify the management of NVIDIA networking resources, install and configure the NVIDIA Network Operator, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Install the NVIDIA Network Operator, as described in <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/operators/administrator-tasks#olm-adding-operators-to-a-cluster\">Adding Operators to a cluster</a> in the OpenShift documentation.</p>\n</li>\n<li>\n<p>Configure the NVIDIA Network Operator, as described in the deployment examples in the <a href=\"https://docs.nvidia.com/networking/display/cokan10/network+operator\">Network Operator Application Notes</a> in the NVIDIA documentation.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>[Optional] To use Single Root I/O Virtualization (SR-IOV) deployment modes, complete the following steps:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Install the SR-IOV Network Operator, as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/networking/networking-operators#installing-sriov-operator\">Installing the SR-IOV Network Operator</a> section in the OpenShift documentation.</p>\n</li>\n<li>\n<p>Configure the SR-IOV Network Operator, as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/networking/networking-operators#configuring-sriov-operator\">Configuring the SR-IOV Network Operator</a> section in the OpenShift documentation.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Use the Machine Configuration Operator to increase the limit of pinned memory for non-root users in the container engine (CRI-O) configuration, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Console, in the <strong>Administrator</strong> perspective, click <strong>Compute &#8594; MachineConfigs</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Create MachineConfig</strong>.</p>\n</li>\n<li>\n<p>Replace the placeholder text with the following content:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example machine configuration</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>apiVersion: machineconfiguration.openshift.io/v1\nkind: MachineConfig\nmetadata:\n  labels:\n    machineconfiguration.openshift.io/role: worker\n  name: 02-worker-container-runtime\nspec:\n  config:\n    ignition:\n      version: 3.2.0\n    storage:\n      files:\n        - contents:\n            inline: |\n              [crio.runtime]\n              default_ulimits = [\n                \"memlock=-1:-1\"\n              ]\n          mode: 420\n          overwrite: true\n          path: /etc/crio/crio.conf.d/10-custom</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Edit the <code>default_ulimits</code> entry to specify an appropriate value for your configuration.\nFor more information about default limits, see the <a href=\"https://access.redhat.com/solutions/6243491\">Set default ulimits on CRIO Using machine config</a> Knowledgebase solution.</p>\n</li>\n<li>\n<p>Click <strong>Create</strong>.</p>\n</li>\n<li>\n<p>Restart the worker nodes to apply the machine configuration.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>This configuration enables non-root users to run the training job with RDMA in the most restrictive OpenShift default security context.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>Verify that the Operators are installed correctly, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Console, in the <strong>Administrator</strong> perspective, click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Select your project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Verify that a pod is running for each of the newly installed Operators.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Verify that RDMA is being used, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Edit the <code>PyTorchJob</code> resource to set the <code>*NCCL_DEBUG*</code> environment variable to <code>INFO</code>, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Setting the NCCL debug level to INFO</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>        spec:\n          containers:\n          - command:\n            - /bin/bash\n            - -c\n            - \"your container command\"\n            env:\n            - name: NCCL_SOCKET_IFNAME\n              value: \"net1\"\n            - name: NCCL_IB_HCA\n              value: \"mlx5_1\"\n            - name: NCCL_DEBUG\n              value: \"INFO\"</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Run the PyTorch job.</p>\n</li>\n<li>\n<p>Check that the pod logs include an entry similar to the following text:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example pod log entry</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [RO]</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh\">Troubleshooting common problems with distributed workloads for administrators</h3>\n<div class=\"paragraph _abstract\">\n<p>If your users are experiencing errors in Open Data Hub relating to distributed workloads, read this section to understand what could be causing the problem, and how to resolve the problem.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_users_ray_cluster_is_in_a_suspended_state\">A user&#8217;s Ray cluster is in a suspended state</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>The resource quota specified in the cluster queue configuration might be insufficient, or the resource flavor might not yet be created.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The user&#8217;s Ray cluster head pod or worker pods remain in a suspended state.\nCheck the status of the <code>Workloads</code> resource that is created with the <code>RayCluster</code> resource.\nThe <code>status.conditions.message</code> field provides the reason for the suspended state, as shown in the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">status:\n conditions:\n   - lastTransitionTime: '2024-05-29T13:05:09Z'\n     message: 'couldn''t assign flavors to pod set small-group-jobtest12: insufficient quota for nvidia.com/gpu in flavor default-flavor in ClusterQueue'</code></pre>\n</div>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Check whether the resource flavor is created, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Home &#8594; Search</strong>, and from the <strong>Resources</strong> list, select <strong>ResourceFlavor</strong>.</p>\n</li>\n<li>\n<p>If necessary, create the resource flavor.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Check the cluster queue configuration in the user&#8217;s code, to ensure that the resources that they requested are within the limits defined for the project.</p>\n</li>\n<li>\n<p>If necessary, increase the resource quota.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>For information about configuring resource flavors and quotas, see <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</a>.</p>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_users_ray_cluster_is_in_a_failed_state\">A user&#8217;s Ray cluster is in a failed state</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>The user might have insufficient resources.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The user&#8217;s Ray cluster head pod or worker pods are not running.\nWhen a Ray cluster is created, it initially enters a <code>failed</code> state.\nThis failed state usually resolves after the reconciliation process completes and the Ray cluster pods are running.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Resolution</div>\n<p>If the failed state persists, complete the following steps:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Click the user&#8217;s pod name to open the pod details page.</p>\n</li>\n<li>\n<p>Click the <strong>Events</strong> tab, and review the pod events to identify the cause of the problem.</p>\n</li>\n<li>\n<p>Check the status of the <code>Workloads</code> resource that is created with the <code>RayCluster</code> resource.\nThe <code>status.conditions.message</code> field provides the reason for the failed state.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_receives_a_failed_to_call_webhook_error_message_for_the_codeflare_operator\">A user receives a \"failed to call webhook\" error message for the CodeFlare Operator</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.up()</code> command, the following error is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">ApiException: (500)\nReason: Internal Server Error\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"Internal error occurred: failed calling webhook \\\"mraycluster.ray.openshift.ai\\\": failed to call webhook: Post \\\"https://codeflare-operator-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\\\": no endpoints available for service \\\"codeflare-operator-webhook-service\\\"\",\"reason\":\"InternalError\",\"details\":{\"causes\":[{\"message\":\"failed calling webhook \\\"mraycluster.ray.openshift.ai\\\": failed to call webhook: Post \\\"https://codeflare-operator-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\\\": no endpoints available for service \\\"codeflare-operator-webhook-service\\\"\"}]},\"code\":500}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The CodeFlare Operator pod might not be running.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Verify that the CodeFlare Operator pod is running.\nIf necessary, restart the CodeFlare Operator pod.</p>\n</li>\n<li>\n<p>Review the logs for the CodeFlare Operator pod to verify that the webhook server is serving, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">INFO\tcontroller-runtime.webhook\t  Serving webhook server\t{\"host\": \"\", \"port\": 9443}</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue\">A user receives a \"failed to call webhook\" error message for Kueue</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.up()</code> command, the following error is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">ApiException: (500)\nReason: Internal Server Error\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"Internal error occurred: failed calling webhook \\\"mraycluster.kb.io\\\": failed to call webhook: Post \\\"https://kueue-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\\\": no endpoints available for service \\\"kueue-webhook-service\\\"\",\"reason\":\"InternalError\",\"details\":{\"causes\":[{\"message\":\"failed calling webhook \\\"mraycluster.kb.io\\\": failed to call webhook: Post \\\"https://kueue-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\\\": no endpoints available for service \\\"kueue-webhook-service\\\"\"}]},\"code\":500}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The Kueue pod might not be running.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Verify that the Kueue pod is running.\nIf necessary, restart the Kueue pod.</p>\n</li>\n<li>\n<p>Review the logs for the Kueue pod to verify that the webhook server is serving, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">{\"level\":\"info\",\"ts\":\"2024-06-24T14:36:24.255137871Z\",\"logger\":\"controller-runtime.webhook\",\"caller\":\"webhook/server.go:242\",\"msg\":\"Serving webhook server\",\"host\":\"\",\"port\":9443}</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_users_ray_cluster_does_not_start\">A user&#8217;s Ray cluster does not start</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.up()</code> command, when they run either the <code>cluster.details()</code> command or the <code>cluster.status()</code> command, the Ray cluster status remains as <code>Starting</code> instead of changing to <code>Ready</code>.\nNo pods are created.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>Check the status of the <code>Workloads</code> resource that is created with the <code>RayCluster</code> resource.\nThe <code>status.conditions.message</code> field provides the reason for remaining in the <code>Starting</code> state.\nSimilarly, check the <code>status.conditions.message</code> field for the <code>RayCluster</code> resource.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Verify that the KubeRay pod is running.\nIf necessary, restart the KubeRay pod.</p>\n</li>\n<li>\n<p>Review the logs for the KubeRay pod to identify errors.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_receives_a_default_local_queue_not_found_error_message\">A user receives a <strong>Default Local Queue &#8230;&#8203; not found</strong> error message</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.up()</code> command, the following error is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">Default Local Queue with kueue.x-k8s.io/default-queue: true annotation not found please create a default Local Queue or provide the local_queue name in Cluster Configuration.</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>No default local queue is defined, and a local queue is not specified in the cluster configuration.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Check whether a local queue exists in the user&#8217;s project, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Home &#8594; Search</strong>, and from the <strong>Resources</strong> list, select <strong>LocalQueue</strong>.</p>\n</li>\n<li>\n<p>If no local queues are found, create a local queue.</p>\n</li>\n<li>\n<p>Provide the user with the details of the local queues in their project, and advise them to add a local queue to their cluster configuration.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Define a default local queue.</p>\n<div class=\"paragraph\">\n<p>For information about creating a local queue and defining a default local queue, see <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</a>.</p>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_receives_a_local_queue_provided_does_not_exist_error_message\">A user receives a <strong>local_queue provided does not exist</strong> error message</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.up()</code> command, the following error is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">local_queue provided does not exist or is not in this namespace. Please provide the correct local_queue name in Cluster Configuration.</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>An incorrect value is specified for the local queue in the cluster configuration, or an incorrect default local queue is defined.\nThe specified local queue either does not exist, or exists in a different namespace.</p>\n</div>\n<div class=\"olist loweralpha\">\n<div class=\"title\">Resolution</div>\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Click <strong>Search</strong>, and from the <strong>Resources</strong> list, select <strong>LocalQueue</strong>.</p>\n</li>\n<li>\n<p>Resolve the problem in one of the following ways:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If no local queues are found, create a local queue.</p>\n</li>\n<li>\n<p>If one or more local queues are found, provide the user with the details of the local queues in their project.\nAdvise the user to ensure that they spelled the local queue name correctly in their cluster configuration, and that the <code>namespace</code> value in the cluster configuration matches their project name.\nIf the user does not specify a <code>namespace</code> value in the cluster configuration, the Ray cluster is created in the current project.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Define a default local queue.</p>\n<div class=\"paragraph\">\n<p>For information about creating a local queue and defining a default local queue, see <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</a>.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_cannot_create_a_ray_cluster_or_submit_jobs\">A user cannot create a Ray cluster or submit jobs</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.up()</code> command, an error similar to the following text is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">RuntimeError: Failed to get RayCluster CustomResourceDefinition: (403)\nReason: Forbidden\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"rayclusters.ray.io is forbidden: User \\\"system:serviceaccount:regularuser-project:regularuser-workbench\\\" cannot list resource \\\"rayclusters\\\" in API group \\\"ray.io\\\" in the namespace \\\"regularuser-project\\\"\",\"reason\":\"Forbidden\",\"details\":{\"group\":\"ray.io\",\"kind\":\"rayclusters\"},\"code\":403}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The correct OpenShift login credentials are not specified in the <code>TokenAuthentication</code> section of the user&#8217;s notebook code.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Advise the user to identify and specify the correct OpenShift login credentials as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform console header, click your username and click <strong>Copy login command</strong>.</p>\n</li>\n<li>\n<p>In the new tab that opens, log in as the user whose credentials you want to use.</p>\n</li>\n<li>\n<p>Click <strong>Display Token</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Log in with this token</strong> section, copy the <code>token</code> and <code>server</code> values.</p>\n</li>\n<li>\n<p>Specify the copied <code>token</code> and <code>server</code> values in your notebook code as follows:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">auth = TokenAuthentication(\n    token = \"<em>&lt;token&gt;</em>\",\n    server = \"<em>&lt;server&gt;</em>\",\n    skip_tls=False\n)\nauth.login()</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Verify that the user has the correct permissions and is part of the <code>rhoai-users</code> group.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_the_users_pod_provisioned_by_kueue_is_terminated_before_the_users_image_is_pulled\">The user&#8217;s pod provisioned by Kueue is terminated before the user&#8217;s image is pulled</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>Kueue waits for a period of time before marking a workload as ready, to enable all of the workload pods to become provisioned and running.\nBy default, Kueue waits for 5 minutes.\nIf the pod image is very large and is still being pulled after the 5-minute waiting period elapses, Kueue fails the workload and terminates the related pods.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Diagnosis</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Click the user&#8217;s pod name to open the pod details page.</p>\n</li>\n<li>\n<p>Click the <strong>Events</strong> tab, and review the pod events to check whether the image pull completed successfully.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Resolution</div>\n<p>If the pod takes more than 5 minutes to pull the image, resolve the problem in one of the following ways:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Add an <code>OnFailure</code> restart policy for resources that are managed by Kueue.</p>\n</li>\n<li>\n<p>In the <code>redhat-ods-applications</code> namespace, edit the <code>kueue-manager-config</code> ConfigMap to set a custom timeout for the <code>waitForPodsReady</code> property.\nFor more information about this configuration option, see <a href=\"https://kueue.sigs.k8s.io/docs/tasks/manage/setup_wait_for_pods_ready/#enabling-waitforpodsready\">Enabling waitForPodsReady</a> in the Kueue documentation.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_backing_up_data\">Backing up data</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Backing up Open Data Hub involves various components, including the OpenShift Container Platform cluster and storage data.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"backing-up-storage-data_managing-odh\">Backing up storage data</h3>\n<div class=\"paragraph _abstract\">\n<p>It is a best practice to back up the data on your persistent volume claims (PVCs) regularly.</p>\n</div>\n<div class=\"paragraph\">\n<p>Backing up your data is particularly important before you delete a user and before you uninstall Open Data Hub, as all PVCs are deleted when Open Data Hub is uninstalled.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about backing up PVCs for your cluster platform, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/backup_and_restore/oadp-application-backup-and-restore.html\">OADP Application backup and restore</a> in the OpenShift Container Platform documentation.</p>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/storage/understanding-persistent-storage\">Understanding persistent storage</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"backing-up-your-cluster_managing-odh\">Backing up your cluster</h3>\n<div class=\"paragraph _abstract\">\n<p>If you plan to upgrade or uninstall Open Data Hub on your cluster, back up your cluster data so that you can restore it later if needed.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html-single/backup_and_restore/index\">Backup and restore</a> in the OpenShift Container Platform documentation.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"viewing-logs-and-audit-records_managing-odh\">Viewing logs and audit records</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>As a cluster administrator, you can use the Open Data Hub Operator logger to monitor and troubleshoot issues. You can also use OpenShift Container Platform audit records to review a history of changes made to the Open Data Hub Operator configuration.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-the-operator-logger_managing-odh\">Configuring the Open Data Hub Operator logger</h3>\n<div class=\"paragraph _abstract\">\n<p>You can change the log level for Open Data Hub Operator components by setting the <code>.spec.devFlags.logmode</code> flag for the <strong>DSC Initialization</strong>/<code>DSCI</code> custom resource during runtime. If you do not set a <code>logmode</code> value, the logger uses the INFO log level by default.</p>\n</div>\n<div class=\"paragraph\">\n<p>The log level that you set with <code>.spec.devFlags.logmode</code> applies to all components, not just those in a <strong>Managed</strong> state.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following table shows the available log levels:</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<colgroup>\n<col style=\"width: 20%;\">\n<col style=\"width: 20%;\">\n<col style=\"width: 20%;\">\n<col style=\"width: 20%;\">\n<col style=\"width: 20%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">Log level</th>\n<th class=\"tableblock halign-left valign-top\">Stacktrace level</th>\n<th class=\"tableblock halign-left valign-top\">Verbosity</th>\n<th class=\"tableblock halign-left valign-top\">Output</th>\n<th class=\"tableblock halign-left valign-top\">Timestamp type</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>devel</code> or <code>development</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">WARN</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">INFO</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Console</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Epoch timestamps</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>\"\"</code>  (or no <code>logmode</code> value set)</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">ERROR</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">INFO</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">JSON</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Human-readable timestamps</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>prod</code> or <code>production</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">ERROR</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">INFO</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">JSON</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Human-readable timestamps</p></td>\n</tr>\n</tbody>\n</table>\n<div class=\"paragraph\">\n<p>Logs that are set to <code>devel</code> or <code>development</code> generate in a plain text console format.\nLogs that are set to <code>prod</code>, <code>production</code>, or which do not have a level set generate in a JSON format.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have administrator access to the <code>DSCInitialization</code> resources in the OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You installed the OpenShift command line interface (<code>oc</code>) as described in <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform as a cluster administrator.</p>\n</li>\n<li>\n<p>Click <strong>Operators</strong> → <strong>Installed Operators</strong> and then click the Open Data Hub Operator.</p>\n</li>\n<li>\n<p>Click the <strong>DSC Initialization</strong> tab.</p>\n</li>\n<li>\n<p>Click the <strong>default-dsci</strong> object.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>In the <code>spec</code> section, update the <code>.spec.devFlags.logmode</code> flag with the log level that you want to set.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>apiVersion: dscinitialization.opendatahub.io/v1\nkind: DSCInitialization\nmetadata:\n  name: default-dsci\nspec:\n  devFlags:\n    logmode: development</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>You can also configure the log level from the OpenShift CLI by using the following command with the <code>logmode</code> value set to the log level that you want.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc patch dsci default-dsci -p '{\"spec\":{\"devFlags\":{\"logmode\":\"development\"}}}' --type=merge</code></pre>\n</div>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>If you set the component log level to <code>devel</code> or <code>development</code>, logs generate more frequently and include logs at <code>WARN</code> level and above.</p>\n</li>\n<li>\n<p>If you set the component log level to <code>prod</code> or <code>production</code>, or do not set a log level, logs generate less frequently and include logs at <code>ERROR</code> level or above.</p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_viewing_the_open_data_hub_operator_logs\">Viewing the Open Data Hub Operator logs</h4>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift CLI.</p>\n</li>\n<li>\n<p>Run the following command to stream logs from all Operator pods:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>for pod in $(oc get pods -l name=opendatahub-operator -n openshift-operators -o name); do\n  oc logs -f \"$pod\" -n openshift-operators &amp;\ndone</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The Operator pod logs open in your terminal.</p>\n</div>\n<div class=\"admonitionblock tip\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Tip</div>\n</td>\n<td class=\"content\">\nPress <code>Ctrl+C</code> to stop viewing. To fully stop all log streams, run <code>kill $(jobs -p)</code>.\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ol>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"viewing-audit-records_managing-odh\">Viewing audit records</h3>\n<div class=\"paragraph _abstract\">\n<p>Cluster administrators can use OpenShift Container Platform auditing to see changes made to the Open Data Hub Operator configuration by reviewing modifications to the DataScienceCluster (DSC) and DSCInitialization (DSCI) custom resources. Audit logging is enabled by default in standard OpenShift Container Platform cluster configurations.\nFor more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/security_and_compliance/audit-log-view#audit-log-view\" target=\"_blank\" rel=\"noopener\">Viewing audit logs</a> in the OpenShift Container Platform documentation.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following example shows how to use the OpenShift Container Platform audit logs to see the history of changes made (by users) to the DSC and DSCI custom resources.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You installed the OpenShift command line interface (<code>oc</code>) as described in <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In a terminal window, if you are not already logged in to your OpenShift Container Platform cluster as a cluster administrator, log in to the OpenShift Container Platform CLI as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ oc login <em>&lt;openshift_cluster_url&gt;</em> -u <em>&lt;admin_username&gt;</em> -p <em>&lt;password&gt;</em></code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>To access the full content of the changed custom resources, set the OpenShift Container Platform audit log policy to <code>WriteRequestBodies</code> or a more comprehensive profile. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/security_and_compliance/audit-log-policy-config#configuring-audit-policy_audit-log-policy-config\" target=\"_blank\" rel=\"noopener\">Configuring the audit log policy</a>.</p>\n</li>\n<li>\n<p>Fetch the audit log files that are available for the relevant control plane nodes. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc adm node-logs --role=master --path=kube-apiserver/ \\\n  | awk '{ print $1 }' | sort -u \\\n  | while read node ; do\n      oc adm node-logs $node --path=kube-apiserver/audit.log &lt; /dev/null\n    done \\\n  | grep opendatahub &gt; /tmp/kube-apiserver-audit-opendatahub.log</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Search the files for the DSC and DSCI custom resources. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>jq 'select((.objectRef.apiGroup == \"dscinitialization.opendatahub.io\"\n                or .objectRef.apiGroup == \"datasciencecluster.opendatahub.io\")\n              and .user.username != \"system:serviceaccount:redhat-ods-operator:redhat-ods-operator-controller-manager\"\n              and .verb != \"get\" and .verb != \"watch\" and .verb != \"list\")' &lt; /tmp/kube-apiserver-audit-opendatahub.log</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The commands return relevant log entries.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>","id":"46c66196-c4a1-5cc4-abc9-aa6651624fd2","document":{"title":"Managing Open Data Hub"}},"markdownRemark":null},"pageContext":{"id":"46c66196-c4a1-5cc4-abc9-aa6651624fd2"}},"staticQueryHashes":["2604506565"],"slicesMap":{}}